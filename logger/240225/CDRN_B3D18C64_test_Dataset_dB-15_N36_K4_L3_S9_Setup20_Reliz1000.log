Train.py PID: 2485

H shape: (20000, 4, 36) (20000, 4, 36)
NMMSE of valid dataset:: 0.06314184112037872
num samples :: 200000
num valid: 20000
config_path: conf/config_multisetup.yml
{'config': 'conf/config_multisetup.yml',
 'dataloader': {'batch_size': 512, 'num_workers': 1, 'shuffle': True},
 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset13_N36K4M4/train_Dataset_dB-15_N36_K4_L3_S9_Setup200_Reliz1000.mat',
             'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset13_N36K4M4/test_Dataset_dB-15_N36_K4_L3_S9_Setup20_Reliz1000.mat',
             'with_Vpinv': True},
 'log_path': 'logger/240225/CDRN_B3D18C64_test_Dataset_dB-15_N36_K4_L3_S9_Setup20_Reliz1000.log',
 'model': {'name': 'DnCNN_MultiBlock_ds',
           'params': {'block': 3,
                      'depth': 18,
                      'filters': 64,
                      'image_channels': 2,
                      'use_bnorm': True}},
 'seed': 10,
 'trainer': {'epoch_num': 240,
             'loss': 'SmoothL1Loss',
             'lr_scheduler': {'name': 'StepLR',
                              'params': {'gamma': 0.1, 'step_size': 60}},
             'optimizer': {'name': 'Adam',
                           'params': {'lr': 0.001, 'weight_decay': 0.001}}}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (47): ReLU(inplace=True)
      (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (50): ReLU(inplace=True)
      (51): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 6.80 MB
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.001
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7fb0a5ba7fb0>
loss function:: SmoothL1Loss()
[2025-02-24 15:46:37] Epoch 1/240, Loss: 43.779800, Train_MMSE: 0.158534, NMMSE: 0.109685, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 15:47:55] Epoch 2/240, Loss: 39.914635, Train_MMSE: 0.102676, NMMSE: 0.093592, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 15:49:23] Epoch 3/240, Loss: 38.695259, Train_MMSE: 0.09292, NMMSE: 0.088851, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 15:51:21] Epoch 4/240, Loss: 38.186504, Train_MMSE: 0.090097, NMMSE: 0.08694, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 15:53:32] Epoch 5/240, Loss: 38.273632, Train_MMSE: 0.088643, NMMSE: 0.087216, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 15:56:05] Epoch 6/240, Loss: 38.013912, Train_MMSE: 0.087743, NMMSE: 0.085794, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 15:58:43] Epoch 7/240, Loss: 37.549274, Train_MMSE: 0.087077, NMMSE: 0.085181, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:01:16] Epoch 8/240, Loss: 37.646580, Train_MMSE: 0.08648, NMMSE: 0.084821, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:03:41] Epoch 9/240, Loss: 37.948864, Train_MMSE: 0.085997, NMMSE: 0.085036, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:06:05] Epoch 10/240, Loss: 37.259705, Train_MMSE: 0.085554, NMMSE: 0.084604, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:08:29] Epoch 11/240, Loss: 37.303177, Train_MMSE: 0.085147, NMMSE: 0.085778, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:10:53] Epoch 12/240, Loss: 37.338413, Train_MMSE: 0.084868, NMMSE: 0.084159, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:13:17] Epoch 13/240, Loss: 37.506023, Train_MMSE: 0.084492, NMMSE: 0.084051, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:15:39] Epoch 14/240, Loss: 37.084404, Train_MMSE: 0.084221, NMMSE: 0.083683, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:18:03] Epoch 15/240, Loss: 37.330223, Train_MMSE: 0.083984, NMMSE: 0.083244, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:20:26] Epoch 16/240, Loss: 37.038258, Train_MMSE: 0.083685, NMMSE: 0.083332, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:22:49] Epoch 17/240, Loss: 37.151260, Train_MMSE: 0.083433, NMMSE: 0.083861, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:25:11] Epoch 18/240, Loss: 36.698696, Train_MMSE: 0.083206, NMMSE: 0.082749, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:27:36] Epoch 19/240, Loss: 36.845154, Train_MMSE: 0.08289, NMMSE: 0.083151, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:30:02] Epoch 20/240, Loss: 36.779060, Train_MMSE: 0.082624, NMMSE: 0.082528, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:32:26] Epoch 21/240, Loss: 36.604500, Train_MMSE: 0.082385, NMMSE: 0.082805, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:34:53] Epoch 22/240, Loss: 37.107525, Train_MMSE: 0.082109, NMMSE: 0.082283, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:37:17] Epoch 23/240, Loss: 36.756111, Train_MMSE: 0.081957, NMMSE: 0.082143, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:39:41] Epoch 24/240, Loss: 36.448441, Train_MMSE: 0.081697, NMMSE: 0.081735, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:42:03] Epoch 25/240, Loss: 36.937401, Train_MMSE: 0.081557, NMMSE: 0.081532, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:44:28] Epoch 26/240, Loss: 36.694649, Train_MMSE: 0.081383, NMMSE: 0.081646, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:46:52] Epoch 27/240, Loss: 36.299671, Train_MMSE: 0.081164, NMMSE: 0.081706, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:49:16] Epoch 28/240, Loss: 36.188057, Train_MMSE: 0.081011, NMMSE: 0.081406, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:51:39] Epoch 29/240, Loss: 36.448685, Train_MMSE: 0.080902, NMMSE: 0.081984, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:54:04] Epoch 30/240, Loss: 36.415668, Train_MMSE: 0.080755, NMMSE: 0.080853, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:56:28] Epoch 31/240, Loss: 36.446159, Train_MMSE: 0.080566, NMMSE: 0.081137, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 16:58:51] Epoch 32/240, Loss: 36.552601, Train_MMSE: 0.080377, NMMSE: 0.081484, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:01:15] Epoch 33/240, Loss: 36.171883, Train_MMSE: 0.080248, NMMSE: 0.080988, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:03:39] Epoch 34/240, Loss: 36.089146, Train_MMSE: 0.080153, NMMSE: 0.081248, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:06:04] Epoch 35/240, Loss: 35.967327, Train_MMSE: 0.079978, NMMSE: 0.081062, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:08:29] Epoch 36/240, Loss: 36.268078, Train_MMSE: 0.07985, NMMSE: 0.081009, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:10:52] Epoch 37/240, Loss: 36.195496, Train_MMSE: 0.079733, NMMSE: 0.080584, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:13:16] Epoch 38/240, Loss: 36.003090, Train_MMSE: 0.079595, NMMSE: 0.080732, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:15:38] Epoch 39/240, Loss: 35.755882, Train_MMSE: 0.079527, NMMSE: 0.081461, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:18:02] Epoch 40/240, Loss: 36.192020, Train_MMSE: 0.079342, NMMSE: 0.080391, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:20:27] Epoch 41/240, Loss: 35.969326, Train_MMSE: 0.079213, NMMSE: 0.080281, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:22:50] Epoch 42/240, Loss: 36.303318, Train_MMSE: 0.079126, NMMSE: 0.079942, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:25:14] Epoch 43/240, Loss: 36.361046, Train_MMSE: 0.079041, NMMSE: 0.080344, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:27:39] Epoch 44/240, Loss: 35.838963, Train_MMSE: 0.078944, NMMSE: 0.080199, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:30:03] Epoch 45/240, Loss: 36.058121, Train_MMSE: 0.078784, NMMSE: 0.08011, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:32:31] Epoch 46/240, Loss: 36.098755, Train_MMSE: 0.078693, NMMSE: 0.080603, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:34:55] Epoch 47/240, Loss: 36.152027, Train_MMSE: 0.078614, NMMSE: 0.08021, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:37:18] Epoch 48/240, Loss: 35.897705, Train_MMSE: 0.078552, NMMSE: 0.080281, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:39:43] Epoch 49/240, Loss: 35.686279, Train_MMSE: 0.078418, NMMSE: 0.07968, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:42:05] Epoch 50/240, Loss: 35.872093, Train_MMSE: 0.078351, NMMSE: 0.080086, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:44:27] Epoch 51/240, Loss: 35.962833, Train_MMSE: 0.078263, NMMSE: 0.0799, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:46:50] Epoch 52/240, Loss: 35.638927, Train_MMSE: 0.07817, NMMSE: 0.080119, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:49:14] Epoch 53/240, Loss: 35.649189, Train_MMSE: 0.078049, NMMSE: 0.079737, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:51:37] Epoch 54/240, Loss: 35.715267, Train_MMSE: 0.07798, NMMSE: 0.079817, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:54:03] Epoch 55/240, Loss: 35.710102, Train_MMSE: 0.077928, NMMSE: 0.079462, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:56:26] Epoch 56/240, Loss: 35.752438, Train_MMSE: 0.077872, NMMSE: 0.079302, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 17:58:50] Epoch 57/240, Loss: 35.933956, Train_MMSE: 0.077781, NMMSE: 0.079845, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 18:01:13] Epoch 58/240, Loss: 35.031425, Train_MMSE: 0.077729, NMMSE: 0.079491, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 18:03:37] Epoch 59/240, Loss: 35.757980, Train_MMSE: 0.077655, NMMSE: 0.079884, LS_NMSE: 0.234713, Lr: 0.001
[2025-02-24 18:06:04] Epoch 60/240, Loss: 35.766033, Train_MMSE: 0.07759, NMMSE: 0.080042, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:08:28] Epoch 61/240, Loss: 34.606556, Train_MMSE: 0.073857, NMMSE: 0.07678, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:10:52] Epoch 62/240, Loss: 34.555920, Train_MMSE: 0.073043, NMMSE: 0.077004, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:13:15] Epoch 63/240, Loss: 34.123428, Train_MMSE: 0.072697, NMMSE: 0.077227, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:15:40] Epoch 64/240, Loss: 34.219433, Train_MMSE: 0.072448, NMMSE: 0.077338, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:18:03] Epoch 65/240, Loss: 34.114826, Train_MMSE: 0.072235, NMMSE: 0.07749, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:20:26] Epoch 66/240, Loss: 34.161030, Train_MMSE: 0.072044, NMMSE: 0.077506, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:22:49] Epoch 67/240, Loss: 34.111938, Train_MMSE: 0.071867, NMMSE: 0.077667, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:25:14] Epoch 68/240, Loss: 34.224243, Train_MMSE: 0.07171, NMMSE: 0.077929, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:27:39] Epoch 69/240, Loss: 34.005299, Train_MMSE: 0.071558, NMMSE: 0.077847, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:30:02] Epoch 70/240, Loss: 34.271721, Train_MMSE: 0.071432, NMMSE: 0.078367, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:32:26] Epoch 71/240, Loss: 33.878551, Train_MMSE: 0.071295, NMMSE: 0.078135, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:34:50] Epoch 72/240, Loss: 34.241074, Train_MMSE: 0.071175, NMMSE: 0.078155, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:37:14] Epoch 73/240, Loss: 33.758858, Train_MMSE: 0.071046, NMMSE: 0.078418, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:39:38] Epoch 74/240, Loss: 34.229179, Train_MMSE: 0.070936, NMMSE: 0.078404, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:42:02] Epoch 75/240, Loss: 34.013477, Train_MMSE: 0.070819, NMMSE: 0.078406, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:44:25] Epoch 76/240, Loss: 34.084602, Train_MMSE: 0.070724, NMMSE: 0.078602, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:46:48] Epoch 77/240, Loss: 33.952255, Train_MMSE: 0.070614, NMMSE: 0.078602, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:49:13] Epoch 78/240, Loss: 33.922146, Train_MMSE: 0.070523, NMMSE: 0.078757, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:51:37] Epoch 79/240, Loss: 33.604763, Train_MMSE: 0.070429, NMMSE: 0.078725, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:53:58] Epoch 80/240, Loss: 33.937885, Train_MMSE: 0.070313, NMMSE: 0.078926, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:56:20] Epoch 81/240, Loss: 33.727646, Train_MMSE: 0.070233, NMMSE: 0.078826, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 18:58:42] Epoch 82/240, Loss: 33.322353, Train_MMSE: 0.070148, NMMSE: 0.079112, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:01:05] Epoch 83/240, Loss: 33.821995, Train_MMSE: 0.070064, NMMSE: 0.079207, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:03:27] Epoch 84/240, Loss: 33.760368, Train_MMSE: 0.069968, NMMSE: 0.079197, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:05:50] Epoch 85/240, Loss: 33.753540, Train_MMSE: 0.069885, NMMSE: 0.07933, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:08:15] Epoch 86/240, Loss: 33.759087, Train_MMSE: 0.069804, NMMSE: 0.079422, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:10:38] Epoch 87/240, Loss: 33.896526, Train_MMSE: 0.069724, NMMSE: 0.079621, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:13:01] Epoch 88/240, Loss: 33.270664, Train_MMSE: 0.069649, NMMSE: 0.079412, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:15:25] Epoch 89/240, Loss: 33.564003, Train_MMSE: 0.069566, NMMSE: 0.079649, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:17:48] Epoch 90/240, Loss: 33.779846, Train_MMSE: 0.069485, NMMSE: 0.079805, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:20:12] Epoch 91/240, Loss: 33.476139, Train_MMSE: 0.069416, NMMSE: 0.0798, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:22:35] Epoch 92/240, Loss: 33.651855, Train_MMSE: 0.069355, NMMSE: 0.08008, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:24:58] Epoch 93/240, Loss: 33.478977, Train_MMSE: 0.069281, NMMSE: 0.080143, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:27:21] Epoch 94/240, Loss: 33.652817, Train_MMSE: 0.069199, NMMSE: 0.080094, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:29:47] Epoch 95/240, Loss: 33.349739, Train_MMSE: 0.069131, NMMSE: 0.080036, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:32:10] Epoch 96/240, Loss: 33.669266, Train_MMSE: 0.069071, NMMSE: 0.080215, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:34:35] Epoch 97/240, Loss: 33.236954, Train_MMSE: 0.069004, NMMSE: 0.080224, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:36:58] Epoch 98/240, Loss: 33.601406, Train_MMSE: 0.068927, NMMSE: 0.080221, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:39:23] Epoch 99/240, Loss: 33.253418, Train_MMSE: 0.068864, NMMSE: 0.08037, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:41:47] Epoch 100/240, Loss: 33.367935, Train_MMSE: 0.068798, NMMSE: 0.080214, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:44:10] Epoch 101/240, Loss: 33.710396, Train_MMSE: 0.068728, NMMSE: 0.080701, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:46:34] Epoch 102/240, Loss: 33.280598, Train_MMSE: 0.068677, NMMSE: 0.080595, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:48:57] Epoch 103/240, Loss: 33.201977, Train_MMSE: 0.068608, NMMSE: 0.080603, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:51:21] Epoch 104/240, Loss: 33.075649, Train_MMSE: 0.068547, NMMSE: 0.080653, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:53:45] Epoch 105/240, Loss: 33.570553, Train_MMSE: 0.06849, NMMSE: 0.08074, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:56:07] Epoch 106/240, Loss: 33.084026, Train_MMSE: 0.068427, NMMSE: 0.080998, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 19:58:29] Epoch 107/240, Loss: 33.242573, Train_MMSE: 0.068369, NMMSE: 0.080734, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:00:54] Epoch 108/240, Loss: 33.185513, Train_MMSE: 0.068315, NMMSE: 0.081026, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:03:18] Epoch 109/240, Loss: 33.341057, Train_MMSE: 0.068254, NMMSE: 0.081162, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:05:40] Epoch 110/240, Loss: 33.414219, Train_MMSE: 0.0682, NMMSE: 0.081071, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:08:03] Epoch 111/240, Loss: 33.297390, Train_MMSE: 0.068138, NMMSE: 0.081187, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:10:26] Epoch 112/240, Loss: 33.279675, Train_MMSE: 0.068098, NMMSE: 0.081356, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:12:47] Epoch 113/240, Loss: 33.551723, Train_MMSE: 0.068033, NMMSE: 0.081528, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:15:08] Epoch 114/240, Loss: 32.940392, Train_MMSE: 0.067978, NMMSE: 0.08159, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:17:31] Epoch 115/240, Loss: 33.312809, Train_MMSE: 0.067937, NMMSE: 0.081456, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:19:53] Epoch 116/240, Loss: 33.130623, Train_MMSE: 0.067875, NMMSE: 0.08162, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:22:14] Epoch 117/240, Loss: 33.234978, Train_MMSE: 0.067811, NMMSE: 0.081705, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:24:37] Epoch 118/240, Loss: 33.051071, Train_MMSE: 0.067781, NMMSE: 0.081829, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:26:59] Epoch 119/240, Loss: 32.987968, Train_MMSE: 0.067737, NMMSE: 0.081789, LS_NMSE: 0.234713, Lr: 0.0001
[2025-02-24 20:29:22] Epoch 120/240, Loss: 32.872490, Train_MMSE: 0.067677, NMMSE: 0.081767, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:31:45] Epoch 121/240, Loss: 32.725613, Train_MMSE: 0.066474, NMMSE: 0.081744, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:34:06] Epoch 122/240, Loss: 32.843494, Train_MMSE: 0.066289, NMMSE: 0.081757, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:36:27] Epoch 123/240, Loss: 32.507191, Train_MMSE: 0.066242, NMMSE: 0.081946, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:38:47] Epoch 124/240, Loss: 32.717167, Train_MMSE: 0.066206, NMMSE: 0.081943, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:41:10] Epoch 125/240, Loss: 32.673733, Train_MMSE: 0.066184, NMMSE: 0.082038, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:43:32] Epoch 126/240, Loss: 32.688084, Train_MMSE: 0.066171, NMMSE: 0.082038, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:45:54] Epoch 127/240, Loss: 32.658138, Train_MMSE: 0.066147, NMMSE: 0.082032, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:48:15] Epoch 128/240, Loss: 32.581631, Train_MMSE: 0.066133, NMMSE: 0.082169, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:50:36] Epoch 129/240, Loss: 32.420643, Train_MMSE: 0.066119, NMMSE: 0.082121, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:52:56] Epoch 130/240, Loss: 32.874992, Train_MMSE: 0.0661, NMMSE: 0.082175, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:55:16] Epoch 131/240, Loss: 32.748077, Train_MMSE: 0.066096, NMMSE: 0.082124, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:57:37] Epoch 132/240, Loss: 32.493134, Train_MMSE: 0.06608, NMMSE: 0.082207, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 20:59:57] Epoch 133/240, Loss: 32.759499, Train_MMSE: 0.066073, NMMSE: 0.082264, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:02:19] Epoch 134/240, Loss: 32.647335, Train_MMSE: 0.066051, NMMSE: 0.082303, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:04:39] Epoch 135/240, Loss: 32.723911, Train_MMSE: 0.066045, NMMSE: 0.082218, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:07:00] Epoch 136/240, Loss: 32.551155, Train_MMSE: 0.066035, NMMSE: 0.082269, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:09:21] Epoch 137/240, Loss: 32.307312, Train_MMSE: 0.066024, NMMSE: 0.082291, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:11:41] Epoch 138/240, Loss: 32.751862, Train_MMSE: 0.066005, NMMSE: 0.082362, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:14:03] Epoch 139/240, Loss: 32.597454, Train_MMSE: 0.066002, NMMSE: 0.082448, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:16:26] Epoch 140/240, Loss: 32.388897, Train_MMSE: 0.065997, NMMSE: 0.082374, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:18:46] Epoch 141/240, Loss: 32.760773, Train_MMSE: 0.06598, NMMSE: 0.082489, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:21:07] Epoch 142/240, Loss: 32.359303, Train_MMSE: 0.065968, NMMSE: 0.082453, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:23:30] Epoch 143/240, Loss: 32.445560, Train_MMSE: 0.065962, NMMSE: 0.082429, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:25:52] Epoch 144/240, Loss: 32.402931, Train_MMSE: 0.065953, NMMSE: 0.082442, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:28:12] Epoch 145/240, Loss: 32.861519, Train_MMSE: 0.065936, NMMSE: 0.082424, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:30:33] Epoch 146/240, Loss: 32.473347, Train_MMSE: 0.065938, NMMSE: 0.082498, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:32:55] Epoch 147/240, Loss: 32.599789, Train_MMSE: 0.065924, NMMSE: 0.08256, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:35:16] Epoch 148/240, Loss: 32.731964, Train_MMSE: 0.065918, NMMSE: 0.082513, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:37:35] Epoch 149/240, Loss: 31.991699, Train_MMSE: 0.065901, NMMSE: 0.082556, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:39:57] Epoch 150/240, Loss: 32.489700, Train_MMSE: 0.065892, NMMSE: 0.08255, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:42:19] Epoch 151/240, Loss: 32.639240, Train_MMSE: 0.065888, NMMSE: 0.082547, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:44:40] Epoch 152/240, Loss: 32.611073, Train_MMSE: 0.065875, NMMSE: 0.08256, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:47:01] Epoch 153/240, Loss: 32.517143, Train_MMSE: 0.065867, NMMSE: 0.082554, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:49:23] Epoch 154/240, Loss: 32.613441, Train_MMSE: 0.065861, NMMSE: 0.082639, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:51:46] Epoch 155/240, Loss: 32.121372, Train_MMSE: 0.065853, NMMSE: 0.08267, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:54:07] Epoch 156/240, Loss: 32.241657, Train_MMSE: 0.065845, NMMSE: 0.082657, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:56:30] Epoch 157/240, Loss: 32.036186, Train_MMSE: 0.065835, NMMSE: 0.082618, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 21:58:50] Epoch 158/240, Loss: 32.422630, Train_MMSE: 0.065826, NMMSE: 0.082692, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:01:11] Epoch 159/240, Loss: 32.467613, Train_MMSE: 0.065818, NMMSE: 0.082655, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:03:33] Epoch 160/240, Loss: 32.218536, Train_MMSE: 0.06581, NMMSE: 0.082768, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:05:54] Epoch 161/240, Loss: 32.601318, Train_MMSE: 0.065801, NMMSE: 0.082704, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:08:16] Epoch 162/240, Loss: 32.362217, Train_MMSE: 0.065795, NMMSE: 0.082733, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:10:37] Epoch 163/240, Loss: 32.480412, Train_MMSE: 0.065783, NMMSE: 0.082669, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:12:58] Epoch 164/240, Loss: 32.386490, Train_MMSE: 0.065778, NMMSE: 0.082785, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:15:19] Epoch 165/240, Loss: 32.444214, Train_MMSE: 0.065767, NMMSE: 0.082723, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:17:41] Epoch 166/240, Loss: 32.371449, Train_MMSE: 0.065764, NMMSE: 0.08273, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:20:02] Epoch 167/240, Loss: 32.483284, Train_MMSE: 0.065753, NMMSE: 0.082751, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:22:24] Epoch 168/240, Loss: 32.688530, Train_MMSE: 0.065745, NMMSE: 0.082807, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:24:46] Epoch 169/240, Loss: 32.355949, Train_MMSE: 0.065733, NMMSE: 0.082801, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:27:07] Epoch 170/240, Loss: 32.743759, Train_MMSE: 0.065726, NMMSE: 0.082865, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:29:29] Epoch 171/240, Loss: 32.086304, Train_MMSE: 0.065723, NMMSE: 0.082885, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:31:49] Epoch 172/240, Loss: 32.570606, Train_MMSE: 0.065717, NMMSE: 0.082874, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:34:12] Epoch 173/240, Loss: 32.493351, Train_MMSE: 0.065708, NMMSE: 0.082872, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:36:34] Epoch 174/240, Loss: 32.375660, Train_MMSE: 0.065703, NMMSE: 0.08294, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:38:54] Epoch 175/240, Loss: 32.419964, Train_MMSE: 0.0657, NMMSE: 0.08286, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:41:16] Epoch 176/240, Loss: 32.106403, Train_MMSE: 0.065692, NMMSE: 0.082903, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:43:37] Epoch 177/240, Loss: 32.294422, Train_MMSE: 0.065675, NMMSE: 0.082966, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:46:00] Epoch 178/240, Loss: 32.395504, Train_MMSE: 0.06567, NMMSE: 0.082894, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:48:21] Epoch 179/240, Loss: 32.547199, Train_MMSE: 0.065664, NMMSE: 0.082917, LS_NMSE: 0.234713, Lr: 1e-05
[2025-02-24 22:50:41] Epoch 180/240, Loss: 32.458565, Train_MMSE: 0.065667, NMMSE: 0.082958, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 22:53:04] Epoch 181/240, Loss: 32.009449, Train_MMSE: 0.065489, NMMSE: 0.083062, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 22:55:25] Epoch 182/240, Loss: 32.280701, Train_MMSE: 0.065479, NMMSE: 0.082948, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 22:57:47] Epoch 183/240, Loss: 32.128620, Train_MMSE: 0.065473, NMMSE: 0.082932, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:00:09] Epoch 184/240, Loss: 32.321026, Train_MMSE: 0.065475, NMMSE: 0.082998, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:02:30] Epoch 185/240, Loss: 32.454590, Train_MMSE: 0.06547, NMMSE: 0.083021, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:04:53] Epoch 186/240, Loss: 32.285393, Train_MMSE: 0.065472, NMMSE: 0.082934, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:07:12] Epoch 187/240, Loss: 32.244423, Train_MMSE: 0.065473, NMMSE: 0.083082, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:09:34] Epoch 188/240, Loss: 32.338516, Train_MMSE: 0.06547, NMMSE: 0.082987, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:11:57] Epoch 189/240, Loss: 32.354012, Train_MMSE: 0.065462, NMMSE: 0.083024, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:14:18] Epoch 190/240, Loss: 32.224667, Train_MMSE: 0.065465, NMMSE: 0.083049, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:16:41] Epoch 191/240, Loss: 32.336872, Train_MMSE: 0.065467, NMMSE: 0.082987, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:19:02] Epoch 192/240, Loss: 32.498020, Train_MMSE: 0.065464, NMMSE: 0.083011, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:21:24] Epoch 193/240, Loss: 32.437424, Train_MMSE: 0.065463, NMMSE: 0.083076, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:23:47] Epoch 194/240, Loss: 32.458755, Train_MMSE: 0.065464, NMMSE: 0.083023, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:26:08] Epoch 195/240, Loss: 32.276455, Train_MMSE: 0.065462, NMMSE: 0.082966, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:28:28] Epoch 196/240, Loss: 32.569225, Train_MMSE: 0.065459, NMMSE: 0.083015, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:30:52] Epoch 197/240, Loss: 32.512371, Train_MMSE: 0.065458, NMMSE: 0.083043, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:33:15] Epoch 198/240, Loss: 32.651665, Train_MMSE: 0.06546, NMMSE: 0.083063, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:35:38] Epoch 199/240, Loss: 32.356445, Train_MMSE: 0.065456, NMMSE: 0.083, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:37:58] Epoch 200/240, Loss: 32.508503, Train_MMSE: 0.065454, NMMSE: 0.082969, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:40:21] Epoch 201/240, Loss: 32.291897, Train_MMSE: 0.065458, NMMSE: 0.083073, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:42:43] Epoch 202/240, Loss: 32.334892, Train_MMSE: 0.065458, NMMSE: 0.083029, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:45:03] Epoch 203/240, Loss: 32.332603, Train_MMSE: 0.065454, NMMSE: 0.083059, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:47:25] Epoch 204/240, Loss: 32.342865, Train_MMSE: 0.065451, NMMSE: 0.083026, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:49:48] Epoch 205/240, Loss: 32.755398, Train_MMSE: 0.065457, NMMSE: 0.082989, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:52:09] Epoch 206/240, Loss: 32.457485, Train_MMSE: 0.065454, NMMSE: 0.083019, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:54:33] Epoch 207/240, Loss: 32.045025, Train_MMSE: 0.06545, NMMSE: 0.083082, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:56:55] Epoch 208/240, Loss: 32.620987, Train_MMSE: 0.065448, NMMSE: 0.083044, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-24 23:59:16] Epoch 209/240, Loss: 32.264912, Train_MMSE: 0.065451, NMMSE: 0.083045, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:01:37] Epoch 210/240, Loss: 32.398930, Train_MMSE: 0.065454, NMMSE: 0.083013, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:03:59] Epoch 211/240, Loss: 32.247490, Train_MMSE: 0.065452, NMMSE: 0.083006, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:06:21] Epoch 212/240, Loss: 32.205105, Train_MMSE: 0.065447, NMMSE: 0.082986, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:08:42] Epoch 213/240, Loss: 32.327534, Train_MMSE: 0.065448, NMMSE: 0.083013, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:11:03] Epoch 214/240, Loss: 32.344269, Train_MMSE: 0.065453, NMMSE: 0.083034, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:13:25] Epoch 215/240, Loss: 32.082050, Train_MMSE: 0.065448, NMMSE: 0.08306, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:15:47] Epoch 216/240, Loss: 32.247608, Train_MMSE: 0.06544, NMMSE: 0.083097, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:18:09] Epoch 217/240, Loss: 31.995646, Train_MMSE: 0.065447, NMMSE: 0.083043, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:20:31] Epoch 218/240, Loss: 32.326500, Train_MMSE: 0.065444, NMMSE: 0.083082, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:22:53] Epoch 219/240, Loss: 32.418846, Train_MMSE: 0.065445, NMMSE: 0.083053, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:25:16] Epoch 220/240, Loss: 32.448112, Train_MMSE: 0.065444, NMMSE: 0.083116, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:27:38] Epoch 221/240, Loss: 32.326202, Train_MMSE: 0.065443, NMMSE: 0.083064, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:29:58] Epoch 222/240, Loss: 32.193611, Train_MMSE: 0.06544, NMMSE: 0.083037, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:32:21] Epoch 223/240, Loss: 32.257778, Train_MMSE: 0.065439, NMMSE: 0.08307, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:34:43] Epoch 224/240, Loss: 32.275215, Train_MMSE: 0.065432, NMMSE: 0.083154, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:37:04] Epoch 225/240, Loss: 32.381481, Train_MMSE: 0.065437, NMMSE: 0.083098, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:39:27] Epoch 226/240, Loss: 32.665791, Train_MMSE: 0.065436, NMMSE: 0.083081, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:41:49] Epoch 227/240, Loss: 32.729851, Train_MMSE: 0.065436, NMMSE: 0.08305, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:44:12] Epoch 228/240, Loss: 32.247944, Train_MMSE: 0.065435, NMMSE: 0.083074, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:46:34] Epoch 229/240, Loss: 32.444016, Train_MMSE: 0.06543, NMMSE: 0.08301, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:48:55] Epoch 230/240, Loss: 32.180855, Train_MMSE: 0.065429, NMMSE: 0.083052, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:51:20] Epoch 231/240, Loss: 32.374866, Train_MMSE: 0.065432, NMMSE: 0.083072, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:53:41] Epoch 232/240, Loss: 32.459282, Train_MMSE: 0.065428, NMMSE: 0.083061, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:56:01] Epoch 233/240, Loss: 32.678761, Train_MMSE: 0.065427, NMMSE: 0.083089, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 00:58:25] Epoch 234/240, Loss: 32.375946, Train_MMSE: 0.065432, NMMSE: 0.083154, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 01:00:45] Epoch 235/240, Loss: 32.375874, Train_MMSE: 0.065429, NMMSE: 0.083103, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 01:03:06] Epoch 236/240, Loss: 32.182388, Train_MMSE: 0.065431, NMMSE: 0.083142, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 01:05:29] Epoch 237/240, Loss: 32.427265, Train_MMSE: 0.06543, NMMSE: 0.083088, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 01:07:51] Epoch 238/240, Loss: 32.001476, Train_MMSE: 0.065432, NMMSE: 0.083071, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 01:10:13] Epoch 239/240, Loss: 32.618855, Train_MMSE: 0.065426, NMMSE: 0.083037, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-06
[2025-02-25 01:12:35] Epoch 240/240, Loss: 32.245449, Train_MMSE: 0.06542, NMMSE: 0.083031, LS_NMSE: 0.234713, Lr: 1.0000000000000002e-07
