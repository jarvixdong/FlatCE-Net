H shape: (10000, 4, 36) (10000, 4, 36)
NMMSE of valid dataset:: 0.055706420795849976
num samples :: 100000
num valid: 10000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/train_Dataset_dB-10_N36_K4_L2_S9_Setup100_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/test_Dataset_dB-10_N36_K4_L2_S9_Setup10_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}, 'trainer': {'optimizer': 'SGD', 'lr': 0.001, 'weight_decay': 0.001, 'lr_scheduler': 'Plateau', 'lr_gamma': 0.1, 'min_lr': 1e-06, 'patience': 5}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 5.95 MB
loss function:: L1Loss()
[2025-02-21 20:34:49] Epoch 1/100, Loss: 66.650177, Train_MMSE: 0.278577, NMMSE: 0.241862, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:35:01] Epoch 2/100, Loss: 65.570107, Train_MMSE: 0.275512, NMMSE: 0.235847, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:35:13] Epoch 3/100, Loss: 64.874649, Train_MMSE: 0.266145, NMMSE: 0.226009, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:35:25] Epoch 4/100, Loss: 62.873814, Train_MMSE: 0.253824, NMMSE: 0.214545, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:35:38] Epoch 5/100, Loss: 60.316727, Train_MMSE: 0.240182, NMMSE: 0.20288, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:35:54] Epoch 6/100, Loss: 59.775566, Train_MMSE: 0.226507, NMMSE: 0.192035, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:36:12] Epoch 7/100, Loss: 56.869083, Train_MMSE: 0.212765, NMMSE: 0.180564, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:36:34] Epoch 8/100, Loss: 55.673508, Train_MMSE: 0.199093, NMMSE: 0.169734, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:36:56] Epoch 9/100, Loss: 53.729141, Train_MMSE: 0.187185, NMMSE: 0.161512, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:37:19] Epoch 10/100, Loss: 53.035572, Train_MMSE: 0.178111, NMMSE: 0.155456, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:37:42] Epoch 11/100, Loss: 51.943817, Train_MMSE: 0.171561, NMMSE: 0.150862, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:38:04] Epoch 12/100, Loss: 50.931168, Train_MMSE: 0.166554, NMMSE: 0.147121, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:38:26] Epoch 13/100, Loss: 50.877201, Train_MMSE: 0.162506, NMMSE: 0.144351, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:38:48] Epoch 14/100, Loss: 50.014172, Train_MMSE: 0.158732, NMMSE: 0.141654, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:39:11] Epoch 15/100, Loss: 49.383213, Train_MMSE: 0.155075, NMMSE: 0.137879, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:39:33] Epoch 16/100, Loss: 48.871704, Train_MMSE: 0.151689, NMMSE: 0.135021, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:39:55] Epoch 17/100, Loss: 48.458553, Train_MMSE: 0.148759, NMMSE: 0.132705, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:40:17] Epoch 18/100, Loss: 48.238464, Train_MMSE: 0.146, NMMSE: 0.130919, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:40:39] Epoch 19/100, Loss: 47.407684, Train_MMSE: 0.143555, NMMSE: 0.129411, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:41:02] Epoch 20/100, Loss: 47.293056, Train_MMSE: 0.141323, NMMSE: 0.127532, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:41:24] Epoch 21/100, Loss: 47.223652, Train_MMSE: 0.13896, NMMSE: 0.125972, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:41:47] Epoch 22/100, Loss: 46.383316, Train_MMSE: 0.13662, NMMSE: 0.123806, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:42:10] Epoch 23/100, Loss: 46.044582, Train_MMSE: 0.134431, NMMSE: 0.122577, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:42:32] Epoch 24/100, Loss: 45.683472, Train_MMSE: 0.132148, NMMSE: 0.120565, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:42:55] Epoch 25/100, Loss: 45.340446, Train_MMSE: 0.129999, NMMSE: 0.118415, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:43:17] Epoch 26/100, Loss: 44.859043, Train_MMSE: 0.127856, NMMSE: 0.116138, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:43:39] Epoch 27/100, Loss: 44.482170, Train_MMSE: 0.125482, NMMSE: 0.114287, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:44:02] Epoch 28/100, Loss: 43.983921, Train_MMSE: 0.123195, NMMSE: 0.112818, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:44:25] Epoch 29/100, Loss: 43.748978, Train_MMSE: 0.120884, NMMSE: 0.110843, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:44:47] Epoch 30/100, Loss: 43.629726, Train_MMSE: 0.118552, NMMSE: 0.109581, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:45:10] Epoch 31/100, Loss: 43.437187, Train_MMSE: 0.116558, NMMSE: 0.107118, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:45:32] Epoch 32/100, Loss: 42.419731, Train_MMSE: 0.114621, NMMSE: 0.105923, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:45:55] Epoch 33/100, Loss: 41.995949, Train_MMSE: 0.112961, NMMSE: 0.104316, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:46:17] Epoch 34/100, Loss: 42.042011, Train_MMSE: 0.111647, NMMSE: 0.103577, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:46:40] Epoch 35/100, Loss: 42.023010, Train_MMSE: 0.110305, NMMSE: 0.102598, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:47:02] Epoch 36/100, Loss: 41.888329, Train_MMSE: 0.109172, NMMSE: 0.101384, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:47:25] Epoch 37/100, Loss: 41.332623, Train_MMSE: 0.108065, NMMSE: 0.101363, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:47:47] Epoch 38/100, Loss: 40.999504, Train_MMSE: 0.107293, NMMSE: 0.100394, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:48:09] Epoch 39/100, Loss: 41.442669, Train_MMSE: 0.106428, NMMSE: 0.099866, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:48:32] Epoch 40/100, Loss: 40.981586, Train_MMSE: 0.105797, NMMSE: 0.100066, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:48:55] Epoch 41/100, Loss: 40.652039, Train_MMSE: 0.105058, NMMSE: 0.099072, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:49:17] Epoch 42/100, Loss: 40.820736, Train_MMSE: 0.10436, NMMSE: 0.097976, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:49:40] Epoch 43/100, Loss: 40.496601, Train_MMSE: 0.103809, NMMSE: 0.097493, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:50:02] Epoch 44/100, Loss: 40.528606, Train_MMSE: 0.103276, NMMSE: 0.097396, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:50:25] Epoch 45/100, Loss: 40.457779, Train_MMSE: 0.102678, NMMSE: 0.096828, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:50:47] Epoch 46/100, Loss: 39.881397, Train_MMSE: 0.10229, NMMSE: 0.096471, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:51:09] Epoch 47/100, Loss: 40.073887, Train_MMSE: 0.101751, NMMSE: 0.096251, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:51:31] Epoch 48/100, Loss: 39.671822, Train_MMSE: 0.101353, NMMSE: 0.09635, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:51:53] Epoch 49/100, Loss: 40.054321, Train_MMSE: 0.10103, NMMSE: 0.095474, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:52:15] Epoch 50/100, Loss: 39.491768, Train_MMSE: 0.100522, NMMSE: 0.095375, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:52:37] Epoch 51/100, Loss: 39.504433, Train_MMSE: 0.100219, NMMSE: 0.096067, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:52:59] Epoch 52/100, Loss: 39.580582, Train_MMSE: 0.099841, NMMSE: 0.095556, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:53:21] Epoch 53/100, Loss: 40.006462, Train_MMSE: 0.099533, NMMSE: 0.095059, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:53:43] Epoch 54/100, Loss: 39.577244, Train_MMSE: 0.099245, NMMSE: 0.09512, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 20:54:05] Epoch 55/100, Loss: 39.599583, Train_MMSE: 0.098946, NMMSE: 0.094547, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:54:28] Epoch 56/100, Loss: 39.214153, Train_MMSE: 0.096644, NMMSE: 0.092527, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:54:50] Epoch 57/100, Loss: 38.845871, Train_MMSE: 0.096343, NMMSE: 0.092549, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:55:12] Epoch 58/100, Loss: 38.804371, Train_MMSE: 0.096241, NMMSE: 0.092503, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:55:34] Epoch 59/100, Loss: 38.803337, Train_MMSE: 0.096179, NMMSE: 0.092489, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:55:58] Epoch 60/100, Loss: 38.912403, Train_MMSE: 0.096133, NMMSE: 0.092537, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:56:24] Epoch 61/100, Loss: 38.643509, Train_MMSE: 0.096068, NMMSE: 0.092483, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 20:56:51] Epoch 62/100, Loss: 38.772087, Train_MMSE: 0.096012, NMMSE: 0.092481, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 20:57:22] Epoch 63/100, Loss: 38.641102, Train_MMSE: 0.09578, NMMSE: 0.092359, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 20:57:53] Epoch 64/100, Loss: 38.614090, Train_MMSE: 0.095741, NMMSE: 0.092356, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 20:58:24] Epoch 65/100, Loss: 38.755116, Train_MMSE: 0.095734, NMMSE: 0.092345, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 20:58:55] Epoch 66/100, Loss: 38.434746, Train_MMSE: 0.095718, NMMSE: 0.092351, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 20:59:26] Epoch 67/100, Loss: 38.532612, Train_MMSE: 0.095719, NMMSE: 0.092342, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 20:59:58] Epoch 68/100, Loss: 38.752632, Train_MMSE: 0.09571, NMMSE: 0.092347, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:00:32] Epoch 69/100, Loss: 38.283699, Train_MMSE: 0.095686, NMMSE: 0.092337, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:01:07] Epoch 70/100, Loss: 38.646160, Train_MMSE: 0.095678, NMMSE: 0.092341, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:01:43] Epoch 71/100, Loss: 38.672527, Train_MMSE: 0.095683, NMMSE: 0.092344, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:02:28] Epoch 72/100, Loss: 38.962505, Train_MMSE: 0.095681, NMMSE: 0.092343, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:03:17] Epoch 73/100, Loss: 39.128452, Train_MMSE: 0.095677, NMMSE: 0.092337, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:04:07] Epoch 74/100, Loss: 38.646633, Train_MMSE: 0.095683, NMMSE: 0.09235, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:04:58] Epoch 75/100, Loss: 38.720943, Train_MMSE: 0.095686, NMMSE: 0.092336, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:05:48] Epoch 76/100, Loss: 38.637501, Train_MMSE: 0.095674, NMMSE: 0.092342, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:06:44] Epoch 77/100, Loss: 38.561394, Train_MMSE: 0.095684, NMMSE: 0.092331, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:07:46] Epoch 78/100, Loss: 38.869144, Train_MMSE: 0.095677, NMMSE: 0.092335, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:08:47] Epoch 79/100, Loss: 39.073841, Train_MMSE: 0.095677, NMMSE: 0.09234, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:09:49] Epoch 80/100, Loss: 38.772003, Train_MMSE: 0.095679, NMMSE: 0.092349, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:10:52] Epoch 81/100, Loss: 38.647343, Train_MMSE: 0.095672, NMMSE: 0.092341, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:11:56] Epoch 82/100, Loss: 38.928360, Train_MMSE: 0.095674, NMMSE: 0.092343, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:12:57] Epoch 83/100, Loss: 38.411854, Train_MMSE: 0.095665, NMMSE: 0.092336, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:14:00] Epoch 84/100, Loss: 38.211777, Train_MMSE: 0.095686, NMMSE: 0.092336, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:15:02] Epoch 85/100, Loss: 38.426105, Train_MMSE: 0.095677, NMMSE: 0.09234, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:16:03] Epoch 86/100, Loss: 38.521801, Train_MMSE: 0.095664, NMMSE: 0.092341, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:17:06] Epoch 87/100, Loss: 38.525757, Train_MMSE: 0.095672, NMMSE: 0.092346, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:18:07] Epoch 88/100, Loss: 38.455135, Train_MMSE: 0.095667, NMMSE: 0.092342, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:19:09] Epoch 89/100, Loss: 38.696270, Train_MMSE: 0.095672, NMMSE: 0.092348, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:20:13] Epoch 90/100, Loss: 38.758636, Train_MMSE: 0.09567, NMMSE: 0.092347, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:21:15] Epoch 91/100, Loss: 38.562878, Train_MMSE: 0.095676, NMMSE: 0.092343, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:22:17] Epoch 92/100, Loss: 39.003494, Train_MMSE: 0.095678, NMMSE: 0.09234, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:23:18] Epoch 93/100, Loss: 38.685696, Train_MMSE: 0.095668, NMMSE: 0.092348, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:24:19] Epoch 94/100, Loss: 38.357437, Train_MMSE: 0.09567, NMMSE: 0.092349, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:25:21] Epoch 95/100, Loss: 38.766628, Train_MMSE: 0.095668, NMMSE: 0.092348, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:26:23] Epoch 96/100, Loss: 38.877144, Train_MMSE: 0.095665, NMMSE: 0.092328, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:27:25] Epoch 97/100, Loss: 38.506245, Train_MMSE: 0.095669, NMMSE: 0.092332, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:28:28] Epoch 98/100, Loss: 38.491272, Train_MMSE: 0.095675, NMMSE: 0.092333, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:29:30] Epoch 99/100, Loss: 38.728825, Train_MMSE: 0.095665, NMMSE: 0.092332, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:30:31] Epoch 100/100, Loss: 38.801556, Train_MMSE: 0.095669, NMMSE: 0.092341, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
