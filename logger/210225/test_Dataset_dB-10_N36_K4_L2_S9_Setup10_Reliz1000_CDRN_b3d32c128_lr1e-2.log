H shape: (10000, 4, 36) (10000, 4, 36)
NMMSE of valid dataset:: 0.055706420795849976
num samples :: 100000
num valid: 10000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/train_Dataset_dB-10_N36_K4_L2_S9_Setup100_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/test_Dataset_dB-10_N36_K4_L2_S9_Setup10_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 64, 'num_layers': 3}, 'logger': {'path': None}, 'trainer': {'optimizer': 'SGD', 'lr': 0.01, 'weight_decay': 0.001, 'lr_scheduler': 'Plateau', 'lr_gamma': 0.1, 'min_lr': 1e-06, 'patience': 20}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 23.72 MB
loss function:: L1Loss()
[2025-02-21 21:07:47] Epoch 1/150, Loss: 53.072052, Train_MMSE: 0.227905, NMMSE: 0.155024, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:08:29] Epoch 2/150, Loss: 48.508350, Train_MMSE: 0.158552, NMMSE: 0.13063, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:09:11] Epoch 3/150, Loss: 43.213051, Train_MMSE: 0.129747, NMMSE: 0.105976, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:09:54] Epoch 4/150, Loss: 41.166946, Train_MMSE: 0.109586, NMMSE: 0.097403, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:10:36] Epoch 5/150, Loss: 40.005741, Train_MMSE: 0.102863, NMMSE: 0.093834, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:11:19] Epoch 6/150, Loss: 39.472427, Train_MMSE: 0.099287, NMMSE: 0.092576, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:12:02] Epoch 7/150, Loss: 38.944870, Train_MMSE: 0.096773, NMMSE: 0.092029, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:12:40] Epoch 8/150, Loss: 38.654011, Train_MMSE: 0.094935, NMMSE: 0.09102, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:13:15] Epoch 9/150, Loss: 38.408264, Train_MMSE: 0.093341, NMMSE: 0.090455, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:13:51] Epoch 10/150, Loss: 38.120850, Train_MMSE: 0.092139, NMMSE: 0.090134, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:14:26] Epoch 11/150, Loss: 38.046265, Train_MMSE: 0.090964, NMMSE: 0.090685, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:15:01] Epoch 12/150, Loss: 37.557552, Train_MMSE: 0.089926, NMMSE: 0.090529, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:15:37] Epoch 13/150, Loss: 37.372543, Train_MMSE: 0.08885, NMMSE: 0.090678, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:16:13] Epoch 14/150, Loss: 37.207474, Train_MMSE: 0.087922, NMMSE: 0.090641, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:16:47] Epoch 15/150, Loss: 36.886822, Train_MMSE: 0.086954, NMMSE: 0.091201, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:17:23] Epoch 16/150, Loss: 36.884861, Train_MMSE: 0.086052, NMMSE: 0.091175, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:17:58] Epoch 17/150, Loss: 37.108170, Train_MMSE: 0.085197, NMMSE: 0.091946, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:18:34] Epoch 18/150, Loss: 36.606056, Train_MMSE: 0.084349, NMMSE: 0.092036, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:19:09] Epoch 19/150, Loss: 36.332516, Train_MMSE: 0.083426, NMMSE: 0.092549, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:19:44] Epoch 20/150, Loss: 35.916027, Train_MMSE: 0.082604, NMMSE: 0.093081, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:20:20] Epoch 21/150, Loss: 35.981358, Train_MMSE: 0.081834, NMMSE: 0.094143, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:20:55] Epoch 22/150, Loss: 36.062061, Train_MMSE: 0.080979, NMMSE: 0.094293, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:21:31] Epoch 23/150, Loss: 35.884308, Train_MMSE: 0.080196, NMMSE: 0.094583, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:22:07] Epoch 24/150, Loss: 34.928703, Train_MMSE: 0.079455, NMMSE: 0.095419, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:22:42] Epoch 25/150, Loss: 35.202747, Train_MMSE: 0.078605, NMMSE: 0.095378, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:23:17] Epoch 26/150, Loss: 35.051105, Train_MMSE: 0.07793, NMMSE: 0.095081, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:23:52] Epoch 27/150, Loss: 35.003273, Train_MMSE: 0.077192, NMMSE: 0.095942, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:24:27] Epoch 28/150, Loss: 34.508564, Train_MMSE: 0.076495, NMMSE: 0.095807, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-21 21:25:03] Epoch 29/150, Loss: 34.725254, Train_MMSE: 0.075772, NMMSE: 0.096, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:25:39] Epoch 30/150, Loss: 31.842920, Train_MMSE: 0.067779, NMMSE: 0.096314, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:26:15] Epoch 31/150, Loss: 31.323900, Train_MMSE: 0.065097, NMMSE: 0.097136, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:26:50] Epoch 32/150, Loss: 30.993587, Train_MMSE: 0.063975, NMMSE: 0.097828, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:27:25] Epoch 33/150, Loss: 30.888615, Train_MMSE: 0.063171, NMMSE: 0.098587, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:28:01] Epoch 34/150, Loss: 30.950954, Train_MMSE: 0.062509, NMMSE: 0.098828, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:28:37] Epoch 35/150, Loss: 30.488272, Train_MMSE: 0.061938, NMMSE: 0.099084, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:29:12] Epoch 36/150, Loss: 30.425306, Train_MMSE: 0.061406, NMMSE: 0.100181, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:29:40] Epoch 37/150, Loss: 30.352058, Train_MMSE: 0.060928, NMMSE: 0.100373, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:30:08] Epoch 38/150, Loss: 29.952702, Train_MMSE: 0.060469, NMMSE: 0.100841, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:30:36] Epoch 39/150, Loss: 29.746677, Train_MMSE: 0.060043, NMMSE: 0.101109, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:31:04] Epoch 40/150, Loss: 29.973667, Train_MMSE: 0.059641, NMMSE: 0.101685, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:31:32] Epoch 41/150, Loss: 29.671198, Train_MMSE: 0.059258, NMMSE: 0.10192, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:32:00] Epoch 42/150, Loss: 29.611776, Train_MMSE: 0.058886, NMMSE: 0.102176, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:32:29] Epoch 43/150, Loss: 29.512642, Train_MMSE: 0.058527, NMMSE: 0.102593, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:32:57] Epoch 44/150, Loss: 29.415335, Train_MMSE: 0.05818, NMMSE: 0.103345, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:33:25] Epoch 45/150, Loss: 29.302111, Train_MMSE: 0.057854, NMMSE: 0.103387, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:33:53] Epoch 46/150, Loss: 29.128225, Train_MMSE: 0.057533, NMMSE: 0.104177, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:34:21] Epoch 47/150, Loss: 29.299173, Train_MMSE: 0.057227, NMMSE: 0.104402, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:34:49] Epoch 48/150, Loss: 28.841492, Train_MMSE: 0.056914, NMMSE: 0.104719, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:35:17] Epoch 49/150, Loss: 29.042402, Train_MMSE: 0.056628, NMMSE: 0.105167, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-21 21:35:45] Epoch 50/150, Loss: 28.943808, Train_MMSE: 0.056333, NMMSE: 0.105217, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:36:14] Epoch 51/150, Loss: 27.892694, Train_MMSE: 0.054468, NMMSE: 0.105725, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:36:42] Epoch 52/150, Loss: 27.785227, Train_MMSE: 0.054118, NMMSE: 0.105905, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:37:11] Epoch 53/150, Loss: 27.943972, Train_MMSE: 0.054003, NMMSE: 0.106049, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:37:43] Epoch 54/150, Loss: 27.865499, Train_MMSE: 0.053908, NMMSE: 0.106107, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:38:17] Epoch 55/150, Loss: 27.712906, Train_MMSE: 0.053849, NMMSE: 0.106289, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:38:54] Epoch 56/150, Loss: 27.693514, Train_MMSE: 0.053784, NMMSE: 0.106353, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:39:32] Epoch 57/150, Loss: 27.903698, Train_MMSE: 0.053733, NMMSE: 0.106428, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:40:08] Epoch 58/150, Loss: 27.756134, Train_MMSE: 0.053671, NMMSE: 0.106512, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:40:38] Epoch 59/150, Loss: 27.485901, Train_MMSE: 0.053629, NMMSE: 0.106589, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:41:09] Epoch 60/150, Loss: 27.716272, Train_MMSE: 0.053578, NMMSE: 0.106614, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:41:38] Epoch 61/150, Loss: 27.694780, Train_MMSE: 0.053538, NMMSE: 0.106844, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:42:08] Epoch 62/150, Loss: 27.639025, Train_MMSE: 0.053485, NMMSE: 0.106703, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:42:38] Epoch 63/150, Loss: 27.566969, Train_MMSE: 0.053451, NMMSE: 0.106762, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:43:08] Epoch 64/150, Loss: 27.444937, Train_MMSE: 0.053399, NMMSE: 0.106873, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:43:38] Epoch 65/150, Loss: 27.447781, Train_MMSE: 0.053358, NMMSE: 0.106921, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:44:07] Epoch 66/150, Loss: 27.693325, Train_MMSE: 0.053315, NMMSE: 0.107072, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:44:37] Epoch 67/150, Loss: 27.334908, Train_MMSE: 0.053273, NMMSE: 0.107142, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:45:07] Epoch 68/150, Loss: 27.616777, Train_MMSE: 0.053247, NMMSE: 0.107135, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:45:37] Epoch 69/150, Loss: 27.521410, Train_MMSE: 0.053198, NMMSE: 0.107153, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:46:07] Epoch 70/150, Loss: 27.571358, Train_MMSE: 0.053166, NMMSE: 0.107247, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-21 21:46:37] Epoch 71/150, Loss: 27.351160, Train_MMSE: 0.053112, NMMSE: 0.107369, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:47:07] Epoch 72/150, Loss: 27.502066, Train_MMSE: 0.052879, NMMSE: 0.107332, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:47:38] Epoch 73/150, Loss: 27.468452, Train_MMSE: 0.052863, NMMSE: 0.107417, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:48:09] Epoch 74/150, Loss: 27.164093, Train_MMSE: 0.052856, NMMSE: 0.107441, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:48:40] Epoch 75/150, Loss: 27.363472, Train_MMSE: 0.052845, NMMSE: 0.10744, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:49:10] Epoch 76/150, Loss: 27.205582, Train_MMSE: 0.052841, NMMSE: 0.107339, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:49:39] Epoch 77/150, Loss: 27.428036, Train_MMSE: 0.052836, NMMSE: 0.107475, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:50:12] Epoch 78/150, Loss: 27.311239, Train_MMSE: 0.052842, NMMSE: 0.107419, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:50:45] Epoch 79/150, Loss: 27.459534, Train_MMSE: 0.052826, NMMSE: 0.107505, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:51:22] Epoch 80/150, Loss: 27.466963, Train_MMSE: 0.052826, NMMSE: 0.107474, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:52:00] Epoch 81/150, Loss: 27.464264, Train_MMSE: 0.052825, NMMSE: 0.107416, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:52:37] Epoch 82/150, Loss: 27.401846, Train_MMSE: 0.052815, NMMSE: 0.107476, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:53:15] Epoch 83/150, Loss: 27.486664, Train_MMSE: 0.05282, NMMSE: 0.107488, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:53:52] Epoch 84/150, Loss: 27.144321, Train_MMSE: 0.05281, NMMSE: 0.107522, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:54:30] Epoch 85/150, Loss: 27.378845, Train_MMSE: 0.052812, NMMSE: 0.10748, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:55:07] Epoch 86/150, Loss: 27.421427, Train_MMSE: 0.052794, NMMSE: 0.107495, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:55:43] Epoch 87/150, Loss: 27.364481, Train_MMSE: 0.052801, NMMSE: 0.107541, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:56:22] Epoch 88/150, Loss: 27.439789, Train_MMSE: 0.0528, NMMSE: 0.107572, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:56:59] Epoch 89/150, Loss: 27.292202, Train_MMSE: 0.052796, NMMSE: 0.107568, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:57:36] Epoch 90/150, Loss: 27.180733, Train_MMSE: 0.052782, NMMSE: 0.107671, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:58:13] Epoch 91/150, Loss: 27.458704, Train_MMSE: 0.052784, NMMSE: 0.107501, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-21 21:58:51] Epoch 92/150, Loss: 27.140442, Train_MMSE: 0.052782, NMMSE: 0.107581, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 21:59:29] Epoch 93/150, Loss: 27.278803, Train_MMSE: 0.052755, NMMSE: 0.107486, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:00:05] Epoch 94/150, Loss: 27.414846, Train_MMSE: 0.052743, NMMSE: 0.107523, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:00:42] Epoch 95/150, Loss: 27.413300, Train_MMSE: 0.052743, NMMSE: 0.107571, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:01:20] Epoch 96/150, Loss: 27.350260, Train_MMSE: 0.052744, NMMSE: 0.107527, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:01:57] Epoch 97/150, Loss: 27.165794, Train_MMSE: 0.052743, NMMSE: 0.1075, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:02:34] Epoch 98/150, Loss: 27.150038, Train_MMSE: 0.052741, NMMSE: 0.107586, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:03:12] Epoch 99/150, Loss: 27.425755, Train_MMSE: 0.052744, NMMSE: 0.10764, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:03:50] Epoch 100/150, Loss: 27.335735, Train_MMSE: 0.052747, NMMSE: 0.107573, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:04:27] Epoch 101/150, Loss: 27.316948, Train_MMSE: 0.052744, NMMSE: 0.107527, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:05:04] Epoch 102/150, Loss: 27.423136, Train_MMSE: 0.052748, NMMSE: 0.107463, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:05:41] Epoch 103/150, Loss: 27.243357, Train_MMSE: 0.052741, NMMSE: 0.107483, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:06:19] Epoch 104/150, Loss: 27.465820, Train_MMSE: 0.05274, NMMSE: 0.107567, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:06:57] Epoch 105/150, Loss: 27.266964, Train_MMSE: 0.052741, NMMSE: 0.107503, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:07:35] Epoch 106/150, Loss: 27.238550, Train_MMSE: 0.052744, NMMSE: 0.107618, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:08:12] Epoch 107/150, Loss: 27.381437, Train_MMSE: 0.052746, NMMSE: 0.107575, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:08:50] Epoch 108/150, Loss: 27.270704, Train_MMSE: 0.052742, NMMSE: 0.107617, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:09:28] Epoch 109/150, Loss: 27.332270, Train_MMSE: 0.052738, NMMSE: 0.107635, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:10:06] Epoch 110/150, Loss: 27.403122, Train_MMSE: 0.052745, NMMSE: 0.107567, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:10:44] Epoch 111/150, Loss: 27.245550, Train_MMSE: 0.052743, NMMSE: 0.107581, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:11:21] Epoch 112/150, Loss: 27.181528, Train_MMSE: 0.052746, NMMSE: 0.10748, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:11:58] Epoch 113/150, Loss: 27.327082, Train_MMSE: 0.052739, NMMSE: 0.107547, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:12:35] Epoch 114/150, Loss: 27.274387, Train_MMSE: 0.052738, NMMSE: 0.107653, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:13:12] Epoch 115/150, Loss: 27.161076, Train_MMSE: 0.052743, NMMSE: 0.107616, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:13:49] Epoch 116/150, Loss: 27.375004, Train_MMSE: 0.052735, NMMSE: 0.10756, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:14:27] Epoch 117/150, Loss: 27.563135, Train_MMSE: 0.052748, NMMSE: 0.10758, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:15:05] Epoch 118/150, Loss: 27.355951, Train_MMSE: 0.052741, NMMSE: 0.107538, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:15:43] Epoch 119/150, Loss: 27.391132, Train_MMSE: 0.052738, NMMSE: 0.107543, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:16:20] Epoch 120/150, Loss: 27.409037, Train_MMSE: 0.052738, NMMSE: 0.107587, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:16:57] Epoch 121/150, Loss: 27.291136, Train_MMSE: 0.052731, NMMSE: 0.107622, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:17:35] Epoch 122/150, Loss: 27.437700, Train_MMSE: 0.052733, NMMSE: 0.10754, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:18:12] Epoch 123/150, Loss: 27.430128, Train_MMSE: 0.052739, NMMSE: 0.107533, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:18:49] Epoch 124/150, Loss: 27.225422, Train_MMSE: 0.052746, NMMSE: 0.107494, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:19:27] Epoch 125/150, Loss: 27.235891, Train_MMSE: 0.05273, NMMSE: 0.107534, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:20:05] Epoch 126/150, Loss: 27.474039, Train_MMSE: 0.052739, NMMSE: 0.10753, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:20:42] Epoch 127/150, Loss: 27.199890, Train_MMSE: 0.052736, NMMSE: 0.107613, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:21:20] Epoch 128/150, Loss: 27.180838, Train_MMSE: 0.052734, NMMSE: 0.107614, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:21:58] Epoch 129/150, Loss: 27.089870, Train_MMSE: 0.052737, NMMSE: 0.107556, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:22:35] Epoch 130/150, Loss: 27.084541, Train_MMSE: 0.052722, NMMSE: 0.10759, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:23:12] Epoch 131/150, Loss: 27.198521, Train_MMSE: 0.05273, NMMSE: 0.10752, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:23:52] Epoch 132/150, Loss: 27.467150, Train_MMSE: 0.052733, NMMSE: 0.107553, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:24:31] Epoch 133/150, Loss: 27.291378, Train_MMSE: 0.052733, NMMSE: 0.107523, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:25:10] Epoch 134/150, Loss: 27.423555, Train_MMSE: 0.052728, NMMSE: 0.107559, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:25:48] Epoch 135/150, Loss: 27.396715, Train_MMSE: 0.052734, NMMSE: 0.107551, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:26:28] Epoch 136/150, Loss: 27.450401, Train_MMSE: 0.052731, NMMSE: 0.107653, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:27:06] Epoch 137/150, Loss: 27.193529, Train_MMSE: 0.052734, NMMSE: 0.107562, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:27:45] Epoch 138/150, Loss: 27.187429, Train_MMSE: 0.052734, NMMSE: 0.107579, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:28:23] Epoch 139/150, Loss: 27.306273, Train_MMSE: 0.052729, NMMSE: 0.107662, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:29:05] Epoch 140/150, Loss: 27.129236, Train_MMSE: 0.052732, NMMSE: 0.107565, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:29:50] Epoch 141/150, Loss: 27.157568, Train_MMSE: 0.052722, NMMSE: 0.107533, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:30:34] Epoch 142/150, Loss: 27.393963, Train_MMSE: 0.052736, NMMSE: 0.107615, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:31:20] Epoch 143/150, Loss: 27.258886, Train_MMSE: 0.052727, NMMSE: 0.107637, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:32:05] Epoch 144/150, Loss: 27.315933, Train_MMSE: 0.052733, NMMSE: 0.107588, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:32:48] Epoch 145/150, Loss: 27.270491, Train_MMSE: 0.052731, NMMSE: 0.107531, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:33:34] Epoch 146/150, Loss: 27.170767, Train_MMSE: 0.052727, NMMSE: 0.107558, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:34:20] Epoch 147/150, Loss: 27.272282, Train_MMSE: 0.052728, NMMSE: 0.107565, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:35:06] Epoch 148/150, Loss: 27.335732, Train_MMSE: 0.052725, NMMSE: 0.107591, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:35:51] Epoch 149/150, Loss: 27.278278, Train_MMSE: 0.052725, NMMSE: 0.107635, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
[2025-02-21 22:36:36] Epoch 150/150, Loss: 27.387791, Train_MMSE: 0.052726, NMMSE: 0.107615, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
