H shape: (10000, 4, 36) (10000, 4, 36)
NMMSE of valid dataset:: 0.055706420795849976
num samples :: 100000
num valid: 10000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/train_Dataset_dB-10_N36_K4_L2_S9_Setup100_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/test_Dataset_dB-10_N36_K4_L2_S9_Setup10_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}, 'trainer': {'optimizer': 'Adam', 'lr': 0.01, 'weight_decay': 0.001, 'lr_scheduler': 'Plateau', 'lr_gamma': 0.1, 'min_lr': 1e-06, 'patience': 20}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (47): ReLU(inplace=True)
      (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (50): ReLU(inplace=True)
      (51): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 6.80 MB
loss function:: L1Loss()
[2025-02-22 18:13:14] Epoch 1/200, Loss: 52.966358, Train_MMSE: 0.21667, NMMSE: 0.170165, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:14:15] Epoch 2/200, Loss: 44.558754, Train_MMSE: 0.145925, NMMSE: 0.120937, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:15:12] Epoch 3/200, Loss: 41.069736, Train_MMSE: 0.113033, NMMSE: 0.099582, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:16:10] Epoch 4/200, Loss: 39.871937, Train_MMSE: 0.102828, NMMSE: 0.095451, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:17:10] Epoch 5/200, Loss: 40.141914, Train_MMSE: 0.099443, NMMSE: 0.092247, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:18:07] Epoch 6/200, Loss: 38.900406, Train_MMSE: 0.097764, NMMSE: 0.09176, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:19:05] Epoch 7/200, Loss: 39.235123, Train_MMSE: 0.09676, NMMSE: 0.088478, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:20:05] Epoch 8/200, Loss: 38.982746, Train_MMSE: 0.095988, NMMSE: 0.089751, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:21:05] Epoch 9/200, Loss: 38.937923, Train_MMSE: 0.095619, NMMSE: 0.088231, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:22:04] Epoch 10/200, Loss: 39.177292, Train_MMSE: 0.095232, NMMSE: 0.088051, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:23:02] Epoch 11/200, Loss: 38.779320, Train_MMSE: 0.094941, NMMSE: 0.088694, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:23:59] Epoch 12/200, Loss: 38.638416, Train_MMSE: 0.094694, NMMSE: 0.087448, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:24:58] Epoch 13/200, Loss: 38.911331, Train_MMSE: 0.094455, NMMSE: 0.086899, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:25:57] Epoch 14/200, Loss: 38.889099, Train_MMSE: 0.094371, NMMSE: 0.088133, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:26:54] Epoch 15/200, Loss: 39.073307, Train_MMSE: 0.094163, NMMSE: 0.087346, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:27:52] Epoch 16/200, Loss: 38.385666, Train_MMSE: 0.094037, NMMSE: 0.088727, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:28:51] Epoch 17/200, Loss: 38.472187, Train_MMSE: 0.093921, NMMSE: 0.086715, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:29:49] Epoch 18/200, Loss: 38.037174, Train_MMSE: 0.09374, NMMSE: 0.087602, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:30:48] Epoch 19/200, Loss: 38.381546, Train_MMSE: 0.093655, NMMSE: 0.08903, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:31:47] Epoch 20/200, Loss: 38.389301, Train_MMSE: 0.093553, NMMSE: 0.088102, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:32:45] Epoch 21/200, Loss: 38.457092, Train_MMSE: 0.09358, NMMSE: 0.086269, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:33:44] Epoch 22/200, Loss: 38.432758, Train_MMSE: 0.093449, NMMSE: 0.087173, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:34:42] Epoch 23/200, Loss: 38.518806, Train_MMSE: 0.093302, NMMSE: 0.086869, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:35:41] Epoch 24/200, Loss: 38.276581, Train_MMSE: 0.093445, NMMSE: 0.087374, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:36:41] Epoch 25/200, Loss: 38.490746, Train_MMSE: 0.093247, NMMSE: 0.086429, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:37:41] Epoch 26/200, Loss: 38.293930, Train_MMSE: 0.09324, NMMSE: 0.086497, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:38:40] Epoch 27/200, Loss: 38.578007, Train_MMSE: 0.09312, NMMSE: 0.087403, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:39:38] Epoch 28/200, Loss: 38.717182, Train_MMSE: 0.093084, NMMSE: 0.088084, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:40:35] Epoch 29/200, Loss: 38.154682, Train_MMSE: 0.093138, NMMSE: 0.087038, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:41:35] Epoch 30/200, Loss: 38.786427, Train_MMSE: 0.092955, NMMSE: 0.086474, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:42:33] Epoch 31/200, Loss: 38.325058, Train_MMSE: 0.092956, NMMSE: 0.085749, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:43:33] Epoch 32/200, Loss: 38.181744, Train_MMSE: 0.092891, NMMSE: 0.086889, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:44:32] Epoch 33/200, Loss: 38.384159, Train_MMSE: 0.09298, NMMSE: 0.087123, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:45:33] Epoch 34/200, Loss: 38.644173, Train_MMSE: 0.092817, NMMSE: 0.08616, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:46:31] Epoch 35/200, Loss: 38.496006, Train_MMSE: 0.092687, NMMSE: 0.086094, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:47:30] Epoch 36/200, Loss: 38.259869, Train_MMSE: 0.092627, NMMSE: 0.085976, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:48:27] Epoch 37/200, Loss: 37.969475, Train_MMSE: 0.092461, NMMSE: 0.085612, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:49:26] Epoch 38/200, Loss: 38.758274, Train_MMSE: 0.092328, NMMSE: 0.08616, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:50:26] Epoch 39/200, Loss: 38.407448, Train_MMSE: 0.092192, NMMSE: 0.086529, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:51:25] Epoch 40/200, Loss: 38.570145, Train_MMSE: 0.092082, NMMSE: 0.087807, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:52:25] Epoch 41/200, Loss: 37.840042, Train_MMSE: 0.091897, NMMSE: 0.089057, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:53:24] Epoch 42/200, Loss: 37.675297, Train_MMSE: 0.091846, NMMSE: 0.084855, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:54:24] Epoch 43/200, Loss: 38.419247, Train_MMSE: 0.091658, NMMSE: 0.086311, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:55:24] Epoch 44/200, Loss: 37.803589, Train_MMSE: 0.091492, NMMSE: 0.084366, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:56:22] Epoch 45/200, Loss: 37.954475, Train_MMSE: 0.091388, NMMSE: 0.085221, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:57:22] Epoch 46/200, Loss: 38.026516, Train_MMSE: 0.091153, NMMSE: 0.086075, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:58:22] Epoch 47/200, Loss: 37.839985, Train_MMSE: 0.090985, NMMSE: 0.084603, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:59:21] Epoch 48/200, Loss: 38.310310, Train_MMSE: 0.091036, NMMSE: 0.084136, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 19:00:21] Epoch 49/200, Loss: 37.743320, Train_MMSE: 0.090807, NMMSE: 0.084763, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 19:01:20] Epoch 50/200, Loss: 38.550198, Train_MMSE: 0.090537, NMMSE: 0.08455, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:02:20] Epoch 51/200, Loss: 36.609402, Train_MMSE: 0.085809, NMMSE: 0.07816, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:03:19] Epoch 52/200, Loss: 36.500832, Train_MMSE: 0.084841, NMMSE: 0.077501, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:04:19] Epoch 53/200, Loss: 36.395924, Train_MMSE: 0.084557, NMMSE: 0.077461, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:05:18] Epoch 54/200, Loss: 36.259846, Train_MMSE: 0.084339, NMMSE: 0.077189, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:06:17] Epoch 55/200, Loss: 35.872147, Train_MMSE: 0.084204, NMMSE: 0.077142, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:07:16] Epoch 56/200, Loss: 36.812798, Train_MMSE: 0.084024, NMMSE: 0.076904, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:08:15] Epoch 57/200, Loss: 36.402882, Train_MMSE: 0.083892, NMMSE: 0.077193, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:09:14] Epoch 58/200, Loss: 36.286823, Train_MMSE: 0.083773, NMMSE: 0.076947, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:10:14] Epoch 59/200, Loss: 36.023670, Train_MMSE: 0.08364, NMMSE: 0.077504, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:11:13] Epoch 60/200, Loss: 36.345261, Train_MMSE: 0.083555, NMMSE: 0.076759, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:12:13] Epoch 61/200, Loss: 36.225952, Train_MMSE: 0.0834, NMMSE: 0.076724, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:13:11] Epoch 62/200, Loss: 36.112568, Train_MMSE: 0.083362, NMMSE: 0.076713, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:14:10] Epoch 63/200, Loss: 35.953190, Train_MMSE: 0.083227, NMMSE: 0.076663, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:15:10] Epoch 64/200, Loss: 36.317158, Train_MMSE: 0.083108, NMMSE: 0.076731, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:16:10] Epoch 65/200, Loss: 36.240120, Train_MMSE: 0.083066, NMMSE: 0.076566, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:17:10] Epoch 66/200, Loss: 36.010365, Train_MMSE: 0.082931, NMMSE: 0.07734, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:18:10] Epoch 67/200, Loss: 36.114521, Train_MMSE: 0.082849, NMMSE: 0.076261, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:19:10] Epoch 68/200, Loss: 36.025379, Train_MMSE: 0.082745, NMMSE: 0.076558, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:20:11] Epoch 69/200, Loss: 36.202087, Train_MMSE: 0.082696, NMMSE: 0.076615, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:21:11] Epoch 70/200, Loss: 35.954880, Train_MMSE: 0.082636, NMMSE: 0.076149, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:22:10] Epoch 71/200, Loss: 36.259571, Train_MMSE: 0.082552, NMMSE: 0.076734, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:23:08] Epoch 72/200, Loss: 35.881611, Train_MMSE: 0.082443, NMMSE: 0.075994, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:24:07] Epoch 73/200, Loss: 36.270458, Train_MMSE: 0.082388, NMMSE: 0.075886, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:25:05] Epoch 74/200, Loss: 36.125877, Train_MMSE: 0.082296, NMMSE: 0.077179, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:26:03] Epoch 75/200, Loss: 35.873119, Train_MMSE: 0.082262, NMMSE: 0.075973, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:27:02] Epoch 76/200, Loss: 35.626259, Train_MMSE: 0.082164, NMMSE: 0.075936, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:28:00] Epoch 77/200, Loss: 35.747036, Train_MMSE: 0.082072, NMMSE: 0.076145, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:28:59] Epoch 78/200, Loss: 36.351067, Train_MMSE: 0.082073, NMMSE: 0.075738, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:29:58] Epoch 79/200, Loss: 36.266132, Train_MMSE: 0.081929, NMMSE: 0.076948, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:30:57] Epoch 80/200, Loss: 35.749111, Train_MMSE: 0.081886, NMMSE: 0.076007, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:31:56] Epoch 81/200, Loss: 35.809177, Train_MMSE: 0.081781, NMMSE: 0.07562, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:32:55] Epoch 82/200, Loss: 35.824329, Train_MMSE: 0.081716, NMMSE: 0.075738, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:33:55] Epoch 83/200, Loss: 35.751087, Train_MMSE: 0.08165, NMMSE: 0.076165, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:34:56] Epoch 84/200, Loss: 35.866474, Train_MMSE: 0.081563, NMMSE: 0.075521, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:35:53] Epoch 85/200, Loss: 35.532753, Train_MMSE: 0.081477, NMMSE: 0.075001, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:36:53] Epoch 86/200, Loss: 35.969238, Train_MMSE: 0.081439, NMMSE: 0.075393, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:37:51] Epoch 87/200, Loss: 35.264992, Train_MMSE: 0.081365, NMMSE: 0.075232, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:38:49] Epoch 88/200, Loss: 35.785175, Train_MMSE: 0.081271, NMMSE: 0.075313, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:39:49] Epoch 89/200, Loss: 35.927235, Train_MMSE: 0.08115, NMMSE: 0.075107, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:40:48] Epoch 90/200, Loss: 35.932858, Train_MMSE: 0.081187, NMMSE: 0.075947, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:41:47] Epoch 91/200, Loss: 35.667351, Train_MMSE: 0.081071, NMMSE: 0.075274, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:42:46] Epoch 92/200, Loss: 35.659962, Train_MMSE: 0.080993, NMMSE: 0.075792, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:43:45] Epoch 93/200, Loss: 35.657166, Train_MMSE: 0.080935, NMMSE: 0.075892, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:44:44] Epoch 94/200, Loss: 35.500370, Train_MMSE: 0.080905, NMMSE: 0.075026, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:45:42] Epoch 95/200, Loss: 35.838726, Train_MMSE: 0.080801, NMMSE: 0.074839, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:46:41] Epoch 96/200, Loss: 35.472908, Train_MMSE: 0.08073, NMMSE: 0.074916, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:47:40] Epoch 97/200, Loss: 35.830982, Train_MMSE: 0.080617, NMMSE: 0.075621, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:48:38] Epoch 98/200, Loss: 35.553665, Train_MMSE: 0.080532, NMMSE: 0.075331, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:49:38] Epoch 99/200, Loss: 35.533466, Train_MMSE: 0.080479, NMMSE: 0.075421, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:50:37] Epoch 100/200, Loss: 35.581551, Train_MMSE: 0.080431, NMMSE: 0.074819, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:51:37] Epoch 101/200, Loss: 34.927444, Train_MMSE: 0.079036, NMMSE: 0.072969, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:52:37] Epoch 102/200, Loss: 35.380390, Train_MMSE: 0.078841, NMMSE: 0.072933, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:53:37] Epoch 103/200, Loss: 35.353592, Train_MMSE: 0.078784, NMMSE: 0.072873, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:54:37] Epoch 104/200, Loss: 35.071018, Train_MMSE: 0.078746, NMMSE: 0.072833, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:55:36] Epoch 105/200, Loss: 35.015827, Train_MMSE: 0.078699, NMMSE: 0.072909, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:56:35] Epoch 106/200, Loss: 35.155415, Train_MMSE: 0.078671, NMMSE: 0.072881, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:57:34] Epoch 107/200, Loss: 35.423504, Train_MMSE: 0.078639, NMMSE: 0.072869, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:58:33] Epoch 108/200, Loss: 35.327084, Train_MMSE: 0.07862, NMMSE: 0.072761, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:59:32] Epoch 109/200, Loss: 34.843544, Train_MMSE: 0.078578, NMMSE: 0.072879, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:00:31] Epoch 110/200, Loss: 35.256592, Train_MMSE: 0.078555, NMMSE: 0.072782, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:01:32] Epoch 111/200, Loss: 35.023987, Train_MMSE: 0.078524, NMMSE: 0.072936, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:02:31] Epoch 112/200, Loss: 35.340534, Train_MMSE: 0.07851, NMMSE: 0.072717, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:03:30] Epoch 113/200, Loss: 35.098652, Train_MMSE: 0.078466, NMMSE: 0.072696, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:04:30] Epoch 114/200, Loss: 34.908772, Train_MMSE: 0.078453, NMMSE: 0.0728, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:05:30] Epoch 115/200, Loss: 34.825901, Train_MMSE: 0.078425, NMMSE: 0.072844, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:06:29] Epoch 116/200, Loss: 35.127346, Train_MMSE: 0.078402, NMMSE: 0.072651, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:07:28] Epoch 117/200, Loss: 34.809040, Train_MMSE: 0.07839, NMMSE: 0.072643, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:08:26] Epoch 118/200, Loss: 34.822369, Train_MMSE: 0.078341, NMMSE: 0.07276, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:09:24] Epoch 119/200, Loss: 35.430584, Train_MMSE: 0.078308, NMMSE: 0.072787, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:10:23] Epoch 120/200, Loss: 34.873882, Train_MMSE: 0.078299, NMMSE: 0.07259, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:11:22] Epoch 121/200, Loss: 35.366451, Train_MMSE: 0.078279, NMMSE: 0.072555, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:12:21] Epoch 122/200, Loss: 35.347641, Train_MMSE: 0.07826, NMMSE: 0.072601, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:13:21] Epoch 123/200, Loss: 35.059002, Train_MMSE: 0.078236, NMMSE: 0.072787, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:14:19] Epoch 124/200, Loss: 34.876751, Train_MMSE: 0.078233, NMMSE: 0.072522, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:15:18] Epoch 125/200, Loss: 35.275166, Train_MMSE: 0.07819, NMMSE: 0.072529, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:16:18] Epoch 126/200, Loss: 35.298500, Train_MMSE: 0.078166, NMMSE: 0.072528, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:17:15] Epoch 127/200, Loss: 35.326477, Train_MMSE: 0.078145, NMMSE: 0.072456, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:18:14] Epoch 128/200, Loss: 35.100296, Train_MMSE: 0.07814, NMMSE: 0.072505, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:19:14] Epoch 129/200, Loss: 34.725216, Train_MMSE: 0.078109, NMMSE: 0.07259, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:20:14] Epoch 130/200, Loss: 34.769299, Train_MMSE: 0.078102, NMMSE: 0.072603, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:21:13] Epoch 131/200, Loss: 35.080997, Train_MMSE: 0.078063, NMMSE: 0.07252, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:22:13] Epoch 132/200, Loss: 34.981647, Train_MMSE: 0.078059, NMMSE: 0.072488, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:23:12] Epoch 133/200, Loss: 34.708691, Train_MMSE: 0.078038, NMMSE: 0.072455, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:24:12] Epoch 134/200, Loss: 34.902359, Train_MMSE: 0.078019, NMMSE: 0.072515, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:25:10] Epoch 135/200, Loss: 34.729195, Train_MMSE: 0.077991, NMMSE: 0.07238, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:26:10] Epoch 136/200, Loss: 34.796680, Train_MMSE: 0.077977, NMMSE: 0.072474, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:27:09] Epoch 137/200, Loss: 35.050804, Train_MMSE: 0.077947, NMMSE: 0.072358, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:28:10] Epoch 138/200, Loss: 34.729664, Train_MMSE: 0.077935, NMMSE: 0.07233, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:29:09] Epoch 139/200, Loss: 34.795460, Train_MMSE: 0.077917, NMMSE: 0.072334, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:30:08] Epoch 140/200, Loss: 35.035732, Train_MMSE: 0.077894, NMMSE: 0.072354, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:31:06] Epoch 141/200, Loss: 34.885880, Train_MMSE: 0.077879, NMMSE: 0.072323, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:32:05] Epoch 142/200, Loss: 34.692646, Train_MMSE: 0.077867, NMMSE: 0.072255, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:33:03] Epoch 143/200, Loss: 34.953354, Train_MMSE: 0.077844, NMMSE: 0.072391, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:34:02] Epoch 144/200, Loss: 35.050655, Train_MMSE: 0.077831, NMMSE: 0.072229, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:35:01] Epoch 145/200, Loss: 34.890125, Train_MMSE: 0.077798, NMMSE: 0.072203, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:36:00] Epoch 146/200, Loss: 35.063171, Train_MMSE: 0.077801, NMMSE: 0.072302, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:36:59] Epoch 147/200, Loss: 34.738293, Train_MMSE: 0.077771, NMMSE: 0.072294, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:37:59] Epoch 148/200, Loss: 34.696068, Train_MMSE: 0.077765, NMMSE: 0.072281, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:38:57] Epoch 149/200, Loss: 34.970253, Train_MMSE: 0.077748, NMMSE: 0.072193, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:39:56] Epoch 150/200, Loss: 34.820000, Train_MMSE: 0.077733, NMMSE: 0.072192, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:40:55] Epoch 151/200, Loss: 35.210785, Train_MMSE: 0.077489, NMMSE: 0.071957, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:41:55] Epoch 152/200, Loss: 35.120251, Train_MMSE: 0.077455, NMMSE: 0.07196, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:42:50] Epoch 153/200, Loss: 34.881668, Train_MMSE: 0.077451, NMMSE: 0.071946, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:43:46] Epoch 154/200, Loss: 34.643108, Train_MMSE: 0.077445, NMMSE: 0.071953, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:44:40] Epoch 155/200, Loss: 34.750767, Train_MMSE: 0.077444, NMMSE: 0.071927, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:45:26] Epoch 156/200, Loss: 34.819504, Train_MMSE: 0.077439, NMMSE: 0.071947, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:46:12] Epoch 157/200, Loss: 34.532307, Train_MMSE: 0.07743, NMMSE: 0.071933, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:46:57] Epoch 158/200, Loss: 34.698414, Train_MMSE: 0.077438, NMMSE: 0.07194, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:47:42] Epoch 159/200, Loss: 35.096378, Train_MMSE: 0.077439, NMMSE: 0.071942, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:48:29] Epoch 160/200, Loss: 34.855789, Train_MMSE: 0.077427, NMMSE: 0.071943, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:49:16] Epoch 161/200, Loss: 35.078644, Train_MMSE: 0.077433, NMMSE: 0.071927, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:50:02] Epoch 162/200, Loss: 35.267254, Train_MMSE: 0.077427, NMMSE: 0.071923, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:50:47] Epoch 163/200, Loss: 34.763050, Train_MMSE: 0.077426, NMMSE: 0.071934, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:51:34] Epoch 164/200, Loss: 34.916248, Train_MMSE: 0.077422, NMMSE: 0.071932, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:52:19] Epoch 165/200, Loss: 34.955296, Train_MMSE: 0.077417, NMMSE: 0.07193, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:53:05] Epoch 166/200, Loss: 34.889633, Train_MMSE: 0.077416, NMMSE: 0.071937, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:53:52] Epoch 167/200, Loss: 34.714890, Train_MMSE: 0.077415, NMMSE: 0.071919, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:54:38] Epoch 168/200, Loss: 34.471172, Train_MMSE: 0.077411, NMMSE: 0.071938, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:55:24] Epoch 169/200, Loss: 34.746876, Train_MMSE: 0.077409, NMMSE: 0.071917, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:56:10] Epoch 170/200, Loss: 35.140461, Train_MMSE: 0.07741, NMMSE: 0.071926, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:56:56] Epoch 171/200, Loss: 34.561195, Train_MMSE: 0.077411, NMMSE: 0.071925, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:57:42] Epoch 172/200, Loss: 34.584419, Train_MMSE: 0.077403, NMMSE: 0.071912, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:58:28] Epoch 173/200, Loss: 34.701569, Train_MMSE: 0.077399, NMMSE: 0.071915, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:59:15] Epoch 174/200, Loss: 34.872135, Train_MMSE: 0.077394, NMMSE: 0.071915, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:00:01] Epoch 175/200, Loss: 34.492283, Train_MMSE: 0.077388, NMMSE: 0.071914, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:00:47] Epoch 176/200, Loss: 34.852711, Train_MMSE: 0.077389, NMMSE: 0.071913, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:01:33] Epoch 177/200, Loss: 34.929760, Train_MMSE: 0.077393, NMMSE: 0.071896, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:02:19] Epoch 178/200, Loss: 35.122093, Train_MMSE: 0.077383, NMMSE: 0.071919, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:03:05] Epoch 179/200, Loss: 34.580551, Train_MMSE: 0.077385, NMMSE: 0.071915, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:03:52] Epoch 180/200, Loss: 34.687824, Train_MMSE: 0.07738, NMMSE: 0.0719, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:04:38] Epoch 181/200, Loss: 34.695103, Train_MMSE: 0.077382, NMMSE: 0.071904, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:05:25] Epoch 182/200, Loss: 34.846664, Train_MMSE: 0.077377, NMMSE: 0.071899, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:06:12] Epoch 183/200, Loss: 34.585896, Train_MMSE: 0.077378, NMMSE: 0.071917, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:06:58] Epoch 184/200, Loss: 34.550056, Train_MMSE: 0.077376, NMMSE: 0.071889, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:07:43] Epoch 185/200, Loss: 35.040478, Train_MMSE: 0.077372, NMMSE: 0.071897, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:08:29] Epoch 186/200, Loss: 34.568703, Train_MMSE: 0.077362, NMMSE: 0.071906, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:09:16] Epoch 187/200, Loss: 34.852787, Train_MMSE: 0.077354, NMMSE: 0.071898, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:10:03] Epoch 188/200, Loss: 34.989449, Train_MMSE: 0.077361, NMMSE: 0.071881, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:10:49] Epoch 189/200, Loss: 35.079819, Train_MMSE: 0.077363, NMMSE: 0.071885, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:11:35] Epoch 190/200, Loss: 34.518181, Train_MMSE: 0.077353, NMMSE: 0.071891, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:12:22] Epoch 191/200, Loss: 34.677334, Train_MMSE: 0.077355, NMMSE: 0.071885, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:13:09] Epoch 192/200, Loss: 34.818340, Train_MMSE: 0.077348, NMMSE: 0.071868, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:13:55] Epoch 193/200, Loss: 34.996616, Train_MMSE: 0.077356, NMMSE: 0.071886, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:14:41] Epoch 194/200, Loss: 34.724045, Train_MMSE: 0.077343, NMMSE: 0.071875, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:15:27] Epoch 195/200, Loss: 34.700684, Train_MMSE: 0.077339, NMMSE: 0.071874, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:16:14] Epoch 196/200, Loss: 34.692310, Train_MMSE: 0.077349, NMMSE: 0.071881, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:16:59] Epoch 197/200, Loss: 34.846970, Train_MMSE: 0.077339, NMMSE: 0.071874, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:17:45] Epoch 198/200, Loss: 35.027000, Train_MMSE: 0.077339, NMMSE: 0.071879, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:18:31] Epoch 199/200, Loss: 34.749474, Train_MMSE: 0.077331, NMMSE: 0.071862, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:19:07] Epoch 200/200, Loss: 35.217319, Train_MMSE: 0.077336, NMMSE: 0.071867, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
