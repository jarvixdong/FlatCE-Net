H shape: (10000, 4, 36) (10000, 4, 36)
NMMSE of valid dataset:: 0.022683821909496294
num samples :: 100000
num valid: 10000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/train_Dataset_dB-10_N36_K4_L6_S9_Setup100_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/test_Dataset_dB-10_N36_K4_L6_S9_Setup10_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}, 'trainer': {'optimizer': 'Adam', 'lr': 0.01, 'weight_decay': 0.001, 'lr_scheduler': 'Plateau', 'lr_gamma': 0.1, 'min_lr': 1e-06, 'patience': 20}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (47): ReLU(inplace=True)
      (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (50): ReLU(inplace=True)
      (51): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 6.80 MB
loss function:: L1Loss()
[2025-02-22 18:11:42] Epoch 1/200, Loss: 27.056335, Train_MMSE: 0.047003, NMMSE: 0.046385, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:12:32] Epoch 2/200, Loss: 26.624550, Train_MMSE: 0.045137, NMMSE: 0.038821, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:13:32] Epoch 3/200, Loss: 25.669828, Train_MMSE: 0.04291, NMMSE: 0.037547, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:14:31] Epoch 4/200, Loss: 25.646355, Train_MMSE: 0.041276, NMMSE: 0.036247, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:15:29] Epoch 5/200, Loss: 25.559723, Train_MMSE: 0.040485, NMMSE: 0.036073, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:16:28] Epoch 6/200, Loss: 25.300354, Train_MMSE: 0.039877, NMMSE: 0.035313, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:17:26] Epoch 7/200, Loss: 25.139807, Train_MMSE: 0.039345, NMMSE: 0.035503, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:18:25] Epoch 8/200, Loss: 25.316690, Train_MMSE: 0.038999, NMMSE: 0.034394, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:19:24] Epoch 9/200, Loss: 24.981161, Train_MMSE: 0.038713, NMMSE: 0.034338, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:20:23] Epoch 10/200, Loss: 24.952694, Train_MMSE: 0.038503, NMMSE: 0.03442, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:21:21] Epoch 11/200, Loss: 24.714317, Train_MMSE: 0.038243, NMMSE: 0.034267, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:22:20] Epoch 12/200, Loss: 24.731298, Train_MMSE: 0.038063, NMMSE: 0.034169, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:23:19] Epoch 13/200, Loss: 24.527586, Train_MMSE: 0.037878, NMMSE: 0.033802, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:24:19] Epoch 14/200, Loss: 24.709227, Train_MMSE: 0.037743, NMMSE: 0.033954, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:25:18] Epoch 15/200, Loss: 24.727488, Train_MMSE: 0.037589, NMMSE: 0.033733, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:26:18] Epoch 16/200, Loss: 24.768856, Train_MMSE: 0.037495, NMMSE: 0.033695, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:27:22] Epoch 17/200, Loss: 24.654850, Train_MMSE: 0.037404, NMMSE: 0.033402, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:28:21] Epoch 18/200, Loss: 24.541548, Train_MMSE: 0.037353, NMMSE: 0.033372, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:29:21] Epoch 19/200, Loss: 24.322441, Train_MMSE: 0.037248, NMMSE: 0.033127, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:30:19] Epoch 20/200, Loss: 24.451052, Train_MMSE: 0.037155, NMMSE: 0.033105, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:31:19] Epoch 21/200, Loss: 24.439644, Train_MMSE: 0.037097, NMMSE: 0.033915, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:32:21] Epoch 22/200, Loss: 24.505322, Train_MMSE: 0.037047, NMMSE: 0.033064, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:33:20] Epoch 23/200, Loss: 24.462091, Train_MMSE: 0.036986, NMMSE: 0.033391, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:34:21] Epoch 24/200, Loss: 24.529173, Train_MMSE: 0.036929, NMMSE: 0.03295, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:35:20] Epoch 25/200, Loss: 24.359476, Train_MMSE: 0.036868, NMMSE: 0.033916, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:36:20] Epoch 26/200, Loss: 24.339144, Train_MMSE: 0.036824, NMMSE: 0.033301, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:37:19] Epoch 27/200, Loss: 24.558538, Train_MMSE: 0.036781, NMMSE: 0.033511, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:38:20] Epoch 28/200, Loss: 24.279917, Train_MMSE: 0.036774, NMMSE: 0.033193, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:39:19] Epoch 29/200, Loss: 24.475258, Train_MMSE: 0.036696, NMMSE: 0.033286, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:40:19] Epoch 30/200, Loss: 24.353010, Train_MMSE: 0.036642, NMMSE: 0.032785, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:41:19] Epoch 31/200, Loss: 24.327808, Train_MMSE: 0.036616, NMMSE: 0.033154, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:42:20] Epoch 32/200, Loss: 24.291586, Train_MMSE: 0.03657, NMMSE: 0.032981, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:43:19] Epoch 33/200, Loss: 24.227676, Train_MMSE: 0.036567, NMMSE: 0.032647, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:44:19] Epoch 34/200, Loss: 24.362774, Train_MMSE: 0.03654, NMMSE: 0.0329, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:45:19] Epoch 35/200, Loss: 24.247725, Train_MMSE: 0.036467, NMMSE: 0.032643, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:46:19] Epoch 36/200, Loss: 24.210503, Train_MMSE: 0.036461, NMMSE: 0.032878, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:47:19] Epoch 37/200, Loss: 24.421719, Train_MMSE: 0.036381, NMMSE: 0.03237, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:48:19] Epoch 38/200, Loss: 24.268175, Train_MMSE: 0.036352, NMMSE: 0.032836, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:49:18] Epoch 39/200, Loss: 24.438164, Train_MMSE: 0.036354, NMMSE: 0.032649, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:50:18] Epoch 40/200, Loss: 24.060841, Train_MMSE: 0.036308, NMMSE: 0.032757, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:51:18] Epoch 41/200, Loss: 24.299374, Train_MMSE: 0.036299, NMMSE: 0.032658, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:52:17] Epoch 42/200, Loss: 24.402750, Train_MMSE: 0.036269, NMMSE: 0.03315, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:53:15] Epoch 43/200, Loss: 24.347528, Train_MMSE: 0.036235, NMMSE: 0.032909, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:54:15] Epoch 44/200, Loss: 24.252951, Train_MMSE: 0.036203, NMMSE: 0.032874, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:55:13] Epoch 45/200, Loss: 24.127560, Train_MMSE: 0.036139, NMMSE: 0.032521, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:56:12] Epoch 46/200, Loss: 24.102282, Train_MMSE: 0.036102, NMMSE: 0.033547, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:57:12] Epoch 47/200, Loss: 23.912832, Train_MMSE: 0.036067, NMMSE: 0.032192, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:58:11] Epoch 48/200, Loss: 24.171791, Train_MMSE: 0.036028, NMMSE: 0.034359, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 18:59:11] Epoch 49/200, Loss: 24.174189, Train_MMSE: 0.036026, NMMSE: 0.033044, LS_NMSE: 0.040811, Lr: 0.01
[2025-02-22 19:00:10] Epoch 50/200, Loss: 24.091866, Train_MMSE: 0.035971, NMMSE: 0.034334, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:01:11] Epoch 51/200, Loss: 23.734949, Train_MMSE: 0.035127, NMMSE: 0.031128, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:02:12] Epoch 52/200, Loss: 23.937479, Train_MMSE: 0.034963, NMMSE: 0.031071, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:03:12] Epoch 53/200, Loss: 23.908592, Train_MMSE: 0.034905, NMMSE: 0.031032, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:04:11] Epoch 54/200, Loss: 23.773436, Train_MMSE: 0.034859, NMMSE: 0.031008, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:05:11] Epoch 55/200, Loss: 23.784616, Train_MMSE: 0.03482, NMMSE: 0.030953, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:06:10] Epoch 56/200, Loss: 23.700811, Train_MMSE: 0.034803, NMMSE: 0.031033, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:07:09] Epoch 57/200, Loss: 23.853666, Train_MMSE: 0.034785, NMMSE: 0.031004, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:08:09] Epoch 58/200, Loss: 23.605616, Train_MMSE: 0.034755, NMMSE: 0.030967, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:09:10] Epoch 59/200, Loss: 23.769329, Train_MMSE: 0.034733, NMMSE: 0.030956, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:10:10] Epoch 60/200, Loss: 23.671928, Train_MMSE: 0.034718, NMMSE: 0.031056, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:11:09] Epoch 61/200, Loss: 23.689142, Train_MMSE: 0.034698, NMMSE: 0.03092, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:12:08] Epoch 62/200, Loss: 23.651951, Train_MMSE: 0.034675, NMMSE: 0.030899, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:13:10] Epoch 63/200, Loss: 23.845209, Train_MMSE: 0.034667, NMMSE: 0.030852, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:14:09] Epoch 64/200, Loss: 23.490503, Train_MMSE: 0.03465, NMMSE: 0.030927, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:15:10] Epoch 65/200, Loss: 23.676895, Train_MMSE: 0.034628, NMMSE: 0.030838, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:16:10] Epoch 66/200, Loss: 23.793409, Train_MMSE: 0.034627, NMMSE: 0.030826, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:17:10] Epoch 67/200, Loss: 23.590490, Train_MMSE: 0.034607, NMMSE: 0.031045, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:18:10] Epoch 68/200, Loss: 23.467381, Train_MMSE: 0.034596, NMMSE: 0.030962, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:19:11] Epoch 69/200, Loss: 23.633541, Train_MMSE: 0.034595, NMMSE: 0.030895, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:20:11] Epoch 70/200, Loss: 23.485033, Train_MMSE: 0.034571, NMMSE: 0.030825, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:21:12] Epoch 71/200, Loss: 23.578234, Train_MMSE: 0.034562, NMMSE: 0.030838, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:22:13] Epoch 72/200, Loss: 23.700062, Train_MMSE: 0.034546, NMMSE: 0.030842, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:23:13] Epoch 73/200, Loss: 23.676870, Train_MMSE: 0.034541, NMMSE: 0.030812, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:24:12] Epoch 74/200, Loss: 23.533762, Train_MMSE: 0.034524, NMMSE: 0.030891, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:25:12] Epoch 75/200, Loss: 23.359272, Train_MMSE: 0.034512, NMMSE: 0.030835, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:26:12] Epoch 76/200, Loss: 23.402029, Train_MMSE: 0.034508, NMMSE: 0.030765, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:27:12] Epoch 77/200, Loss: 23.499409, Train_MMSE: 0.034497, NMMSE: 0.030721, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:28:12] Epoch 78/200, Loss: 23.544216, Train_MMSE: 0.034502, NMMSE: 0.030808, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:29:11] Epoch 79/200, Loss: 23.446798, Train_MMSE: 0.034476, NMMSE: 0.030833, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:30:12] Epoch 80/200, Loss: 23.653425, Train_MMSE: 0.034475, NMMSE: 0.03067, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:31:13] Epoch 81/200, Loss: 23.523920, Train_MMSE: 0.034481, NMMSE: 0.03069, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:32:13] Epoch 82/200, Loss: 23.573442, Train_MMSE: 0.03445, NMMSE: 0.030865, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:33:12] Epoch 83/200, Loss: 23.561478, Train_MMSE: 0.034449, NMMSE: 0.030796, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:34:12] Epoch 84/200, Loss: 23.550703, Train_MMSE: 0.034451, NMMSE: 0.030749, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:35:12] Epoch 85/200, Loss: 23.566845, Train_MMSE: 0.034446, NMMSE: 0.03072, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:36:12] Epoch 86/200, Loss: 23.652399, Train_MMSE: 0.034436, NMMSE: 0.030786, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:37:13] Epoch 87/200, Loss: 23.534883, Train_MMSE: 0.034421, NMMSE: 0.030678, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:38:14] Epoch 88/200, Loss: 23.429697, Train_MMSE: 0.034417, NMMSE: 0.030715, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:39:13] Epoch 89/200, Loss: 23.583225, Train_MMSE: 0.034415, NMMSE: 0.030712, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:40:13] Epoch 90/200, Loss: 23.461390, Train_MMSE: 0.03442, NMMSE: 0.03109, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:41:13] Epoch 91/200, Loss: 23.385794, Train_MMSE: 0.034392, NMMSE: 0.030695, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:42:12] Epoch 92/200, Loss: 23.419361, Train_MMSE: 0.034401, NMMSE: 0.030657, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:43:11] Epoch 93/200, Loss: 23.559345, Train_MMSE: 0.034384, NMMSE: 0.030677, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:44:10] Epoch 94/200, Loss: 23.547459, Train_MMSE: 0.034388, NMMSE: 0.030806, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:45:08] Epoch 95/200, Loss: 23.576792, Train_MMSE: 0.034367, NMMSE: 0.030649, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:46:08] Epoch 96/200, Loss: 23.429495, Train_MMSE: 0.034364, NMMSE: 0.030658, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:47:07] Epoch 97/200, Loss: 23.633642, Train_MMSE: 0.034357, NMMSE: 0.030777, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:48:07] Epoch 98/200, Loss: 23.652988, Train_MMSE: 0.034352, NMMSE: 0.030802, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:49:06] Epoch 99/200, Loss: 23.422623, Train_MMSE: 0.034323, NMMSE: 0.030834, LS_NMSE: 0.040811, Lr: 0.001
[2025-02-22 19:50:05] Epoch 100/200, Loss: 23.471359, Train_MMSE: 0.034328, NMMSE: 0.030651, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:51:05] Epoch 101/200, Loss: 23.268764, Train_MMSE: 0.034112, NMMSE: 0.030399, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:52:05] Epoch 102/200, Loss: 23.367670, Train_MMSE: 0.034085, NMMSE: 0.03039, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:53:05] Epoch 103/200, Loss: 23.535685, Train_MMSE: 0.034074, NMMSE: 0.030383, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:54:03] Epoch 104/200, Loss: 23.372971, Train_MMSE: 0.034072, NMMSE: 0.030377, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:55:01] Epoch 105/200, Loss: 23.545349, Train_MMSE: 0.034066, NMMSE: 0.03039, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:56:01] Epoch 106/200, Loss: 23.113453, Train_MMSE: 0.034061, NMMSE: 0.030391, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:57:00] Epoch 107/200, Loss: 23.351307, Train_MMSE: 0.034053, NMMSE: 0.030377, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:57:58] Epoch 108/200, Loss: 23.220280, Train_MMSE: 0.034055, NMMSE: 0.030368, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:58:57] Epoch 109/200, Loss: 23.407007, Train_MMSE: 0.034054, NMMSE: 0.030377, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:59:57] Epoch 110/200, Loss: 23.330345, Train_MMSE: 0.034045, NMMSE: 0.030362, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:00:57] Epoch 111/200, Loss: 23.421473, Train_MMSE: 0.034042, NMMSE: 0.030366, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:01:57] Epoch 112/200, Loss: 23.524605, Train_MMSE: 0.03404, NMMSE: 0.030357, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:02:56] Epoch 113/200, Loss: 23.451710, Train_MMSE: 0.034035, NMMSE: 0.030361, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:03:56] Epoch 114/200, Loss: 23.422138, Train_MMSE: 0.03403, NMMSE: 0.030349, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:04:56] Epoch 115/200, Loss: 23.402414, Train_MMSE: 0.034029, NMMSE: 0.03035, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:05:56] Epoch 116/200, Loss: 23.348061, Train_MMSE: 0.034029, NMMSE: 0.030341, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:06:55] Epoch 117/200, Loss: 23.389307, Train_MMSE: 0.034023, NMMSE: 0.030357, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:07:54] Epoch 118/200, Loss: 23.459009, Train_MMSE: 0.03402, NMMSE: 0.030343, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:08:51] Epoch 119/200, Loss: 23.244287, Train_MMSE: 0.034018, NMMSE: 0.030342, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:09:48] Epoch 120/200, Loss: 23.633255, Train_MMSE: 0.034017, NMMSE: 0.030348, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:10:48] Epoch 121/200, Loss: 23.283257, Train_MMSE: 0.034015, NMMSE: 0.030346, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:11:46] Epoch 122/200, Loss: 23.481836, Train_MMSE: 0.034012, NMMSE: 0.030332, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:12:44] Epoch 123/200, Loss: 23.271929, Train_MMSE: 0.034004, NMMSE: 0.030325, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:13:44] Epoch 124/200, Loss: 23.491762, Train_MMSE: 0.034004, NMMSE: 0.030351, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:14:42] Epoch 125/200, Loss: 23.537121, Train_MMSE: 0.034003, NMMSE: 0.030333, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:15:39] Epoch 126/200, Loss: 23.102156, Train_MMSE: 0.034001, NMMSE: 0.030354, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:16:38] Epoch 127/200, Loss: 23.382511, Train_MMSE: 0.033995, NMMSE: 0.030326, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:17:38] Epoch 128/200, Loss: 23.428080, Train_MMSE: 0.033991, NMMSE: 0.030317, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:18:37] Epoch 129/200, Loss: 23.532349, Train_MMSE: 0.033994, NMMSE: 0.030328, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:19:36] Epoch 130/200, Loss: 23.513409, Train_MMSE: 0.033986, NMMSE: 0.030337, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:20:35] Epoch 131/200, Loss: 23.374094, Train_MMSE: 0.03399, NMMSE: 0.030313, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:21:35] Epoch 132/200, Loss: 23.316685, Train_MMSE: 0.033991, NMMSE: 0.030321, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:22:33] Epoch 133/200, Loss: 23.224445, Train_MMSE: 0.033987, NMMSE: 0.030319, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:23:33] Epoch 134/200, Loss: 23.389849, Train_MMSE: 0.03398, NMMSE: 0.030327, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:24:33] Epoch 135/200, Loss: 23.265720, Train_MMSE: 0.033979, NMMSE: 0.03033, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:25:32] Epoch 136/200, Loss: 23.398401, Train_MMSE: 0.033982, NMMSE: 0.030325, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:26:31] Epoch 137/200, Loss: 23.288483, Train_MMSE: 0.033978, NMMSE: 0.030307, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:27:30] Epoch 138/200, Loss: 23.291712, Train_MMSE: 0.033976, NMMSE: 0.030323, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:28:28] Epoch 139/200, Loss: 23.319101, Train_MMSE: 0.03397, NMMSE: 0.030349, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:29:27] Epoch 140/200, Loss: 23.327072, Train_MMSE: 0.033971, NMMSE: 0.030308, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:30:26] Epoch 141/200, Loss: 23.605032, Train_MMSE: 0.03397, NMMSE: 0.030297, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:31:26] Epoch 142/200, Loss: 23.676041, Train_MMSE: 0.03397, NMMSE: 0.030301, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:32:26] Epoch 143/200, Loss: 23.445656, Train_MMSE: 0.033964, NMMSE: 0.030318, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:33:25] Epoch 144/200, Loss: 23.284815, Train_MMSE: 0.033962, NMMSE: 0.030302, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:34:24] Epoch 145/200, Loss: 23.358437, Train_MMSE: 0.033962, NMMSE: 0.03031, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:35:25] Epoch 146/200, Loss: 23.533688, Train_MMSE: 0.03396, NMMSE: 0.030305, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:36:24] Epoch 147/200, Loss: 23.520210, Train_MMSE: 0.033959, NMMSE: 0.030293, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:37:24] Epoch 148/200, Loss: 23.559465, Train_MMSE: 0.033962, NMMSE: 0.030305, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:38:24] Epoch 149/200, Loss: 23.447090, Train_MMSE: 0.033959, NMMSE: 0.030309, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:39:22] Epoch 150/200, Loss: 23.325914, Train_MMSE: 0.033953, NMMSE: 0.030288, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:40:21] Epoch 151/200, Loss: 23.303371, Train_MMSE: 0.033919, NMMSE: 0.030268, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:41:20] Epoch 152/200, Loss: 23.311697, Train_MMSE: 0.033916, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:42:18] Epoch 153/200, Loss: 23.426958, Train_MMSE: 0.033912, NMMSE: 0.030268, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:43:17] Epoch 154/200, Loss: 23.489166, Train_MMSE: 0.033914, NMMSE: 0.030269, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:44:11] Epoch 155/200, Loss: 23.368969, Train_MMSE: 0.033914, NMMSE: 0.030267, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:45:02] Epoch 156/200, Loss: 23.256140, Train_MMSE: 0.033913, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:45:48] Epoch 157/200, Loss: 23.442921, Train_MMSE: 0.03391, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:46:34] Epoch 158/200, Loss: 23.290394, Train_MMSE: 0.033913, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:47:20] Epoch 159/200, Loss: 23.275736, Train_MMSE: 0.033907, NMMSE: 0.030265, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:48:06] Epoch 160/200, Loss: 23.225302, Train_MMSE: 0.033909, NMMSE: 0.030267, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:48:53] Epoch 161/200, Loss: 23.316572, Train_MMSE: 0.033908, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:49:39] Epoch 162/200, Loss: 23.273567, Train_MMSE: 0.033909, NMMSE: 0.030267, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:50:24] Epoch 163/200, Loss: 23.317463, Train_MMSE: 0.033915, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:51:10] Epoch 164/200, Loss: 23.481312, Train_MMSE: 0.033907, NMMSE: 0.030267, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:51:55] Epoch 165/200, Loss: 23.353868, Train_MMSE: 0.033908, NMMSE: 0.030264, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:52:41] Epoch 166/200, Loss: 23.549311, Train_MMSE: 0.033912, NMMSE: 0.030264, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:53:28] Epoch 167/200, Loss: 23.402826, Train_MMSE: 0.03391, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:54:14] Epoch 168/200, Loss: 23.437141, Train_MMSE: 0.033904, NMMSE: 0.030264, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:55:00] Epoch 169/200, Loss: 23.418436, Train_MMSE: 0.033909, NMMSE: 0.030265, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:55:46] Epoch 170/200, Loss: 23.430309, Train_MMSE: 0.033907, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:56:32] Epoch 171/200, Loss: 23.254147, Train_MMSE: 0.033908, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:57:18] Epoch 172/200, Loss: 23.489574, Train_MMSE: 0.033906, NMMSE: 0.030265, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:58:05] Epoch 173/200, Loss: 23.487150, Train_MMSE: 0.03391, NMMSE: 0.030264, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:58:51] Epoch 174/200, Loss: 23.322168, Train_MMSE: 0.033907, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:59:37] Epoch 175/200, Loss: 23.293346, Train_MMSE: 0.033906, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:00:24] Epoch 176/200, Loss: 23.318369, Train_MMSE: 0.033908, NMMSE: 0.030265, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:01:09] Epoch 177/200, Loss: 23.194817, Train_MMSE: 0.033904, NMMSE: 0.030262, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:01:56] Epoch 178/200, Loss: 23.297163, Train_MMSE: 0.033905, NMMSE: 0.030266, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:02:42] Epoch 179/200, Loss: 23.255404, Train_MMSE: 0.033908, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:03:28] Epoch 180/200, Loss: 23.338804, Train_MMSE: 0.033906, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:04:13] Epoch 181/200, Loss: 23.427511, Train_MMSE: 0.033907, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:04:59] Epoch 182/200, Loss: 23.397394, Train_MMSE: 0.033904, NMMSE: 0.030262, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:05:45] Epoch 183/200, Loss: 23.367485, Train_MMSE: 0.033902, NMMSE: 0.030262, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:06:31] Epoch 184/200, Loss: 23.128273, Train_MMSE: 0.033903, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:07:18] Epoch 185/200, Loss: 23.402113, Train_MMSE: 0.033904, NMMSE: 0.03026, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:08:04] Epoch 186/200, Loss: 23.644121, Train_MMSE: 0.033906, NMMSE: 0.03026, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:08:51] Epoch 187/200, Loss: 23.215755, Train_MMSE: 0.033903, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:09:37] Epoch 188/200, Loss: 23.284262, Train_MMSE: 0.033904, NMMSE: 0.030263, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:10:23] Epoch 189/200, Loss: 23.400721, Train_MMSE: 0.033906, NMMSE: 0.030262, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:11:10] Epoch 190/200, Loss: 23.325779, Train_MMSE: 0.033899, NMMSE: 0.03026, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:11:56] Epoch 191/200, Loss: 23.407034, Train_MMSE: 0.033901, NMMSE: 0.030262, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:12:42] Epoch 192/200, Loss: 23.221090, Train_MMSE: 0.0339, NMMSE: 0.03026, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:13:28] Epoch 193/200, Loss: 23.356915, Train_MMSE: 0.033905, NMMSE: 0.030261, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:14:14] Epoch 194/200, Loss: 23.418446, Train_MMSE: 0.033904, NMMSE: 0.030261, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:15:01] Epoch 195/200, Loss: 23.191868, Train_MMSE: 0.033901, NMMSE: 0.03026, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:15:47] Epoch 196/200, Loss: 23.263214, Train_MMSE: 0.033904, NMMSE: 0.030264, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:16:33] Epoch 197/200, Loss: 23.380859, Train_MMSE: 0.033903, NMMSE: 0.030261, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:17:19] Epoch 198/200, Loss: 23.257822, Train_MMSE: 0.033904, NMMSE: 0.03026, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:18:05] Epoch 199/200, Loss: 23.395451, Train_MMSE: 0.033897, NMMSE: 0.030261, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 21:18:51] Epoch 200/200, Loss: 23.322140, Train_MMSE: 0.033904, NMMSE: 0.030259, LS_NMSE: 0.040811, Lr: 1.0000000000000002e-06
00, Loss: 21.445602, Train_MMSE: 0.027745, NMMSE: 0.024888, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:52:18] Epoch 138/200, Loss: 21.113569, Train_MMSE: 0.02777, NMMSE: 0.024875, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:53:08] Epoch 139/200, Loss: 21.190912, Train_MMSE: 0.027748, NMMSE: 0.024889, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:53:59] Epoch 140/200, Loss: 21.282064, Train_MMSE: 0.02776, NMMSE: 0.024857, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:54:50] Epoch 141/200, Loss: 21.053167, Train_MMSE: 0.027745, NMMSE: 0.02487, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:55:41] Epoch 142/200, Loss: 21.159588, Train_MMSE: 0.027773, NMMSE: 0.024883, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:56:32] Epoch 143/200, Loss: 21.151110, Train_MMSE: 0.02777, NMMSE: 0.024887, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:57:23] Epoch 144/200, Loss: 21.225546, Train_MMSE: 0.027756, NMMSE: 0.024915, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:58:14] Epoch 145/200, Loss: 21.137106, Train_MMSE: 0.027761, NMMSE: 0.024877, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:59:06] Epoch 146/200, Loss: 21.030067, Train_MMSE: 0.02777, NMMSE: 0.024848, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 19:59:56] Epoch 147/200, Loss: 20.923880, Train_MMSE: 0.027744, NMMSE: 0.024855, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:00:47] Epoch 148/200, Loss: 21.255255, Train_MMSE: 0.027744, NMMSE: 0.024847, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:01:38] Epoch 149/200, Loss: 21.171310, Train_MMSE: 0.027736, NMMSE: 0.024864, LS_NMSE: 0.040811, Lr: 0.0001
[2025-02-22 20:02:29] Epoch 150/200, Loss: 21.265251, Train_MMSE: 0.027756, NMMSE: 0.024854, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:03:20] Epoch 151/200, Loss: 21.096359, Train_MMSE: 0.027724, NMMSE: 0.024835, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:04:11] Epoch 152/200, Loss: 21.084841, Train_MMSE: 0.027694, NMMSE: 0.024833, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:05:02] Epoch 153/200, Loss: 21.095800, Train_MMSE: 0.027707, NMMSE: 0.024852, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:05:53] Epoch 154/200, Loss: 21.077976, Train_MMSE: 0.02771, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:06:45] Epoch 155/200, Loss: 21.082384, Train_MMSE: 0.027706, NMMSE: 0.024829, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:07:36] Epoch 156/200, Loss: 21.077053, Train_MMSE: 0.027711, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:08:28] Epoch 157/200, Loss: 21.111582, Train_MMSE: 0.027712, NMMSE: 0.024826, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:09:20] Epoch 158/200, Loss: 21.101318, Train_MMSE: 0.027717, NMMSE: 0.024836, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:10:11] Epoch 159/200, Loss: 21.317112, Train_MMSE: 0.027704, NMMSE: 0.024833, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:11:02] Epoch 160/200, Loss: 21.048208, Train_MMSE: 0.027724, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:11:53] Epoch 161/200, Loss: 21.152231, Train_MMSE: 0.027694, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:12:45] Epoch 162/200, Loss: 20.907213, Train_MMSE: 0.027714, NMMSE: 0.024822, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:13:35] Epoch 163/200, Loss: 21.239637, Train_MMSE: 0.027706, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:14:27] Epoch 164/200, Loss: 21.258768, Train_MMSE: 0.027713, NMMSE: 0.024827, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:15:19] Epoch 165/200, Loss: 21.073578, Train_MMSE: 0.027724, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:16:10] Epoch 166/200, Loss: 21.088734, Train_MMSE: 0.027721, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:17:01] Epoch 167/200, Loss: 21.155487, Train_MMSE: 0.027698, NMMSE: 0.024832, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:17:52] Epoch 168/200, Loss: 21.041840, Train_MMSE: 0.027704, NMMSE: 0.024827, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:18:42] Epoch 169/200, Loss: 20.884331, Train_MMSE: 0.027711, NMMSE: 0.024825, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:19:33] Epoch 170/200, Loss: 21.014214, Train_MMSE: 0.027704, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:20:24] Epoch 171/200, Loss: 21.147158, Train_MMSE: 0.027711, NMMSE: 0.02483, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:21:15] Epoch 172/200, Loss: 21.157211, Train_MMSE: 0.027692, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:22:06] Epoch 173/200, Loss: 21.346962, Train_MMSE: 0.027711, NMMSE: 0.024837, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:22:57] Epoch 174/200, Loss: 21.042057, Train_MMSE: 0.027689, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:23:48] Epoch 175/200, Loss: 21.102486, Train_MMSE: 0.027704, NMMSE: 0.024831, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:24:39] Epoch 176/200, Loss: 21.013742, Train_MMSE: 0.027697, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:25:30] Epoch 177/200, Loss: 21.057882, Train_MMSE: 0.02769, NMMSE: 0.024822, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:26:21] Epoch 178/200, Loss: 21.108023, Train_MMSE: 0.027708, NMMSE: 0.024825, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:27:13] Epoch 179/200, Loss: 21.027592, Train_MMSE: 0.027687, NMMSE: 0.024828, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:28:03] Epoch 180/200, Loss: 21.082251, Train_MMSE: 0.027708, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:28:54] Epoch 181/200, Loss: 21.379377, Train_MMSE: 0.02771, NMMSE: 0.024835, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:29:47] Epoch 182/200, Loss: 20.924309, Train_MMSE: 0.027705, NMMSE: 0.024822, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:30:39] Epoch 183/200, Loss: 21.037252, Train_MMSE: 0.027705, NMMSE: 0.024828, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:31:30] Epoch 184/200, Loss: 20.994486, Train_MMSE: 0.027698, NMMSE: 0.024826, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:32:21] Epoch 185/200, Loss: 21.010942, Train_MMSE: 0.027718, NMMSE: 0.024824, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:33:13] Epoch 186/200, Loss: 21.124311, Train_MMSE: 0.027713, NMMSE: 0.024826, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:34:04] Epoch 187/200, Loss: 21.063799, Train_MMSE: 0.027704, NMMSE: 0.024836, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:34:55] Epoch 188/200, Loss: 20.900785, Train_MMSE: 0.027711, NMMSE: 0.024821, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:35:46] Epoch 189/200, Loss: 21.073999, Train_MMSE: 0.027719, NMMSE: 0.024828, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:36:38] Epoch 190/200, Loss: 21.086367, Train_MMSE: 0.027718, NMMSE: 0.024825, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:37:29] Epoch 191/200, Loss: 21.002213, Train_MMSE: 0.027693, NMMSE: 0.024819, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:38:21] Epoch 192/200, Loss: 21.430098, Train_MMSE: 0.027696, NMMSE: 0.024822, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:39:12] Epoch 193/200, Loss: 21.171476, Train_MMSE: 0.027705, NMMSE: 0.024831, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:40:04] Epoch 194/200, Loss: 21.132288, Train_MMSE: 0.027719, NMMSE: 0.024831, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:40:56] Epoch 195/200, Loss: 21.136911, Train_MMSE: 0.027708, NMMSE: 0.02482, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:41:47] Epoch 196/200, Loss: 21.084990, Train_MMSE: 0.027712, NMMSE: 0.024821, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:42:39] Epoch 197/200, Loss: 21.089142, Train_MMSE: 0.027715, NMMSE: 0.024819, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:43:27] Epoch 198/200, Loss: 21.078468, Train_MMSE: 0.027682, NMMSE: 0.024821, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:44:07] Epoch 199/200, Loss: 21.118721, Train_MMSE: 0.027699, NMMSE: 0.024828, LS_NMSE: 0.040811, Lr: 1e-05
[2025-02-22 20:44:47] Epoch 200/200, Loss: 21.041830, Train_MMSE: 0.027717, NMMSE: 0.024823, LS_NMSE: 0.040811, Lr: 1.0000000000000002e-06
