H shape: (10000, 4, 36) (10000, 4, 36)
NMMSE of valid dataset:: 0.024458686477191807
num samples :: 100000
num valid: 10000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/train_Dataset_dB-10_N36_K4_L4_S9_Setup100_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/test_Dataset_dB-10_N36_K4_L4_S9_Setup10_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}, 'trainer': {'optimizer': 'Adam', 'lr': 0.01, 'weight_decay': 0.001, 'lr_scheduler': 'Plateau', 'lr_gamma': 0.1, 'min_lr': 1e-06, 'patience': 20}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (47): ReLU(inplace=True)
      (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (50): ReLU(inplace=True)
      (51): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 6.80 MB
loss function:: L1Loss()
[2025-02-22 18:12:17] Epoch 1/200, Loss: 27.345995, Train_MMSE: 0.046883, NMMSE: 0.043693, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:13:18] Epoch 2/200, Loss: 26.997843, Train_MMSE: 0.044501, NMMSE: 0.037952, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:14:18] Epoch 3/200, Loss: 26.910957, Train_MMSE: 0.043399, NMMSE: 0.038, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:15:16] Epoch 4/200, Loss: 26.841600, Train_MMSE: 0.042772, NMMSE: 0.037149, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:16:15] Epoch 5/200, Loss: 26.627409, Train_MMSE: 0.04241, NMMSE: 0.037081, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:17:15] Epoch 6/200, Loss: 26.625544, Train_MMSE: 0.042081, NMMSE: 0.037202, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:18:14] Epoch 7/200, Loss: 26.445051, Train_MMSE: 0.041814, NMMSE: 0.036584, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:19:14] Epoch 8/200, Loss: 26.229006, Train_MMSE: 0.041593, NMMSE: 0.036694, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:20:14] Epoch 9/200, Loss: 26.290401, Train_MMSE: 0.041247, NMMSE: 0.035884, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:21:14] Epoch 10/200, Loss: 25.901587, Train_MMSE: 0.040757, NMMSE: 0.035713, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:22:13] Epoch 11/200, Loss: 25.740675, Train_MMSE: 0.040457, NMMSE: 0.035451, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:23:12] Epoch 12/200, Loss: 25.959850, Train_MMSE: 0.040269, NMMSE: 0.035402, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:24:12] Epoch 13/200, Loss: 26.228018, Train_MMSE: 0.040111, NMMSE: 0.035124, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:25:11] Epoch 14/200, Loss: 25.810104, Train_MMSE: 0.039989, NMMSE: 0.035106, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:26:10] Epoch 15/200, Loss: 25.935865, Train_MMSE: 0.039889, NMMSE: 0.035486, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:27:09] Epoch 16/200, Loss: 25.752060, Train_MMSE: 0.039779, NMMSE: 0.034942, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:28:08] Epoch 17/200, Loss: 25.680876, Train_MMSE: 0.039664, NMMSE: 0.034716, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:29:07] Epoch 18/200, Loss: 25.831329, Train_MMSE: 0.039582, NMMSE: 0.034601, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:30:06] Epoch 19/200, Loss: 25.829788, Train_MMSE: 0.039491, NMMSE: 0.03468, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:31:06] Epoch 20/200, Loss: 25.663816, Train_MMSE: 0.039424, NMMSE: 0.034903, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:32:04] Epoch 21/200, Loss: 25.618872, Train_MMSE: 0.039364, NMMSE: 0.034941, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:33:02] Epoch 22/200, Loss: 25.785612, Train_MMSE: 0.039325, NMMSE: 0.034591, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:34:02] Epoch 23/200, Loss: 25.541162, Train_MMSE: 0.039258, NMMSE: 0.035246, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:35:02] Epoch 24/200, Loss: 25.635853, Train_MMSE: 0.039213, NMMSE: 0.034489, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:36:00] Epoch 25/200, Loss: 25.778414, Train_MMSE: 0.039198, NMMSE: 0.034933, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:36:59] Epoch 26/200, Loss: 25.654577, Train_MMSE: 0.039168, NMMSE: 0.034434, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:37:58] Epoch 27/200, Loss: 25.554169, Train_MMSE: 0.039132, NMMSE: 0.292294, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:38:57] Epoch 28/200, Loss: 25.602266, Train_MMSE: 0.0391, NMMSE: 0.034771, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:39:56] Epoch 29/200, Loss: 25.461447, Train_MMSE: 0.039076, NMMSE: 0.034435, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:40:55] Epoch 30/200, Loss: 25.633234, Train_MMSE: 0.039088, NMMSE: 0.034368, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:41:54] Epoch 31/200, Loss: 25.527136, Train_MMSE: 0.039024, NMMSE: 0.034828, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:42:53] Epoch 32/200, Loss: 25.593824, Train_MMSE: 0.039004, NMMSE: 0.03448, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:43:52] Epoch 33/200, Loss: 25.595758, Train_MMSE: 0.039001, NMMSE: 0.034295, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:44:51] Epoch 34/200, Loss: 25.536783, Train_MMSE: 0.038981, NMMSE: 0.035044, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:45:51] Epoch 35/200, Loss: 25.556335, Train_MMSE: 0.038967, NMMSE: 0.034797, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:46:51] Epoch 36/200, Loss: 25.701496, Train_MMSE: 0.038933, NMMSE: 0.034208, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:47:50] Epoch 37/200, Loss: 25.672791, Train_MMSE: 0.03894, NMMSE: 0.034339, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:48:49] Epoch 38/200, Loss: 25.531593, Train_MMSE: 0.038925, NMMSE: 0.034325, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:49:48] Epoch 39/200, Loss: 25.698891, Train_MMSE: 0.038903, NMMSE: 0.034683, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:50:49] Epoch 40/200, Loss: 25.713171, Train_MMSE: 0.038921, NMMSE: 0.034571, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:51:46] Epoch 41/200, Loss: 25.567074, Train_MMSE: 0.038894, NMMSE: 0.034246, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:52:46] Epoch 42/200, Loss: 25.677582, Train_MMSE: 0.038891, NMMSE: 0.034291, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:53:46] Epoch 43/200, Loss: 25.526869, Train_MMSE: 0.038836, NMMSE: 0.034196, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:54:47] Epoch 44/200, Loss: 25.486568, Train_MMSE: 0.038851, NMMSE: 0.034363, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:55:46] Epoch 45/200, Loss: 25.422188, Train_MMSE: 0.038836, NMMSE: 0.034522, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:56:46] Epoch 46/200, Loss: 25.433353, Train_MMSE: 0.038818, NMMSE: 0.03452, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:57:46] Epoch 47/200, Loss: 25.321962, Train_MMSE: 0.038789, NMMSE: 0.034437, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:58:44] Epoch 48/200, Loss: 25.475344, Train_MMSE: 0.038756, NMMSE: 0.03493, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 18:59:44] Epoch 49/200, Loss: 25.430290, Train_MMSE: 0.038769, NMMSE: 0.034568, LS_NMSE: 0.040619, Lr: 0.01
[2025-02-22 19:00:44] Epoch 50/200, Loss: 25.762312, Train_MMSE: 0.038768, NMMSE: 0.035309, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:01:43] Epoch 51/200, Loss: 25.106411, Train_MMSE: 0.038149, NMMSE: 0.033206, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:02:44] Epoch 52/200, Loss: 25.276865, Train_MMSE: 0.038014, NMMSE: 0.033161, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:03:43] Epoch 53/200, Loss: 25.235729, Train_MMSE: 0.037973, NMMSE: 0.033182, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:04:41] Epoch 54/200, Loss: 25.199240, Train_MMSE: 0.037951, NMMSE: 0.033151, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:05:39] Epoch 55/200, Loss: 25.194462, Train_MMSE: 0.037931, NMMSE: 0.033118, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:06:39] Epoch 56/200, Loss: 25.029327, Train_MMSE: 0.037911, NMMSE: 0.033124, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:07:39] Epoch 57/200, Loss: 25.021528, Train_MMSE: 0.037897, NMMSE: 0.033077, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:08:39] Epoch 58/200, Loss: 25.323038, Train_MMSE: 0.037889, NMMSE: 0.033061, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:09:39] Epoch 59/200, Loss: 24.976414, Train_MMSE: 0.037878, NMMSE: 0.033096, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:10:40] Epoch 60/200, Loss: 25.250174, Train_MMSE: 0.037865, NMMSE: 0.033133, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:11:40] Epoch 61/200, Loss: 25.182697, Train_MMSE: 0.037859, NMMSE: 0.033055, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:12:39] Epoch 62/200, Loss: 25.371134, Train_MMSE: 0.037842, NMMSE: 0.033113, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:13:37] Epoch 63/200, Loss: 25.247904, Train_MMSE: 0.03784, NMMSE: 0.033082, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:14:36] Epoch 64/200, Loss: 25.188608, Train_MMSE: 0.037824, NMMSE: 0.033155, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:15:33] Epoch 65/200, Loss: 25.188023, Train_MMSE: 0.037829, NMMSE: 0.033234, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:16:32] Epoch 66/200, Loss: 25.202688, Train_MMSE: 0.0378, NMMSE: 0.033133, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:17:31] Epoch 67/200, Loss: 25.139236, Train_MMSE: 0.037774, NMMSE: 0.033156, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:18:30] Epoch 68/200, Loss: 25.119547, Train_MMSE: 0.037775, NMMSE: 0.03308, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:19:30] Epoch 69/200, Loss: 25.050697, Train_MMSE: 0.037756, NMMSE: 0.033057, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:20:29] Epoch 70/200, Loss: 24.985699, Train_MMSE: 0.037747, NMMSE: 0.033167, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:21:30] Epoch 71/200, Loss: 25.181166, Train_MMSE: 0.037732, NMMSE: 0.033025, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:22:29] Epoch 72/200, Loss: 25.085810, Train_MMSE: 0.037735, NMMSE: 0.033047, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:23:27] Epoch 73/200, Loss: 25.151075, Train_MMSE: 0.037727, NMMSE: 0.033074, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:24:26] Epoch 74/200, Loss: 25.142189, Train_MMSE: 0.037705, NMMSE: 0.032969, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:25:26] Epoch 75/200, Loss: 25.087566, Train_MMSE: 0.037701, NMMSE: 0.033092, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:26:25] Epoch 76/200, Loss: 25.318949, Train_MMSE: 0.037692, NMMSE: 0.032999, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:27:24] Epoch 77/200, Loss: 25.060261, Train_MMSE: 0.037676, NMMSE: 0.033058, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:28:25] Epoch 78/200, Loss: 25.217754, Train_MMSE: 0.037673, NMMSE: 0.033197, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:29:23] Epoch 79/200, Loss: 25.135738, Train_MMSE: 0.037667, NMMSE: 0.032933, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:30:24] Epoch 80/200, Loss: 25.109632, Train_MMSE: 0.037659, NMMSE: 0.033033, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:31:24] Epoch 81/200, Loss: 25.139917, Train_MMSE: 0.037659, NMMSE: 0.033016, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:32:22] Epoch 82/200, Loss: 25.255829, Train_MMSE: 0.037656, NMMSE: 0.032912, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:33:21] Epoch 83/200, Loss: 25.157736, Train_MMSE: 0.03764, NMMSE: 0.032933, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:34:21] Epoch 84/200, Loss: 25.179945, Train_MMSE: 0.03763, NMMSE: 0.03293, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:35:21] Epoch 85/200, Loss: 25.093855, Train_MMSE: 0.037627, NMMSE: 0.032897, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:36:21] Epoch 86/200, Loss: 25.265390, Train_MMSE: 0.037624, NMMSE: 0.03296, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:37:22] Epoch 87/200, Loss: 25.171303, Train_MMSE: 0.037617, NMMSE: 0.033007, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:38:23] Epoch 88/200, Loss: 25.137239, Train_MMSE: 0.0376, NMMSE: 0.032959, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:39:24] Epoch 89/200, Loss: 25.220236, Train_MMSE: 0.037597, NMMSE: 0.032885, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:40:24] Epoch 90/200, Loss: 25.102541, Train_MMSE: 0.03758, NMMSE: 0.032827, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:41:23] Epoch 91/200, Loss: 25.138958, Train_MMSE: 0.037579, NMMSE: 0.032956, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:42:22] Epoch 92/200, Loss: 25.007574, Train_MMSE: 0.037565, NMMSE: 0.032947, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:43:21] Epoch 93/200, Loss: 25.096615, Train_MMSE: 0.03756, NMMSE: 0.03282, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:44:20] Epoch 94/200, Loss: 25.076263, Train_MMSE: 0.037557, NMMSE: 0.032929, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:45:19] Epoch 95/200, Loss: 25.078203, Train_MMSE: 0.037551, NMMSE: 0.032917, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:46:19] Epoch 96/200, Loss: 24.988710, Train_MMSE: 0.037541, NMMSE: 0.032956, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:47:17] Epoch 97/200, Loss: 25.049927, Train_MMSE: 0.037533, NMMSE: 0.032941, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:48:17] Epoch 98/200, Loss: 24.952185, Train_MMSE: 0.037536, NMMSE: 0.032979, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:49:16] Epoch 99/200, Loss: 25.059092, Train_MMSE: 0.037534, NMMSE: 0.032846, LS_NMSE: 0.040619, Lr: 0.001
[2025-02-22 19:50:15] Epoch 100/200, Loss: 25.018785, Train_MMSE: 0.037515, NMMSE: 0.032834, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:51:14] Epoch 101/200, Loss: 25.157230, Train_MMSE: 0.037352, NMMSE: 0.032651, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:52:14] Epoch 102/200, Loss: 24.948872, Train_MMSE: 0.037333, NMMSE: 0.032646, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:53:15] Epoch 103/200, Loss: 24.931202, Train_MMSE: 0.037328, NMMSE: 0.032647, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:54:14] Epoch 104/200, Loss: 24.892679, Train_MMSE: 0.037321, NMMSE: 0.032642, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:55:14] Epoch 105/200, Loss: 24.994318, Train_MMSE: 0.037318, NMMSE: 0.032644, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:56:13] Epoch 106/200, Loss: 25.033464, Train_MMSE: 0.037317, NMMSE: 0.032644, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:57:13] Epoch 107/200, Loss: 24.686584, Train_MMSE: 0.037311, NMMSE: 0.032646, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:58:11] Epoch 108/200, Loss: 25.051559, Train_MMSE: 0.037305, NMMSE: 0.032625, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 19:59:10] Epoch 109/200, Loss: 24.966280, Train_MMSE: 0.037305, NMMSE: 0.03262, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:00:10] Epoch 110/200, Loss: 25.073717, Train_MMSE: 0.037299, NMMSE: 0.032628, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:01:10] Epoch 111/200, Loss: 25.142326, Train_MMSE: 0.037297, NMMSE: 0.032623, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:02:10] Epoch 112/200, Loss: 24.917038, Train_MMSE: 0.037295, NMMSE: 0.032628, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:03:08] Epoch 113/200, Loss: 25.059975, Train_MMSE: 0.037292, NMMSE: 0.032614, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:04:08] Epoch 114/200, Loss: 25.158897, Train_MMSE: 0.037289, NMMSE: 0.032632, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:05:09] Epoch 115/200, Loss: 25.002806, Train_MMSE: 0.037285, NMMSE: 0.032613, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:06:09] Epoch 116/200, Loss: 24.875393, Train_MMSE: 0.037282, NMMSE: 0.032623, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:07:08] Epoch 117/200, Loss: 25.103315, Train_MMSE: 0.037283, NMMSE: 0.032615, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:08:07] Epoch 118/200, Loss: 24.975752, Train_MMSE: 0.037282, NMMSE: 0.032639, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:09:05] Epoch 119/200, Loss: 24.978104, Train_MMSE: 0.037277, NMMSE: 0.032612, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:10:03] Epoch 120/200, Loss: 25.078033, Train_MMSE: 0.037275, NMMSE: 0.032615, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:11:03] Epoch 121/200, Loss: 24.831539, Train_MMSE: 0.037271, NMMSE: 0.032615, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:12:03] Epoch 122/200, Loss: 24.943289, Train_MMSE: 0.03727, NMMSE: 0.032602, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:13:01] Epoch 123/200, Loss: 25.030600, Train_MMSE: 0.037272, NMMSE: 0.032608, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:14:00] Epoch 124/200, Loss: 24.968914, Train_MMSE: 0.037265, NMMSE: 0.032599, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:14:58] Epoch 125/200, Loss: 25.061649, Train_MMSE: 0.037259, NMMSE: 0.032601, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:15:58] Epoch 126/200, Loss: 25.015999, Train_MMSE: 0.037266, NMMSE: 0.032586, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:16:57] Epoch 127/200, Loss: 24.957071, Train_MMSE: 0.03726, NMMSE: 0.032613, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:17:55] Epoch 128/200, Loss: 25.065359, Train_MMSE: 0.03726, NMMSE: 0.032601, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:18:55] Epoch 129/200, Loss: 24.847534, Train_MMSE: 0.037256, NMMSE: 0.032592, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:19:55] Epoch 130/200, Loss: 24.923494, Train_MMSE: 0.037252, NMMSE: 0.032587, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:20:54] Epoch 131/200, Loss: 24.880650, Train_MMSE: 0.037253, NMMSE: 0.032602, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:21:53] Epoch 132/200, Loss: 24.683416, Train_MMSE: 0.037251, NMMSE: 0.032602, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:22:51] Epoch 133/200, Loss: 25.021723, Train_MMSE: 0.03725, NMMSE: 0.032589, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:23:51] Epoch 134/200, Loss: 25.105616, Train_MMSE: 0.037244, NMMSE: 0.032575, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:24:51] Epoch 135/200, Loss: 24.808939, Train_MMSE: 0.037249, NMMSE: 0.032582, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:25:51] Epoch 136/200, Loss: 25.130882, Train_MMSE: 0.037241, NMMSE: 0.032589, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:26:50] Epoch 137/200, Loss: 25.000153, Train_MMSE: 0.037246, NMMSE: 0.03259, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:27:48] Epoch 138/200, Loss: 24.901669, Train_MMSE: 0.037243, NMMSE: 0.032582, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:28:47] Epoch 139/200, Loss: 25.001575, Train_MMSE: 0.037242, NMMSE: 0.032585, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:29:46] Epoch 140/200, Loss: 25.067474, Train_MMSE: 0.037237, NMMSE: 0.032597, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:30:45] Epoch 141/200, Loss: 24.997074, Train_MMSE: 0.037234, NMMSE: 0.032585, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:31:46] Epoch 142/200, Loss: 25.064222, Train_MMSE: 0.037239, NMMSE: 0.032586, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:32:45] Epoch 143/200, Loss: 24.923029, Train_MMSE: 0.037232, NMMSE: 0.032586, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:33:46] Epoch 144/200, Loss: 25.025869, Train_MMSE: 0.037234, NMMSE: 0.032587, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:34:45] Epoch 145/200, Loss: 24.871258, Train_MMSE: 0.037232, NMMSE: 0.032587, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:35:45] Epoch 146/200, Loss: 24.911291, Train_MMSE: 0.037229, NMMSE: 0.03259, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:36:43] Epoch 147/200, Loss: 24.954786, Train_MMSE: 0.037233, NMMSE: 0.032568, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:37:41] Epoch 148/200, Loss: 25.078211, Train_MMSE: 0.037226, NMMSE: 0.032564, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:38:40] Epoch 149/200, Loss: 24.844160, Train_MMSE: 0.037224, NMMSE: 0.032567, LS_NMSE: 0.040619, Lr: 0.0001
[2025-02-22 20:39:39] Epoch 150/200, Loss: 24.920750, Train_MMSE: 0.037226, NMMSE: 0.032569, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:40:37] Epoch 151/200, Loss: 24.966120, Train_MMSE: 0.037198, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:41:37] Epoch 152/200, Loss: 24.793348, Train_MMSE: 0.037197, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:42:34] Epoch 153/200, Loss: 24.935221, Train_MMSE: 0.037191, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:43:30] Epoch 154/200, Loss: 24.985285, Train_MMSE: 0.03719, NMMSE: 0.032546, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:44:24] Epoch 155/200, Loss: 24.752174, Train_MMSE: 0.037192, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:45:14] Epoch 156/200, Loss: 24.835381, Train_MMSE: 0.03719, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:46:00] Epoch 157/200, Loss: 24.934376, Train_MMSE: 0.037191, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:46:46] Epoch 158/200, Loss: 24.867306, Train_MMSE: 0.037195, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:47:31] Epoch 159/200, Loss: 24.796780, Train_MMSE: 0.03719, NMMSE: 0.032541, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:48:18] Epoch 160/200, Loss: 24.971661, Train_MMSE: 0.037189, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:49:04] Epoch 161/200, Loss: 25.212627, Train_MMSE: 0.037193, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:49:51] Epoch 162/200, Loss: 24.850256, Train_MMSE: 0.037189, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:50:36] Epoch 163/200, Loss: 25.088036, Train_MMSE: 0.037192, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:51:23] Epoch 164/200, Loss: 25.053387, Train_MMSE: 0.037189, NMMSE: 0.03255, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:52:09] Epoch 165/200, Loss: 25.036493, Train_MMSE: 0.037193, NMMSE: 0.03255, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:52:55] Epoch 166/200, Loss: 24.865595, Train_MMSE: 0.037192, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:53:42] Epoch 167/200, Loss: 24.875944, Train_MMSE: 0.037191, NMMSE: 0.032549, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:54:29] Epoch 168/200, Loss: 24.883820, Train_MMSE: 0.037192, NMMSE: 0.032542, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:55:17] Epoch 169/200, Loss: 24.973989, Train_MMSE: 0.037189, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:56:02] Epoch 170/200, Loss: 25.000828, Train_MMSE: 0.03719, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:56:49] Epoch 171/200, Loss: 24.951591, Train_MMSE: 0.037192, NMMSE: 0.032547, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:57:35] Epoch 172/200, Loss: 24.897293, Train_MMSE: 0.037192, NMMSE: 0.032549, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:58:23] Epoch 173/200, Loss: 24.966068, Train_MMSE: 0.037189, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:59:10] Epoch 174/200, Loss: 24.889143, Train_MMSE: 0.037185, NMMSE: 0.032548, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 20:59:58] Epoch 175/200, Loss: 24.867691, Train_MMSE: 0.037189, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:00:45] Epoch 176/200, Loss: 24.811638, Train_MMSE: 0.037187, NMMSE: 0.032545, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:01:32] Epoch 177/200, Loss: 25.149866, Train_MMSE: 0.037184, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:02:18] Epoch 178/200, Loss: 25.003290, Train_MMSE: 0.037186, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:03:04] Epoch 179/200, Loss: 24.876303, Train_MMSE: 0.037189, NMMSE: 0.032542, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:03:53] Epoch 180/200, Loss: 24.867855, Train_MMSE: 0.037185, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:04:40] Epoch 181/200, Loss: 24.975651, Train_MMSE: 0.037186, NMMSE: 0.032546, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:05:27] Epoch 182/200, Loss: 24.773895, Train_MMSE: 0.037185, NMMSE: 0.032538, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:06:14] Epoch 183/200, Loss: 24.825880, Train_MMSE: 0.037184, NMMSE: 0.032554, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:07:01] Epoch 184/200, Loss: 25.110994, Train_MMSE: 0.037186, NMMSE: 0.032541, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:07:47] Epoch 185/200, Loss: 24.851940, Train_MMSE: 0.037185, NMMSE: 0.032544, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:08:35] Epoch 186/200, Loss: 25.083368, Train_MMSE: 0.037183, NMMSE: 0.03254, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:09:21] Epoch 187/200, Loss: 24.926405, Train_MMSE: 0.037183, NMMSE: 0.032539, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:10:08] Epoch 188/200, Loss: 25.022951, Train_MMSE: 0.037185, NMMSE: 0.032541, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:10:52] Epoch 189/200, Loss: 24.960344, Train_MMSE: 0.037187, NMMSE: 0.032563, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:11:40] Epoch 190/200, Loss: 24.794947, Train_MMSE: 0.037185, NMMSE: 0.03254, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:12:26] Epoch 191/200, Loss: 25.010891, Train_MMSE: 0.037185, NMMSE: 0.032541, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:13:12] Epoch 192/200, Loss: 25.064026, Train_MMSE: 0.037184, NMMSE: 0.03254, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:13:59] Epoch 193/200, Loss: 25.077393, Train_MMSE: 0.037181, NMMSE: 0.032539, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:14:45] Epoch 194/200, Loss: 24.956804, Train_MMSE: 0.037181, NMMSE: 0.032539, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:15:32] Epoch 195/200, Loss: 24.768486, Train_MMSE: 0.037186, NMMSE: 0.032537, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:16:18] Epoch 196/200, Loss: 24.905914, Train_MMSE: 0.037183, NMMSE: 0.032541, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:17:04] Epoch 197/200, Loss: 25.036404, Train_MMSE: 0.037185, NMMSE: 0.03254, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:17:50] Epoch 198/200, Loss: 25.034227, Train_MMSE: 0.037181, NMMSE: 0.03254, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:18:36] Epoch 199/200, Loss: 25.011526, Train_MMSE: 0.037182, NMMSE: 0.032538, LS_NMSE: 0.040619, Lr: 1e-05
[2025-02-22 21:19:09] Epoch 200/200, Loss: 24.999168, Train_MMSE: 0.03718, NMMSE: 0.032543, LS_NMSE: 0.040619, Lr: 1.0000000000000002e-06
