H shape: (10000, 4, 36) (10000, 4, 36)
NMMSE of valid dataset:: 0.055706420795849976
num samples :: 100000
num valid: 10000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/train_Dataset_dB-10_N36_K4_L2_S9_Setup100_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/test_Dataset_dB-10_N36_K4_L2_S9_Setup10_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}, 'trainer': {'optimizer': 'Adam', 'lr': 0.01, 'weight_decay': 0.001, 'lr_scheduler': 'Plateau', 'lr_gamma': 0.1, 'min_lr': 1e-06, 'patience': 20}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (47): ReLU(inplace=True)
      (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (50): ReLU(inplace=True)
      (51): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 6.80 MB
loss function:: L1Loss()
[2025-02-22 18:12:50] Epoch 1/200, Loss: 53.547863, Train_MMSE: 0.220515, NMMSE: 0.172051, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:13:49] Epoch 2/200, Loss: 46.928650, Train_MMSE: 0.154955, NMMSE: 0.12818, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:14:46] Epoch 3/200, Loss: 42.345276, Train_MMSE: 0.124291, NMMSE: 0.105955, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:15:44] Epoch 4/200, Loss: 41.402576, Train_MMSE: 0.110217, NMMSE: 0.09878, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:16:43] Epoch 5/200, Loss: 40.620552, Train_MMSE: 0.104654, NMMSE: 0.095786, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:17:42] Epoch 6/200, Loss: 40.376621, Train_MMSE: 0.101705, NMMSE: 0.094616, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:18:41] Epoch 7/200, Loss: 39.762188, Train_MMSE: 0.100083, NMMSE: 0.095454, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:19:39] Epoch 8/200, Loss: 39.300495, Train_MMSE: 0.098955, NMMSE: 0.090771, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:20:39] Epoch 9/200, Loss: 39.309464, Train_MMSE: 0.098133, NMMSE: 0.090799, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:21:39] Epoch 10/200, Loss: 39.633877, Train_MMSE: 0.097427, NMMSE: 0.092432, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:22:37] Epoch 11/200, Loss: 39.302795, Train_MMSE: 0.09667, NMMSE: 0.092849, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:23:35] Epoch 12/200, Loss: 38.976910, Train_MMSE: 0.096191, NMMSE: 0.089708, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:24:32] Epoch 13/200, Loss: 39.179199, Train_MMSE: 0.095867, NMMSE: 0.089084, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:25:32] Epoch 14/200, Loss: 39.151245, Train_MMSE: 0.095335, NMMSE: 0.090001, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:26:30] Epoch 15/200, Loss: 38.822548, Train_MMSE: 0.095104, NMMSE: 0.088024, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:27:28] Epoch 16/200, Loss: 38.440620, Train_MMSE: 0.094783, NMMSE: 0.088057, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:28:27] Epoch 17/200, Loss: 38.905426, Train_MMSE: 0.094596, NMMSE: 0.087932, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:29:26] Epoch 18/200, Loss: 38.826241, Train_MMSE: 0.094345, NMMSE: 0.089583, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:30:24] Epoch 19/200, Loss: 38.495911, Train_MMSE: 0.093967, NMMSE: 0.087855, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:31:23] Epoch 20/200, Loss: 38.105198, Train_MMSE: 0.093848, NMMSE: 0.08662, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:32:22] Epoch 21/200, Loss: 38.806629, Train_MMSE: 0.093544, NMMSE: 0.089877, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:33:22] Epoch 22/200, Loss: 38.778839, Train_MMSE: 0.093339, NMMSE: 0.086924, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:34:22] Epoch 23/200, Loss: 38.217106, Train_MMSE: 0.09327, NMMSE: 0.088811, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:35:21] Epoch 24/200, Loss: 38.392597, Train_MMSE: 0.093006, NMMSE: 0.088849, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:36:21] Epoch 25/200, Loss: 38.479664, Train_MMSE: 0.092952, NMMSE: 0.085702, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:37:21] Epoch 26/200, Loss: 38.213596, Train_MMSE: 0.09282, NMMSE: 0.087301, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:38:21] Epoch 27/200, Loss: 38.742889, Train_MMSE: 0.092676, NMMSE: 0.087651, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:39:20] Epoch 28/200, Loss: 38.536037, Train_MMSE: 0.092604, NMMSE: 0.086967, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:40:19] Epoch 29/200, Loss: 38.437977, Train_MMSE: 0.092354, NMMSE: 0.085235, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:41:20] Epoch 30/200, Loss: 38.242527, Train_MMSE: 0.092204, NMMSE: 0.088201, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:42:18] Epoch 31/200, Loss: 37.893024, Train_MMSE: 0.092102, NMMSE: 0.08601, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:43:17] Epoch 32/200, Loss: 38.058540, Train_MMSE: 0.092011, NMMSE: 0.086325, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:44:16] Epoch 33/200, Loss: 37.727867, Train_MMSE: 0.091984, NMMSE: 0.086126, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:45:14] Epoch 34/200, Loss: 38.687511, Train_MMSE: 0.091857, NMMSE: 0.087953, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:46:13] Epoch 35/200, Loss: 38.437725, Train_MMSE: 0.091723, NMMSE: 0.08596, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:47:11] Epoch 36/200, Loss: 37.927299, Train_MMSE: 0.091528, NMMSE: 0.087997, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:48:10] Epoch 37/200, Loss: 37.855301, Train_MMSE: 0.091587, NMMSE: 0.085093, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:49:08] Epoch 38/200, Loss: 37.683868, Train_MMSE: 0.091474, NMMSE: 0.085805, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:50:08] Epoch 39/200, Loss: 38.336296, Train_MMSE: 0.091381, NMMSE: 0.086658, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:51:08] Epoch 40/200, Loss: 38.391273, Train_MMSE: 0.091406, NMMSE: 0.086287, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:52:07] Epoch 41/200, Loss: 37.771320, Train_MMSE: 0.091159, NMMSE: 0.087256, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:53:06] Epoch 42/200, Loss: 38.385494, Train_MMSE: 0.091077, NMMSE: 0.087898, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:54:05] Epoch 43/200, Loss: 38.087635, Train_MMSE: 0.091173, NMMSE: 0.085628, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:55:04] Epoch 44/200, Loss: 37.920326, Train_MMSE: 0.090956, NMMSE: 0.084336, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:56:04] Epoch 45/200, Loss: 37.851295, Train_MMSE: 0.091021, NMMSE: 0.086899, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:57:03] Epoch 46/200, Loss: 37.842888, Train_MMSE: 0.090768, NMMSE: 0.084271, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:58:03] Epoch 47/200, Loss: 37.670525, Train_MMSE: 0.090721, NMMSE: 0.084462, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 18:59:02] Epoch 48/200, Loss: 37.587967, Train_MMSE: 0.090627, NMMSE: 0.088636, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 19:00:01] Epoch 49/200, Loss: 38.636387, Train_MMSE: 0.09071, NMMSE: 0.085041, LS_NMSE: 0.242602, Lr: 0.01
[2025-02-22 19:01:01] Epoch 50/200, Loss: 37.804371, Train_MMSE: 0.090575, NMMSE: 0.085885, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:02:01] Epoch 51/200, Loss: 36.502266, Train_MMSE: 0.085018, NMMSE: 0.077455, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:03:02] Epoch 52/200, Loss: 36.319454, Train_MMSE: 0.083765, NMMSE: 0.077088, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:03:58] Epoch 53/200, Loss: 36.008720, Train_MMSE: 0.083392, NMMSE: 0.076797, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:04:56] Epoch 54/200, Loss: 36.329762, Train_MMSE: 0.083082, NMMSE: 0.076918, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:05:54] Epoch 55/200, Loss: 35.687229, Train_MMSE: 0.082862, NMMSE: 0.076516, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:06:54] Epoch 56/200, Loss: 36.026085, Train_MMSE: 0.082671, NMMSE: 0.076552, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:07:53] Epoch 57/200, Loss: 36.005951, Train_MMSE: 0.082475, NMMSE: 0.076086, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:08:53] Epoch 58/200, Loss: 36.037895, Train_MMSE: 0.08227, NMMSE: 0.076346, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:09:51] Epoch 59/200, Loss: 36.350372, Train_MMSE: 0.082142, NMMSE: 0.075869, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:10:51] Epoch 60/200, Loss: 36.138721, Train_MMSE: 0.082063, NMMSE: 0.076235, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:11:50] Epoch 61/200, Loss: 35.987316, Train_MMSE: 0.081841, NMMSE: 0.076131, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:12:50] Epoch 62/200, Loss: 36.068939, Train_MMSE: 0.081765, NMMSE: 0.075588, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:13:48] Epoch 63/200, Loss: 35.656391, Train_MMSE: 0.081683, NMMSE: 0.076174, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:14:47] Epoch 64/200, Loss: 35.972919, Train_MMSE: 0.081546, NMMSE: 0.076083, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:15:46] Epoch 65/200, Loss: 35.796608, Train_MMSE: 0.081438, NMMSE: 0.075736, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:16:45] Epoch 66/200, Loss: 35.637531, Train_MMSE: 0.081345, NMMSE: 0.075963, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:17:44] Epoch 67/200, Loss: 35.863014, Train_MMSE: 0.081343, NMMSE: 0.076236, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:18:43] Epoch 68/200, Loss: 35.564411, Train_MMSE: 0.081248, NMMSE: 0.076674, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:19:42] Epoch 69/200, Loss: 35.952316, Train_MMSE: 0.081101, NMMSE: 0.075597, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:20:41] Epoch 70/200, Loss: 35.984253, Train_MMSE: 0.081044, NMMSE: 0.075739, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:21:41] Epoch 71/200, Loss: 35.579582, Train_MMSE: 0.080949, NMMSE: 0.075369, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:22:40] Epoch 72/200, Loss: 36.109226, Train_MMSE: 0.080948, NMMSE: 0.075112, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:23:39] Epoch 73/200, Loss: 35.857452, Train_MMSE: 0.080845, NMMSE: 0.076215, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:24:38] Epoch 74/200, Loss: 35.511398, Train_MMSE: 0.080787, NMMSE: 0.075314, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:25:38] Epoch 75/200, Loss: 35.795254, Train_MMSE: 0.080766, NMMSE: 0.075013, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:26:36] Epoch 76/200, Loss: 35.561569, Train_MMSE: 0.080684, NMMSE: 0.075251, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:27:36] Epoch 77/200, Loss: 35.763123, Train_MMSE: 0.080635, NMMSE: 0.075002, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:28:36] Epoch 78/200, Loss: 35.780750, Train_MMSE: 0.080572, NMMSE: 0.07512, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:29:33] Epoch 79/200, Loss: 35.399815, Train_MMSE: 0.080529, NMMSE: 0.075417, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:30:33] Epoch 80/200, Loss: 35.651356, Train_MMSE: 0.080509, NMMSE: 0.075399, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:31:33] Epoch 81/200, Loss: 35.287647, Train_MMSE: 0.080482, NMMSE: 0.074955, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:32:32] Epoch 82/200, Loss: 35.282341, Train_MMSE: 0.080362, NMMSE: 0.074903, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:33:31] Epoch 83/200, Loss: 35.856804, Train_MMSE: 0.080436, NMMSE: 0.075312, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:34:30] Epoch 84/200, Loss: 35.587791, Train_MMSE: 0.080306, NMMSE: 0.074557, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:35:29] Epoch 85/200, Loss: 35.540108, Train_MMSE: 0.080319, NMMSE: 0.07514, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:36:30] Epoch 86/200, Loss: 35.644699, Train_MMSE: 0.080278, NMMSE: 0.075448, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:37:30] Epoch 87/200, Loss: 35.475269, Train_MMSE: 0.080192, NMMSE: 0.075564, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:38:29] Epoch 88/200, Loss: 35.466663, Train_MMSE: 0.080147, NMMSE: 0.074819, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:39:29] Epoch 89/200, Loss: 35.691200, Train_MMSE: 0.08016, NMMSE: 0.07493, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:40:30] Epoch 90/200, Loss: 35.423744, Train_MMSE: 0.08009, NMMSE: 0.074981, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:41:29] Epoch 91/200, Loss: 35.466492, Train_MMSE: 0.080059, NMMSE: 0.075096, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:42:28] Epoch 92/200, Loss: 35.306747, Train_MMSE: 0.080034, NMMSE: 0.075398, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:43:28] Epoch 93/200, Loss: 35.510838, Train_MMSE: 0.080081, NMMSE: 0.075005, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:44:28] Epoch 94/200, Loss: 35.277504, Train_MMSE: 0.079944, NMMSE: 0.074668, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:45:27] Epoch 95/200, Loss: 35.973598, Train_MMSE: 0.079962, NMMSE: 0.07488, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:46:28] Epoch 96/200, Loss: 35.829601, Train_MMSE: 0.079984, NMMSE: 0.075124, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:47:27] Epoch 97/200, Loss: 35.565735, Train_MMSE: 0.079897, NMMSE: 0.074412, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:48:27] Epoch 98/200, Loss: 35.216618, Train_MMSE: 0.079845, NMMSE: 0.074849, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:49:27] Epoch 99/200, Loss: 35.702816, Train_MMSE: 0.07984, NMMSE: 0.074645, LS_NMSE: 0.242602, Lr: 0.001
[2025-02-22 19:50:27] Epoch 100/200, Loss: 35.285217, Train_MMSE: 0.079808, NMMSE: 0.074953, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:51:28] Epoch 101/200, Loss: 35.074471, Train_MMSE: 0.078193, NMMSE: 0.072985, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:52:28] Epoch 102/200, Loss: 34.608444, Train_MMSE: 0.07797, NMMSE: 0.072978, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:53:29] Epoch 103/200, Loss: 35.165997, Train_MMSE: 0.077898, NMMSE: 0.072921, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:54:26] Epoch 104/200, Loss: 35.114819, Train_MMSE: 0.077848, NMMSE: 0.072898, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:55:25] Epoch 105/200, Loss: 34.920467, Train_MMSE: 0.077826, NMMSE: 0.072952, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:56:25] Epoch 106/200, Loss: 34.655277, Train_MMSE: 0.077791, NMMSE: 0.072905, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:57:25] Epoch 107/200, Loss: 34.993484, Train_MMSE: 0.077764, NMMSE: 0.072864, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:58:23] Epoch 108/200, Loss: 34.908356, Train_MMSE: 0.077758, NMMSE: 0.072925, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 19:59:21] Epoch 109/200, Loss: 35.175556, Train_MMSE: 0.077735, NMMSE: 0.072914, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:00:21] Epoch 110/200, Loss: 35.051121, Train_MMSE: 0.077698, NMMSE: 0.072868, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:01:22] Epoch 111/200, Loss: 34.969296, Train_MMSE: 0.077687, NMMSE: 0.072879, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:02:21] Epoch 112/200, Loss: 35.444801, Train_MMSE: 0.07765, NMMSE: 0.07298, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:03:19] Epoch 113/200, Loss: 35.002117, Train_MMSE: 0.077626, NMMSE: 0.072931, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:04:18] Epoch 114/200, Loss: 35.003304, Train_MMSE: 0.077633, NMMSE: 0.072863, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:05:19] Epoch 115/200, Loss: 34.886280, Train_MMSE: 0.077592, NMMSE: 0.072906, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:06:18] Epoch 116/200, Loss: 35.336048, Train_MMSE: 0.077583, NMMSE: 0.072791, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:07:17] Epoch 117/200, Loss: 35.116291, Train_MMSE: 0.077563, NMMSE: 0.072849, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:08:16] Epoch 118/200, Loss: 34.678108, Train_MMSE: 0.077544, NMMSE: 0.07283, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:09:14] Epoch 119/200, Loss: 34.612835, Train_MMSE: 0.077533, NMMSE: 0.072916, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:10:13] Epoch 120/200, Loss: 35.140152, Train_MMSE: 0.077513, NMMSE: 0.072829, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:11:13] Epoch 121/200, Loss: 35.032818, Train_MMSE: 0.07748, NMMSE: 0.072894, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:12:12] Epoch 122/200, Loss: 34.615479, Train_MMSE: 0.077472, NMMSE: 0.07281, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:13:10] Epoch 123/200, Loss: 34.784325, Train_MMSE: 0.077481, NMMSE: 0.073021, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:14:08] Epoch 124/200, Loss: 34.776154, Train_MMSE: 0.077454, NMMSE: 0.072852, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:15:06] Epoch 125/200, Loss: 34.574551, Train_MMSE: 0.07745, NMMSE: 0.072884, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:16:05] Epoch 126/200, Loss: 34.764202, Train_MMSE: 0.077427, NMMSE: 0.072825, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:17:05] Epoch 127/200, Loss: 35.067039, Train_MMSE: 0.077415, NMMSE: 0.072916, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:18:05] Epoch 128/200, Loss: 34.449646, Train_MMSE: 0.077407, NMMSE: 0.073017, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:19:04] Epoch 129/200, Loss: 34.946674, Train_MMSE: 0.077391, NMMSE: 0.072776, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:20:03] Epoch 130/200, Loss: 35.050171, Train_MMSE: 0.077377, NMMSE: 0.072802, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:21:03] Epoch 131/200, Loss: 35.224529, Train_MMSE: 0.077378, NMMSE: 0.072772, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:22:02] Epoch 132/200, Loss: 34.877033, Train_MMSE: 0.077346, NMMSE: 0.072735, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:23:00] Epoch 133/200, Loss: 34.514534, Train_MMSE: 0.077337, NMMSE: 0.072812, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:23:59] Epoch 134/200, Loss: 34.830288, Train_MMSE: 0.07732, NMMSE: 0.072786, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:24:59] Epoch 135/200, Loss: 34.768837, Train_MMSE: 0.077316, NMMSE: 0.072743, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:25:57] Epoch 136/200, Loss: 34.869740, Train_MMSE: 0.077301, NMMSE: 0.072877, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:26:57] Epoch 137/200, Loss: 34.921856, Train_MMSE: 0.077292, NMMSE: 0.072732, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:27:57] Epoch 138/200, Loss: 34.839184, Train_MMSE: 0.077286, NMMSE: 0.072713, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:28:56] Epoch 139/200, Loss: 34.995533, Train_MMSE: 0.077267, NMMSE: 0.072862, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:29:56] Epoch 140/200, Loss: 35.136845, Train_MMSE: 0.077259, NMMSE: 0.072712, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:30:56] Epoch 141/200, Loss: 34.816101, Train_MMSE: 0.077253, NMMSE: 0.072694, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:31:56] Epoch 142/200, Loss: 34.790134, Train_MMSE: 0.077239, NMMSE: 0.072699, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:32:56] Epoch 143/200, Loss: 34.926094, Train_MMSE: 0.077224, NMMSE: 0.072672, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:33:55] Epoch 144/200, Loss: 34.677311, Train_MMSE: 0.07721, NMMSE: 0.0727, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:34:54] Epoch 145/200, Loss: 34.569656, Train_MMSE: 0.077207, NMMSE: 0.072665, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:35:54] Epoch 146/200, Loss: 35.048809, Train_MMSE: 0.077171, NMMSE: 0.07271, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:36:53] Epoch 147/200, Loss: 34.411270, Train_MMSE: 0.077188, NMMSE: 0.072717, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:37:51] Epoch 148/200, Loss: 34.856255, Train_MMSE: 0.077172, NMMSE: 0.072683, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:38:49] Epoch 149/200, Loss: 35.134392, Train_MMSE: 0.077168, NMMSE: 0.072755, LS_NMSE: 0.242602, Lr: 0.0001
[2025-02-22 20:39:49] Epoch 150/200, Loss: 35.071735, Train_MMSE: 0.077154, NMMSE: 0.07261, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:40:47] Epoch 151/200, Loss: 34.555958, Train_MMSE: 0.076868, NMMSE: 0.072461, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:41:46] Epoch 152/200, Loss: 34.631481, Train_MMSE: 0.076831, NMMSE: 0.072451, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:42:42] Epoch 153/200, Loss: 34.566250, Train_MMSE: 0.076829, NMMSE: 0.07247, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:43:38] Epoch 154/200, Loss: 34.948196, Train_MMSE: 0.07683, NMMSE: 0.072455, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:44:32] Epoch 155/200, Loss: 34.696655, Train_MMSE: 0.076831, NMMSE: 0.072443, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:45:20] Epoch 156/200, Loss: 34.793430, Train_MMSE: 0.076826, NMMSE: 0.072458, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:46:06] Epoch 157/200, Loss: 34.840977, Train_MMSE: 0.076827, NMMSE: 0.072461, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:46:52] Epoch 158/200, Loss: 34.670719, Train_MMSE: 0.076821, NMMSE: 0.072455, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:47:39] Epoch 159/200, Loss: 34.635036, Train_MMSE: 0.076816, NMMSE: 0.072474, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:48:25] Epoch 160/200, Loss: 34.486073, Train_MMSE: 0.07682, NMMSE: 0.072449, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:49:12] Epoch 161/200, Loss: 34.803284, Train_MMSE: 0.076825, NMMSE: 0.072447, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:49:58] Epoch 162/200, Loss: 34.650352, Train_MMSE: 0.076815, NMMSE: 0.072455, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:50:42] Epoch 163/200, Loss: 34.630482, Train_MMSE: 0.076822, NMMSE: 0.072464, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:51:29] Epoch 164/200, Loss: 34.556473, Train_MMSE: 0.076817, NMMSE: 0.072469, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:52:14] Epoch 165/200, Loss: 34.497486, Train_MMSE: 0.076807, NMMSE: 0.072457, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:52:59] Epoch 166/200, Loss: 34.551754, Train_MMSE: 0.076816, NMMSE: 0.07246, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:53:45] Epoch 167/200, Loss: 34.597614, Train_MMSE: 0.076811, NMMSE: 0.072448, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:54:32] Epoch 168/200, Loss: 35.098186, Train_MMSE: 0.07681, NMMSE: 0.072452, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:55:18] Epoch 169/200, Loss: 34.612064, Train_MMSE: 0.076814, NMMSE: 0.072461, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:56:04] Epoch 170/200, Loss: 34.812328, Train_MMSE: 0.076794, NMMSE: 0.072439, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:56:50] Epoch 171/200, Loss: 34.509041, Train_MMSE: 0.076799, NMMSE: 0.072454, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:57:37] Epoch 172/200, Loss: 34.545017, Train_MMSE: 0.076793, NMMSE: 0.072452, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:58:23] Epoch 173/200, Loss: 34.313633, Train_MMSE: 0.0768, NMMSE: 0.072446, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:59:09] Epoch 174/200, Loss: 34.870621, Train_MMSE: 0.076802, NMMSE: 0.072459, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 20:59:56] Epoch 175/200, Loss: 34.422768, Train_MMSE: 0.076799, NMMSE: 0.072448, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:00:41] Epoch 176/200, Loss: 34.422268, Train_MMSE: 0.076792, NMMSE: 0.072441, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:01:27] Epoch 177/200, Loss: 34.716709, Train_MMSE: 0.076791, NMMSE: 0.072449, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:02:13] Epoch 178/200, Loss: 34.999794, Train_MMSE: 0.07679, NMMSE: 0.072436, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:02:58] Epoch 179/200, Loss: 34.881813, Train_MMSE: 0.07679, NMMSE: 0.072443, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:03:44] Epoch 180/200, Loss: 35.092319, Train_MMSE: 0.076783, NMMSE: 0.072439, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:04:29] Epoch 181/200, Loss: 34.816822, Train_MMSE: 0.076786, NMMSE: 0.072443, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:05:15] Epoch 182/200, Loss: 34.445667, Train_MMSE: 0.076786, NMMSE: 0.07244, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:06:00] Epoch 183/200, Loss: 34.768391, Train_MMSE: 0.076783, NMMSE: 0.072436, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:06:46] Epoch 184/200, Loss: 35.000748, Train_MMSE: 0.076777, NMMSE: 0.072456, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:07:32] Epoch 185/200, Loss: 34.648689, Train_MMSE: 0.076779, NMMSE: 0.072434, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:08:17] Epoch 186/200, Loss: 34.664871, Train_MMSE: 0.076772, NMMSE: 0.072438, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:09:04] Epoch 187/200, Loss: 34.548634, Train_MMSE: 0.076776, NMMSE: 0.072458, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:09:50] Epoch 188/200, Loss: 34.624195, Train_MMSE: 0.076779, NMMSE: 0.07245, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:10:35] Epoch 189/200, Loss: 34.459423, Train_MMSE: 0.076772, NMMSE: 0.072472, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:11:21] Epoch 190/200, Loss: 34.673042, Train_MMSE: 0.076763, NMMSE: 0.072437, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:12:08] Epoch 191/200, Loss: 34.513611, Train_MMSE: 0.076769, NMMSE: 0.072443, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:12:54] Epoch 192/200, Loss: 35.024357, Train_MMSE: 0.076774, NMMSE: 0.072436, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:13:40] Epoch 193/200, Loss: 34.917343, Train_MMSE: 0.076771, NMMSE: 0.072431, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:14:25] Epoch 194/200, Loss: 34.769314, Train_MMSE: 0.076771, NMMSE: 0.072439, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:15:12] Epoch 195/200, Loss: 34.646294, Train_MMSE: 0.076768, NMMSE: 0.072423, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:15:57] Epoch 196/200, Loss: 34.697567, Train_MMSE: 0.076766, NMMSE: 0.072433, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:16:43] Epoch 197/200, Loss: 34.733067, Train_MMSE: 0.076758, NMMSE: 0.072443, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:17:29] Epoch 198/200, Loss: 34.789581, Train_MMSE: 0.07676, NMMSE: 0.07245, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:18:14] Epoch 199/200, Loss: 35.015984, Train_MMSE: 0.076766, NMMSE: 0.072438, LS_NMSE: 0.242602, Lr: 1e-05
[2025-02-22 21:18:58] Epoch 200/200, Loss: 34.585651, Train_MMSE: 0.076751, NMMSE: 0.072435, LS_NMSE: 0.242602, Lr: 1.0000000000000002e-06
