H shape: (50000, 4, 36) (50000, 4, 36)
NMMSE of valid dataset:: 0.10944907202708025
num samples :: 500000
num valid: 50000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/v1_train_Dataset_dB-25_N36_K4_L4_S11_Setup500_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/v1_test_Dataset_dB-25_N36_K4_L4_S11_Setup50_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}}
model:: DiaUNet1D(
  (encoders): ModuleList(
    (0): BasicUnetBlock(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Stdconv1D(
            (conv): Conv1d(2, 32, kernel_size=(3,), stride=(1,), padding=(1,))
            (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (1): DynamicDilatedConv(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
              (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv1d(8, 4, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
              (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (3): Sequential(
              (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (projection): Conv1d(60, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (1): BasicUnetBlock(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Stdconv1D(
            (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
            (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (1): DynamicDilatedConv(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
              (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (3): Sequential(
              (0): Conv1d(8, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (projection): Conv1d(120, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (2): BasicUnetBlock(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Stdconv1D(
            (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (1): DynamicDilatedConv(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (3): Sequential(
              (0): Conv1d(16, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (projection): Conv1d(240, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
  )
  (pools): ModuleList(
    (0-2): 3 x MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (bottleneck): BasicUnetBlock(
    (blocks): ModuleList(
      (0): Sequential(
        (0): Stdconv1D(
          (conv): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))
          (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (1): DynamicDilatedConv(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (1): Sequential(
            (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (2): Sequential(
            (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (3): Sequential(
            (0): Conv1d(32, 256, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (projection): Conv1d(480, 256, kernel_size=(1,), stride=(1,))
      )
    )
  )
  (upconvs): ModuleList(
    (0): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))
    (1): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))
    (2): ConvTranspose1d(64, 32, kernel_size=(2,), stride=(2,))
  )
  (decoders): ModuleList(
    (0): BasicUnetBlock(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Stdconv1D(
            (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))
            (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (1): DynamicDilatedConv(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (3): Sequential(
              (0): Conv1d(16, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (projection): Conv1d(240, 128, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (1): BasicUnetBlock(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Stdconv1D(
            (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))
            (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (1): DynamicDilatedConv(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
              (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (3): Sequential(
              (0): Conv1d(8, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (projection): Conv1d(120, 64, kernel_size=(1,), stride=(1,))
        )
      )
    )
    (2): BasicUnetBlock(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Stdconv1D(
            (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))
            (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (1): DynamicDilatedConv(
          (layers): ModuleList(
            (0): Sequential(
              (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv1d(16, 8, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
              (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv1d(8, 4, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
              (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (3): Sequential(
              (0): Conv1d(4, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (projection): Conv1d(60, 32, kernel_size=(1,), stride=(1,))
        )
      )
    )
  )
  (final_conv): Conv1d(32, 2, kernel_size=(1,), stride=(1,))
)
Estimated model size: 3.09 MB
loss function:: L1Loss()
[2025-02-18 18:53:19] Epoch 1/300, Loss: 47.146374, Train_MMSE: 0.174702, NMMSE: 0.129248, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 18:55:06] Epoch 2/300, Loss: 46.323147, Train_MMSE: 0.130593, NMMSE: 0.12801, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 18:56:57] Epoch 3/300, Loss: 46.389637, Train_MMSE: 0.128588, NMMSE: 0.122772, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 18:58:45] Epoch 4/300, Loss: 46.712227, Train_MMSE: 0.128334, NMMSE: 0.126439, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:00:32] Epoch 5/300, Loss: 46.664261, Train_MMSE: 0.132563, NMMSE: 0.127124, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:02:16] Epoch 6/300, Loss: 46.165695, Train_MMSE: 0.12824, NMMSE: 0.125453, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:04:03] Epoch 7/300, Loss: 46.295280, Train_MMSE: 0.128277, NMMSE: 0.145159, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:05:51] Epoch 8/300, Loss: 46.167660, Train_MMSE: 0.128218, NMMSE: 0.123687, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:07:38] Epoch 9/300, Loss: 46.335022, Train_MMSE: 0.126756, NMMSE: 0.142406, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:09:25] Epoch 10/300, Loss: 46.190250, Train_MMSE: 0.126634, NMMSE: 0.122537, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:11:14] Epoch 11/300, Loss: 46.251221, Train_MMSE: 0.127517, NMMSE: 0.123157, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:13:12] Epoch 12/300, Loss: 46.164703, Train_MMSE: 0.127509, NMMSE: 0.128189, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:15:29] Epoch 13/300, Loss: 46.167164, Train_MMSE: 0.12637, NMMSE: 0.122352, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:17:42] Epoch 14/300, Loss: 46.476387, Train_MMSE: 0.126264, NMMSE: 0.121178, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:20:09] Epoch 15/300, Loss: 46.077374, Train_MMSE: 0.126261, NMMSE: 0.124032, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:22:35] Epoch 16/300, Loss: 45.797771, Train_MMSE: 0.1277, NMMSE: 0.121114, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:25:04] Epoch 17/300, Loss: 45.996704, Train_MMSE: 0.126315, NMMSE: 0.124622, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:27:31] Epoch 18/300, Loss: 46.652584, Train_MMSE: 0.12717, NMMSE: 0.123875, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:29:56] Epoch 19/300, Loss: 46.031158, Train_MMSE: 0.126222, NMMSE: 0.122462, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:32:23] Epoch 20/300, Loss: 46.334278, Train_MMSE: 0.126855, NMMSE: 0.127516, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:34:46] Epoch 21/300, Loss: 46.145229, Train_MMSE: 0.127286, NMMSE: 0.124217, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:37:12] Epoch 22/300, Loss: 45.935509, Train_MMSE: 0.126849, NMMSE: 0.175014, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:39:36] Epoch 23/300, Loss: 45.903816, Train_MMSE: 0.126145, NMMSE: 0.124196, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:42:02] Epoch 24/300, Loss: 46.279331, Train_MMSE: 0.128066, NMMSE: 0.12145, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:44:29] Epoch 25/300, Loss: 45.739449, Train_MMSE: 0.126058, NMMSE: 0.12312, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:46:54] Epoch 26/300, Loss: 45.799870, Train_MMSE: 0.127551, NMMSE: 0.127861, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:49:20] Epoch 27/300, Loss: 45.680267, Train_MMSE: 0.125979, NMMSE: 0.121558, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:51:45] Epoch 28/300, Loss: 46.486877, Train_MMSE: 0.125971, NMMSE: 0.124168, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:54:10] Epoch 29/300, Loss: 45.796803, Train_MMSE: 0.125898, NMMSE: 0.126575, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:56:37] Epoch 30/300, Loss: 45.894447, Train_MMSE: 0.127061, NMMSE: 0.126518, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 19:59:03] Epoch 31/300, Loss: 46.295216, Train_MMSE: 0.125817, NMMSE: 0.12186, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:01:41] Epoch 32/300, Loss: 46.203239, Train_MMSE: 0.125913, NMMSE: 0.123499, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:04:24] Epoch 33/300, Loss: 45.970013, Train_MMSE: 0.125845, NMMSE: 0.123587, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:07:06] Epoch 34/300, Loss: 46.180733, Train_MMSE: 0.125851, NMMSE: 0.126358, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:09:50] Epoch 35/300, Loss: 46.253681, Train_MMSE: 0.12747, NMMSE: 0.12554, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:12:35] Epoch 36/300, Loss: 46.159237, Train_MMSE: 0.126078, NMMSE: 0.133682, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:15:19] Epoch 37/300, Loss: 45.586617, Train_MMSE: 0.126051, NMMSE: 0.122169, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:18:02] Epoch 38/300, Loss: 46.066536, Train_MMSE: 0.127606, NMMSE: 0.128825, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:20:49] Epoch 39/300, Loss: 45.642540, Train_MMSE: 0.125873, NMMSE: 0.123934, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:23:32] Epoch 40/300, Loss: 45.940113, Train_MMSE: 0.12591, NMMSE: 0.14691, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:26:14] Epoch 41/300, Loss: 45.773273, Train_MMSE: 0.126312, NMMSE: 0.291671, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:28:54] Epoch 42/300, Loss: 45.694042, Train_MMSE: 0.125902, NMMSE: 0.137129, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:31:40] Epoch 43/300, Loss: 45.933075, Train_MMSE: 0.12645, NMMSE: 0.150323, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:34:20] Epoch 44/300, Loss: 45.787014, Train_MMSE: 0.125683, NMMSE: 0.136509, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:37:00] Epoch 45/300, Loss: 45.805790, Train_MMSE: 0.12609, NMMSE: 0.125658, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:39:35] Epoch 46/300, Loss: 45.645851, Train_MMSE: 0.125695, NMMSE: 0.128972, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:42:15] Epoch 47/300, Loss: 45.738007, Train_MMSE: 0.125696, NMMSE: 0.148682, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:45:00] Epoch 48/300, Loss: 46.182755, Train_MMSE: 0.134377, NMMSE: 0.123871, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:47:46] Epoch 49/300, Loss: 46.110550, Train_MMSE: 0.126542, NMMSE: 0.125502, LS_NMSE: 0.27073, Lr: 0.01
[2025-02-18 20:50:33] Epoch 50/300, Loss: 45.958603, Train_MMSE: 0.126281, NMMSE: 0.134575, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 20:53:15] Epoch 51/300, Loss: 45.344727, Train_MMSE: 0.122768, NMMSE: 0.117035, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 20:56:05] Epoch 52/300, Loss: 45.261116, Train_MMSE: 0.122595, NMMSE: 0.11717, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 20:58:53] Epoch 53/300, Loss: 45.172577, Train_MMSE: 0.122536, NMMSE: 0.11672, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:01:38] Epoch 54/300, Loss: 45.801952, Train_MMSE: 0.122488, NMMSE: 0.116701, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:04:26] Epoch 55/300, Loss: 45.472458, Train_MMSE: 0.122444, NMMSE: 0.11644, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:07:14] Epoch 56/300, Loss: 45.375126, Train_MMSE: 0.122395, NMMSE: 0.116603, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:10:05] Epoch 57/300, Loss: 45.174809, Train_MMSE: 0.122388, NMMSE: 0.116344, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:13:03] Epoch 58/300, Loss: 45.259232, Train_MMSE: 0.122367, NMMSE: 0.118074, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:15:52] Epoch 59/300, Loss: 45.159046, Train_MMSE: 0.122334, NMMSE: 0.116376, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:18:49] Epoch 60/300, Loss: 45.584526, Train_MMSE: 0.122343, NMMSE: 0.119263, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:21:39] Epoch 61/300, Loss: 45.444889, Train_MMSE: 0.122316, NMMSE: 0.116766, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:24:36] Epoch 62/300, Loss: 44.947670, Train_MMSE: 0.122302, NMMSE: 0.116569, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:27:26] Epoch 63/300, Loss: 45.112854, Train_MMSE: 0.122288, NMMSE: 0.116432, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:30:23] Epoch 64/300, Loss: 45.485809, Train_MMSE: 0.122278, NMMSE: 0.116733, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:33:22] Epoch 65/300, Loss: 45.387745, Train_MMSE: 0.122267, NMMSE: 0.116443, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:36:23] Epoch 66/300, Loss: 45.425625, Train_MMSE: 0.122281, NMMSE: 0.119997, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:39:18] Epoch 67/300, Loss: 45.232437, Train_MMSE: 0.122243, NMMSE: 0.117197, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:42:13] Epoch 68/300, Loss: 45.212955, Train_MMSE: 0.122245, NMMSE: 0.117355, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:45:04] Epoch 69/300, Loss: 45.726608, Train_MMSE: 0.122222, NMMSE: 0.116146, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:47:54] Epoch 70/300, Loss: 45.268459, Train_MMSE: 0.122229, NMMSE: 0.118192, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:50:57] Epoch 71/300, Loss: 45.211948, Train_MMSE: 0.122205, NMMSE: 0.116585, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:53:58] Epoch 72/300, Loss: 45.248127, Train_MMSE: 0.122209, NMMSE: 0.116731, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:56:55] Epoch 73/300, Loss: 45.363319, Train_MMSE: 0.122233, NMMSE: 0.11694, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 21:59:55] Epoch 74/300, Loss: 44.971394, Train_MMSE: 0.122207, NMMSE: 0.117558, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:02:54] Epoch 75/300, Loss: 45.137817, Train_MMSE: 0.122195, NMMSE: 0.117572, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:05:45] Epoch 76/300, Loss: 45.278885, Train_MMSE: 0.122189, NMMSE: 0.117468, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:08:47] Epoch 77/300, Loss: 45.288609, Train_MMSE: 0.122208, NMMSE: 0.118201, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:11:46] Epoch 78/300, Loss: 45.511200, Train_MMSE: 0.122201, NMMSE: 0.117694, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:14:44] Epoch 79/300, Loss: 45.216415, Train_MMSE: 0.122215, NMMSE: 0.219993, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:17:49] Epoch 80/300, Loss: 44.948013, Train_MMSE: 0.122206, NMMSE: 0.117346, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:20:58] Epoch 81/300, Loss: 45.052956, Train_MMSE: 0.122196, NMMSE: 0.119219, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:24:03] Epoch 82/300, Loss: 45.177189, Train_MMSE: 0.122178, NMMSE: 0.11772, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:27:13] Epoch 83/300, Loss: 44.994320, Train_MMSE: 0.122179, NMMSE: 0.120778, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:30:05] Epoch 84/300, Loss: 45.715950, Train_MMSE: 0.122191, NMMSE: 0.120356, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:33:10] Epoch 85/300, Loss: 45.370850, Train_MMSE: 0.122189, NMMSE: 0.122761, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:36:13] Epoch 86/300, Loss: 45.244617, Train_MMSE: 0.12218, NMMSE: 0.117351, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:39:12] Epoch 87/300, Loss: 45.004673, Train_MMSE: 0.12221, NMMSE: 0.117675, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:42:20] Epoch 88/300, Loss: 45.377720, Train_MMSE: 0.122146, NMMSE: 0.116289, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:45:25] Epoch 89/300, Loss: 45.208088, Train_MMSE: 0.122183, NMMSE: 0.117095, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:48:27] Epoch 90/300, Loss: 45.051899, Train_MMSE: 0.122167, NMMSE: 0.118762, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:51:27] Epoch 91/300, Loss: 44.905716, Train_MMSE: 0.12218, NMMSE: 0.117777, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:54:31] Epoch 92/300, Loss: 45.109001, Train_MMSE: 0.122156, NMMSE: 0.119869, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 22:57:32] Epoch 93/300, Loss: 45.178509, Train_MMSE: 0.122174, NMMSE: 0.117973, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:00:30] Epoch 94/300, Loss: 45.117867, Train_MMSE: 0.122166, NMMSE: 0.117603, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:03:30] Epoch 95/300, Loss: 45.265713, Train_MMSE: 0.122152, NMMSE: 0.117519, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:06:24] Epoch 96/300, Loss: 45.036682, Train_MMSE: 0.122161, NMMSE: 0.118133, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:09:20] Epoch 97/300, Loss: 45.216034, Train_MMSE: 0.122163, NMMSE: 0.118308, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:12:10] Epoch 98/300, Loss: 45.197021, Train_MMSE: 0.12224, NMMSE: 0.119314, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:15:07] Epoch 99/300, Loss: 44.899971, Train_MMSE: 0.122167, NMMSE: 0.124818, LS_NMSE: 0.27073, Lr: 0.001
[2025-02-18 23:17:55] Epoch 100/300, Loss: 45.205112, Train_MMSE: 0.122176, NMMSE: 0.119791, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:19:44] Epoch 101/300, Loss: 44.926525, Train_MMSE: 0.121381, NMMSE: 0.114945, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:21:36] Epoch 102/300, Loss: 45.214455, Train_MMSE: 0.121316, NMMSE: 0.114943, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:23:28] Epoch 103/300, Loss: 44.840168, Train_MMSE: 0.121304, NMMSE: 0.114849, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:25:22] Epoch 104/300, Loss: 45.336178, Train_MMSE: 0.121298, NMMSE: 0.114956, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:27:16] Epoch 105/300, Loss: 45.000732, Train_MMSE: 0.121287, NMMSE: 0.115012, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:29:06] Epoch 106/300, Loss: 45.073265, Train_MMSE: 0.121282, NMMSE: 0.114906, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:30:01] Epoch 107/300, Loss: 44.964283, Train_MMSE: 0.121263, NMMSE: 0.114943, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:30:53] Epoch 108/300, Loss: 44.881863, Train_MMSE: 0.121272, NMMSE: 0.114946, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:31:47] Epoch 109/300, Loss: 45.161209, Train_MMSE: 0.121269, NMMSE: 0.114883, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:32:41] Epoch 110/300, Loss: 44.759651, Train_MMSE: 0.121256, NMMSE: 0.114848, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:33:34] Epoch 111/300, Loss: 45.083385, Train_MMSE: 0.121247, NMMSE: 0.114923, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:34:28] Epoch 112/300, Loss: 44.864502, Train_MMSE: 0.121255, NMMSE: 0.115146, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:35:21] Epoch 113/300, Loss: 45.256031, Train_MMSE: 0.121254, NMMSE: 0.1149, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:36:13] Epoch 114/300, Loss: 45.231194, Train_MMSE: 0.121237, NMMSE: 0.114874, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:37:08] Epoch 115/300, Loss: 45.158237, Train_MMSE: 0.121245, NMMSE: 0.114879, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:38:02] Epoch 116/300, Loss: 44.773960, Train_MMSE: 0.121236, NMMSE: 0.114823, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:38:57] Epoch 117/300, Loss: 45.172764, Train_MMSE: 0.121233, NMMSE: 0.114913, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:39:52] Epoch 118/300, Loss: 44.942978, Train_MMSE: 0.121239, NMMSE: 0.114868, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:40:46] Epoch 119/300, Loss: 45.083027, Train_MMSE: 0.121227, NMMSE: 0.114899, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:41:39] Epoch 120/300, Loss: 45.120621, Train_MMSE: 0.121229, NMMSE: 0.114906, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:42:31] Epoch 121/300, Loss: 44.944729, Train_MMSE: 0.121228, NMMSE: 0.114916, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:43:25] Epoch 122/300, Loss: 44.987782, Train_MMSE: 0.121219, NMMSE: 0.114816, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:44:20] Epoch 123/300, Loss: 44.930225, Train_MMSE: 0.121218, NMMSE: 0.11496, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:45:14] Epoch 124/300, Loss: 45.318596, Train_MMSE: 0.121216, NMMSE: 0.114873, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:46:07] Epoch 125/300, Loss: 45.581516, Train_MMSE: 0.121224, NMMSE: 0.114805, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:47:01] Epoch 126/300, Loss: 44.820637, Train_MMSE: 0.121212, NMMSE: 0.114984, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:47:56] Epoch 127/300, Loss: 45.300751, Train_MMSE: 0.121212, NMMSE: 0.114891, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:48:48] Epoch 128/300, Loss: 44.938023, Train_MMSE: 0.121211, NMMSE: 0.114838, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:49:41] Epoch 129/300, Loss: 45.324875, Train_MMSE: 0.121214, NMMSE: 0.115203, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:50:33] Epoch 130/300, Loss: 45.053677, Train_MMSE: 0.121209, NMMSE: 0.114958, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:51:28] Epoch 131/300, Loss: 45.091293, Train_MMSE: 0.121204, NMMSE: 0.114925, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:52:22] Epoch 132/300, Loss: 45.006332, Train_MMSE: 0.1212, NMMSE: 0.114904, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:53:17] Epoch 133/300, Loss: 44.908310, Train_MMSE: 0.121193, NMMSE: 0.114782, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:54:12] Epoch 134/300, Loss: 45.104954, Train_MMSE: 0.121201, NMMSE: 0.114923, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:55:06] Epoch 135/300, Loss: 44.704811, Train_MMSE: 0.121205, NMMSE: 0.114958, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:55:58] Epoch 136/300, Loss: 44.941669, Train_MMSE: 0.121201, NMMSE: 0.11505, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:56:52] Epoch 137/300, Loss: 45.315926, Train_MMSE: 0.121204, NMMSE: 0.114789, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:57:46] Epoch 138/300, Loss: 45.011524, Train_MMSE: 0.12119, NMMSE: 0.114878, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:58:40] Epoch 139/300, Loss: 45.570091, Train_MMSE: 0.121198, NMMSE: 0.114963, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-18 23:59:36] Epoch 140/300, Loss: 45.170998, Train_MMSE: 0.121195, NMMSE: 0.115138, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:00:31] Epoch 141/300, Loss: 45.278645, Train_MMSE: 0.121193, NMMSE: 0.114938, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:01:25] Epoch 142/300, Loss: 44.931774, Train_MMSE: 0.121187, NMMSE: 0.114874, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:02:18] Epoch 143/300, Loss: 45.237293, Train_MMSE: 0.121187, NMMSE: 0.114916, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:03:10] Epoch 144/300, Loss: 44.840183, Train_MMSE: 0.121195, NMMSE: 0.114821, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:04:04] Epoch 145/300, Loss: 44.840828, Train_MMSE: 0.121188, NMMSE: 0.114836, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:04:58] Epoch 146/300, Loss: 45.061722, Train_MMSE: 0.121178, NMMSE: 0.114806, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:05:52] Epoch 147/300, Loss: 45.421467, Train_MMSE: 0.121181, NMMSE: 0.114868, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:06:46] Epoch 148/300, Loss: 45.022175, Train_MMSE: 0.12118, NMMSE: 0.114823, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:07:38] Epoch 149/300, Loss: 44.915874, Train_MMSE: 0.121181, NMMSE: 0.114833, LS_NMSE: 0.27073, Lr: 0.0001
[2025-02-19 00:08:32] Epoch 150/300, Loss: 44.923550, Train_MMSE: 0.121175, NMMSE: 0.114814, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:09:28] Epoch 151/300, Loss: 45.011288, Train_MMSE: 0.121055, NMMSE: 0.114603, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:10:22] Epoch 152/300, Loss: 44.911396, Train_MMSE: 0.121039, NMMSE: 0.114599, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:11:15] Epoch 153/300, Loss: 45.210365, Train_MMSE: 0.121048, NMMSE: 0.11461, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:12:08] Epoch 154/300, Loss: 44.796467, Train_MMSE: 0.121041, NMMSE: 0.114609, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:13:02] Epoch 155/300, Loss: 45.064320, Train_MMSE: 0.121032, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:13:54] Epoch 156/300, Loss: 45.172256, Train_MMSE: 0.121042, NMMSE: 0.114602, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:14:48] Epoch 157/300, Loss: 44.902866, Train_MMSE: 0.121042, NMMSE: 0.114626, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:15:42] Epoch 158/300, Loss: 45.280617, Train_MMSE: 0.121046, NMMSE: 0.114602, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:16:36] Epoch 159/300, Loss: 45.021198, Train_MMSE: 0.121041, NMMSE: 0.114602, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:17:30] Epoch 160/300, Loss: 44.859512, Train_MMSE: 0.121036, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:18:25] Epoch 161/300, Loss: 44.916187, Train_MMSE: 0.121046, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:19:20] Epoch 162/300, Loss: 44.860706, Train_MMSE: 0.121046, NMMSE: 0.114606, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:20:13] Epoch 163/300, Loss: 45.525299, Train_MMSE: 0.121039, NMMSE: 0.114606, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:21:07] Epoch 164/300, Loss: 44.882179, Train_MMSE: 0.121031, NMMSE: 0.114597, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:22:02] Epoch 165/300, Loss: 44.817951, Train_MMSE: 0.121038, NMMSE: 0.114597, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:22:53] Epoch 166/300, Loss: 44.883636, Train_MMSE: 0.121031, NMMSE: 0.114604, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:23:47] Epoch 167/300, Loss: 45.104099, Train_MMSE: 0.121032, NMMSE: 0.114593, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:24:42] Epoch 168/300, Loss: 45.129875, Train_MMSE: 0.121033, NMMSE: 0.114592, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:25:37] Epoch 169/300, Loss: 44.974640, Train_MMSE: 0.121038, NMMSE: 0.114598, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:26:31] Epoch 170/300, Loss: 45.034840, Train_MMSE: 0.121038, NMMSE: 0.114601, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:27:25] Epoch 171/300, Loss: 44.837910, Train_MMSE: 0.121041, NMMSE: 0.114596, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:28:19] Epoch 172/300, Loss: 44.852386, Train_MMSE: 0.121028, NMMSE: 0.114588, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:29:13] Epoch 173/300, Loss: 44.944649, Train_MMSE: 0.121041, NMMSE: 0.114592, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:30:07] Epoch 174/300, Loss: 45.103508, Train_MMSE: 0.121025, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:31:03] Epoch 175/300, Loss: 44.886124, Train_MMSE: 0.121031, NMMSE: 0.114601, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:31:57] Epoch 176/300, Loss: 45.494957, Train_MMSE: 0.121023, NMMSE: 0.114597, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:32:51] Epoch 177/300, Loss: 45.379639, Train_MMSE: 0.121033, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:33:44] Epoch 178/300, Loss: 44.894295, Train_MMSE: 0.121028, NMMSE: 0.114584, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:34:36] Epoch 179/300, Loss: 44.739460, Train_MMSE: 0.121032, NMMSE: 0.114588, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:35:30] Epoch 180/300, Loss: 44.973866, Train_MMSE: 0.121033, NMMSE: 0.114604, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:36:25] Epoch 181/300, Loss: 44.971958, Train_MMSE: 0.121031, NMMSE: 0.114591, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:37:20] Epoch 182/300, Loss: 45.230564, Train_MMSE: 0.121036, NMMSE: 0.114599, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:38:13] Epoch 183/300, Loss: 45.219769, Train_MMSE: 0.121029, NMMSE: 0.114601, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:39:05] Epoch 184/300, Loss: 44.976723, Train_MMSE: 0.121031, NMMSE: 0.114588, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:40:00] Epoch 185/300, Loss: 45.007610, Train_MMSE: 0.121033, NMMSE: 0.114597, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:40:54] Epoch 186/300, Loss: 44.932735, Train_MMSE: 0.121034, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:41:48] Epoch 187/300, Loss: 44.605244, Train_MMSE: 0.121033, NMMSE: 0.114591, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:42:42] Epoch 188/300, Loss: 45.033669, Train_MMSE: 0.121027, NMMSE: 0.11459, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:43:34] Epoch 189/300, Loss: 44.988640, Train_MMSE: 0.12102, NMMSE: 0.114589, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:44:28] Epoch 190/300, Loss: 44.584717, Train_MMSE: 0.121018, NMMSE: 0.114608, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:45:21] Epoch 191/300, Loss: 44.766735, Train_MMSE: 0.121027, NMMSE: 0.114598, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:46:15] Epoch 192/300, Loss: 45.114620, Train_MMSE: 0.121028, NMMSE: 0.114588, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:47:09] Epoch 193/300, Loss: 45.129864, Train_MMSE: 0.121024, NMMSE: 0.11459, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:48:02] Epoch 194/300, Loss: 45.083141, Train_MMSE: 0.121024, NMMSE: 0.11461, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:48:55] Epoch 195/300, Loss: 44.988853, Train_MMSE: 0.12102, NMMSE: 0.114591, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:49:49] Epoch 196/300, Loss: 45.231247, Train_MMSE: 0.12102, NMMSE: 0.114591, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:50:43] Epoch 197/300, Loss: 45.208576, Train_MMSE: 0.121024, NMMSE: 0.114591, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:51:37] Epoch 198/300, Loss: 45.023556, Train_MMSE: 0.121021, NMMSE: 0.114597, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:52:31] Epoch 199/300, Loss: 44.822517, Train_MMSE: 0.12103, NMMSE: 0.114595, LS_NMSE: 0.27073, Lr: 1e-05
[2025-02-19 00:53:24] Epoch 200/300, Loss: 45.150131, Train_MMSE: 0.12102, NMMSE: 0.114593, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:54:17] Epoch 201/300, Loss: 45.032120, Train_MMSE: 0.121015, NMMSE: 0.114578, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:55:11] Epoch 202/300, Loss: 44.875122, Train_MMSE: 0.121004, NMMSE: 0.11457, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:56:04] Epoch 203/300, Loss: 44.890144, Train_MMSE: 0.121014, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:56:58] Epoch 204/300, Loss: 44.922199, Train_MMSE: 0.121005, NMMSE: 0.114588, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:57:53] Epoch 205/300, Loss: 45.193077, Train_MMSE: 0.121013, NMMSE: 0.114594, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:58:46] Epoch 206/300, Loss: 44.945442, Train_MMSE: 0.121011, NMMSE: 0.114574, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 00:59:39] Epoch 207/300, Loss: 44.808464, Train_MMSE: 0.121001, NMMSE: 0.114584, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:00:31] Epoch 208/300, Loss: 44.790844, Train_MMSE: 0.121003, NMMSE: 0.11458, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:01:25] Epoch 209/300, Loss: 45.093330, Train_MMSE: 0.120999, NMMSE: 0.114597, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:02:20] Epoch 210/300, Loss: 45.198994, Train_MMSE: 0.121009, NMMSE: 0.114585, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:03:13] Epoch 211/300, Loss: 45.200317, Train_MMSE: 0.121007, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:04:06] Epoch 212/300, Loss: 45.049770, Train_MMSE: 0.12101, NMMSE: 0.114578, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:05:00] Epoch 213/300, Loss: 45.163773, Train_MMSE: 0.121006, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:05:54] Epoch 214/300, Loss: 45.051399, Train_MMSE: 0.121011, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:06:48] Epoch 215/300, Loss: 45.032742, Train_MMSE: 0.121002, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:07:41] Epoch 216/300, Loss: 45.182812, Train_MMSE: 0.121012, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:08:34] Epoch 217/300, Loss: 44.969440, Train_MMSE: 0.120998, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:09:27] Epoch 218/300, Loss: 45.144741, Train_MMSE: 0.121003, NMMSE: 0.114574, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:10:20] Epoch 219/300, Loss: 45.221752, Train_MMSE: 0.121008, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:11:15] Epoch 220/300, Loss: 45.582752, Train_MMSE: 0.121003, NMMSE: 0.114578, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:12:08] Epoch 221/300, Loss: 45.045597, Train_MMSE: 0.121, NMMSE: 0.114572, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:13:01] Epoch 222/300, Loss: 45.234005, Train_MMSE: 0.121008, NMMSE: 0.114566, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:13:54] Epoch 223/300, Loss: 45.299637, Train_MMSE: 0.12101, NMMSE: 0.1146, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:14:49] Epoch 224/300, Loss: 44.736473, Train_MMSE: 0.121007, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:15:44] Epoch 225/300, Loss: 44.718239, Train_MMSE: 0.121006, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:16:37] Epoch 226/300, Loss: 45.421429, Train_MMSE: 0.121002, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:17:30] Epoch 227/300, Loss: 45.208958, Train_MMSE: 0.121003, NMMSE: 0.11457, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:18:25] Epoch 228/300, Loss: 44.818089, Train_MMSE: 0.121006, NMMSE: 0.11458, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:19:21] Epoch 229/300, Loss: 44.990620, Train_MMSE: 0.121004, NMMSE: 0.114579, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:20:14] Epoch 230/300, Loss: 45.237904, Train_MMSE: 0.121004, NMMSE: 0.114576, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:21:08] Epoch 231/300, Loss: 44.907906, Train_MMSE: 0.121001, NMMSE: 0.114582, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:22:02] Epoch 232/300, Loss: 45.254524, Train_MMSE: 0.120997, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:22:59] Epoch 233/300, Loss: 44.815369, Train_MMSE: 0.121008, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:23:53] Epoch 234/300, Loss: 45.306007, Train_MMSE: 0.120999, NMMSE: 0.114603, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:24:45] Epoch 235/300, Loss: 45.251537, Train_MMSE: 0.121, NMMSE: 0.114577, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:25:39] Epoch 236/300, Loss: 45.294971, Train_MMSE: 0.121003, NMMSE: 0.114572, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:26:33] Epoch 237/300, Loss: 45.037277, Train_MMSE: 0.120999, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:27:27] Epoch 238/300, Loss: 44.869999, Train_MMSE: 0.121, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:28:21] Epoch 239/300, Loss: 45.279671, Train_MMSE: 0.121, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:29:15] Epoch 240/300, Loss: 45.647770, Train_MMSE: 0.12101, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:30:08] Epoch 241/300, Loss: 45.297451, Train_MMSE: 0.121, NMMSE: 0.114594, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:31:04] Epoch 242/300, Loss: 44.858162, Train_MMSE: 0.121002, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:32:00] Epoch 243/300, Loss: 45.415882, Train_MMSE: 0.121015, NMMSE: 0.114572, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:32:53] Epoch 244/300, Loss: 45.397697, Train_MMSE: 0.121012, NMMSE: 0.114585, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:33:46] Epoch 245/300, Loss: 45.036568, Train_MMSE: 0.121008, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:34:41] Epoch 246/300, Loss: 44.774239, Train_MMSE: 0.121008, NMMSE: 0.114574, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:35:37] Epoch 247/300, Loss: 45.400375, Train_MMSE: 0.121, NMMSE: 0.114587, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:36:31] Epoch 248/300, Loss: 45.393204, Train_MMSE: 0.121002, NMMSE: 0.114573, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:37:25] Epoch 249/300, Loss: 45.225533, Train_MMSE: 0.121003, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-06
[2025-02-19 01:38:20] Epoch 250/300, Loss: 44.596470, Train_MMSE: 0.121014, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:39:15] Epoch 251/300, Loss: 44.757385, Train_MMSE: 0.121003, NMMSE: 0.11457, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:40:09] Epoch 252/300, Loss: 45.021275, Train_MMSE: 0.121011, NMMSE: 0.114577, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:41:03] Epoch 253/300, Loss: 45.149506, Train_MMSE: 0.120995, NMMSE: 0.114591, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:41:56] Epoch 254/300, Loss: 45.398300, Train_MMSE: 0.120995, NMMSE: 0.114574, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:42:50] Epoch 255/300, Loss: 44.887844, Train_MMSE: 0.121011, NMMSE: 0.114589, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:43:46] Epoch 256/300, Loss: 45.112991, Train_MMSE: 0.121005, NMMSE: 0.114582, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:44:41] Epoch 257/300, Loss: 45.209770, Train_MMSE: 0.121001, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:45:34] Epoch 258/300, Loss: 45.169949, Train_MMSE: 0.121002, NMMSE: 0.114577, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:46:28] Epoch 259/300, Loss: 45.311935, Train_MMSE: 0.121003, NMMSE: 0.114585, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:47:23] Epoch 260/300, Loss: 44.965500, Train_MMSE: 0.121002, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:48:18] Epoch 261/300, Loss: 44.948788, Train_MMSE: 0.121009, NMMSE: 0.114581, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:49:12] Epoch 262/300, Loss: 45.070400, Train_MMSE: 0.121001, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:50:06] Epoch 263/300, Loss: 44.812305, Train_MMSE: 0.121005, NMMSE: 0.11457, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:50:59] Epoch 264/300, Loss: 44.676426, Train_MMSE: 0.12099, NMMSE: 0.114593, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:51:55] Epoch 265/300, Loss: 44.947582, Train_MMSE: 0.121003, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:52:51] Epoch 266/300, Loss: 45.052025, Train_MMSE: 0.120997, NMMSE: 0.114566, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:53:44] Epoch 267/300, Loss: 44.632416, Train_MMSE: 0.121008, NMMSE: 0.11461, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:54:39] Epoch 268/300, Loss: 45.061123, Train_MMSE: 0.121, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:55:35] Epoch 269/300, Loss: 44.807148, Train_MMSE: 0.121007, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:56:31] Epoch 270/300, Loss: 45.022079, Train_MMSE: 0.120993, NMMSE: 0.114566, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:57:24] Epoch 271/300, Loss: 45.012478, Train_MMSE: 0.121005, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:58:18] Epoch 272/300, Loss: 44.700871, Train_MMSE: 0.121001, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 01:59:14] Epoch 273/300, Loss: 44.558537, Train_MMSE: 0.121005, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:00:09] Epoch 274/300, Loss: 44.806335, Train_MMSE: 0.121015, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:01:03] Epoch 275/300, Loss: 45.244141, Train_MMSE: 0.121007, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:01:57] Epoch 276/300, Loss: 44.869633, Train_MMSE: 0.120999, NMMSE: 0.11458, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:02:50] Epoch 277/300, Loss: 45.269459, Train_MMSE: 0.121001, NMMSE: 0.114573, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:03:45] Epoch 278/300, Loss: 44.997669, Train_MMSE: 0.121008, NMMSE: 0.114594, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:04:40] Epoch 279/300, Loss: 45.026363, Train_MMSE: 0.121, NMMSE: 0.114569, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:05:33] Epoch 280/300, Loss: 45.206352, Train_MMSE: 0.121005, NMMSE: 0.114588, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:06:26] Epoch 281/300, Loss: 44.978291, Train_MMSE: 0.121006, NMMSE: 0.11459, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:07:23] Epoch 282/300, Loss: 45.200581, Train_MMSE: 0.121005, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:08:18] Epoch 283/300, Loss: 45.287415, Train_MMSE: 0.121001, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:09:12] Epoch 284/300, Loss: 45.053265, Train_MMSE: 0.121002, NMMSE: 0.114608, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:10:07] Epoch 285/300, Loss: 45.177986, Train_MMSE: 0.121005, NMMSE: 0.114579, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:11:03] Epoch 286/300, Loss: 45.382164, Train_MMSE: 0.120999, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:11:57] Epoch 287/300, Loss: 44.810596, Train_MMSE: 0.120996, NMMSE: 0.114573, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:12:50] Epoch 288/300, Loss: 45.210354, Train_MMSE: 0.120998, NMMSE: 0.114578, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:13:43] Epoch 289/300, Loss: 44.914898, Train_MMSE: 0.121001, NMMSE: 0.114572, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:14:36] Epoch 290/300, Loss: 45.282909, Train_MMSE: 0.121, NMMSE: 0.114602, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:15:31] Epoch 291/300, Loss: 44.758842, Train_MMSE: 0.121001, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:16:25] Epoch 292/300, Loss: 45.010166, Train_MMSE: 0.121001, NMMSE: 0.114568, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:17:19] Epoch 293/300, Loss: 45.152222, Train_MMSE: 0.120992, NMMSE: 0.114567, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:18:12] Epoch 294/300, Loss: 44.867737, Train_MMSE: 0.121001, NMMSE: 0.114566, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:19:07] Epoch 295/300, Loss: 45.260864, Train_MMSE: 0.12099, NMMSE: 0.114574, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:20:02] Epoch 296/300, Loss: 44.902073, Train_MMSE: 0.121, NMMSE: 0.11457, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:20:56] Epoch 297/300, Loss: 45.003601, Train_MMSE: 0.121002, NMMSE: 0.114585, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:21:50] Epoch 298/300, Loss: 45.154083, Train_MMSE: 0.120997, NMMSE: 0.114566, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:22:44] Epoch 299/300, Loss: 45.426052, Train_MMSE: 0.121007, NMMSE: 0.114587, LS_NMSE: 0.27073, Lr: 1.0000000000000002e-07
[2025-02-19 02:23:40] Epoch 300/300, Loss: 44.779144, Train_MMSE: 0.121004, NMMSE: 0.114571, LS_NMSE: 0.27073, Lr: 1.0000000000000004e-08
