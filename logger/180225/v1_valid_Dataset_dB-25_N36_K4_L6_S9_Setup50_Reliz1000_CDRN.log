H shape: (50000, 4, 36) (50000, 4, 36)
NMMSE of valid dataset:: 0.17113055814938608
num samples :: 500000
num valid: 50000
config_path: conf/config_multisetup.yml
cfg: {'seed': 10, 'dataset': {'train_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/v1_train_Dataset_dB-25_N36_K4_L6_S9_Setup500_Reliz1000.mat', 'valid_path': '/mnt/parscratch/users/elq20xd/channel_estimation/cc_data/dataset10_N36K4_3types/v1_valid_Dataset_dB-25_N36_K4_L6_S9_Setup50_Reliz1000.mat', 'with_Vpinv': True}, 'dataloader': {'shuffle': True, 'batch_size': 512, 'num_workers': 1}, 'model': {'channel_index': 32, 'num_layers': 3}, 'logger': {'path': None}}
model:: DnCNN_MultiBlock_ds(
  (layers): ModuleList(
    (0-2): 3 x Sequential(
      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
      (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU(inplace=True)
      (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): ReLU(inplace=True)
      (15): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (17): ReLU(inplace=True)
      (18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (20): ReLU(inplace=True)
      (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (23): ReLU(inplace=True)
      (24): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (26): ReLU(inplace=True)
      (27): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (29): ReLU(inplace=True)
      (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (32): ReLU(inplace=True)
      (33): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (35): ReLU(inplace=True)
      (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (38): ReLU(inplace=True)
      (39): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (40): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (41): ReLU(inplace=True)
      (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (44): ReLU(inplace=True)
      (45): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
Estimated model size: 5.95 MB
loss function:: L1Loss()
[2025-02-19 13:08:08] Epoch 1/50, Loss: 70.527489, Train_MMSE: 0.514167, NMMSE: 0.308489, LS_NMSE: 1.324841, Lr: 0.001
[2025-02-19 13:11:26] Epoch 2/50, Loss: 67.205879, Train_MMSE: 0.284865, NMMSE: 0.279393, LS_NMSE: 1.324841, Lr: 0.001
[2025-02-19 13:14:56] Epoch 3/50, Loss: 66.029762, Train_MMSE: 0.270418, NMMSE: 0.272306, LS_NMSE: 1.324841, Lr: 0.001
[2025-02-19 13:18:24] Epoch 4/50, Loss: 65.382347, Train_MMSE: 0.264442, NMMSE: 0.267877, LS_NMSE: 1.324841, Lr: 0.001
[2025-02-19 13:21:52] Epoch 5/50, Loss: 64.970924, Train_MMSE: 0.260185, NMMSE: 0.262655, LS_NMSE: 1.324841, Lr: 0.001[[2025-02-19 13:25:21] Epoch 6/50, Loss: 64.514206, Train_MMSE: 0.256441, NMMSE: 0.259183, LS_NMSE: 1.324841, Lr: 0.001[[2025-02-19 13:28:41] Epoch 7/50, Loss: 64.224884, Train_MMSE: 0.253038, NMMSE: 0.256015, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:31:56] Epoch 8/50, Loss: 64.129738, Train_MMSE: 0.249308, NMMSE: 0.253484, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 13:35:10] Epoch 9/50, Loss: 63.695145, Train_MMSE: 0.245742, NMMSE: 0.248916, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 13:38:23] Epoch 10/50, Loss: 62.937794, Train_MMSE: 0.24227, NMMSE: 0.248949, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:41:36] Epoch 11/50, Loss: 62.970783, Train_MMSE: 0.239431, NMMSE: 0.246364, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:44:50] Epoch 12/50, Loss: 62.536751, Train_MMSE: 0.237006, NMMSE: 0.240022, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:48:04] Epoch 13/50, Loss: 62.183613, Train_MMSE: 0.235145, NMMSE: 0.239502, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:51:16] Epoch 14/50, Loss: 60.824375, Train_MMSE: 0.233404, NMMSE: 0.236928, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:54:27] Epoch 15/50, Loss: 61.159748, Train_MMSE: 0.23207, NMMSE: 0.237859, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 13:57:39] Epoch 16/50, Loss: 61.467701, Train_MMSE: 0.23082, NMMSE: 0.234801, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 14:00:53] Epoch 17/50, Loss: 61.525826, Train_MMSE: 0.22965, NMMSE: 0.235809, LS_NMSE: 1.324841, Lr: 0.001[[2025-02-19 14:04:06] Epoch 18/50, Loss: 61.361389, Train_MMSE: 0.228568, NMMSE: 0.234091, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 14:07:20] Epoch 19/50, Loss: 61.052177, Train_MMSE: 0.227703, NMMSE: 0.233879, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 14:10:34] Epoch 20/50, Loss: 61.131519, Train_MMSE: 0.226752, NMMSE: 0.232479, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 14:13:47] Epoch 21/50, Loss: 60.928127, Train_MMSE: 0.226002, NMMSE: 0.231661, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 14:16:52] Epoch 22/50, Loss: 61.107815, Train_MMSE: 0.225354, NMMSE: 0.230108, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 14:20:02] Epoch 23/50, Loss: 61.036140, Train_MMSE: 0.22464, NMMSE: 0.227561, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 14:23:14] Epoch 24/50, Loss: 59.739719, Train_MMSE: 0.224058, NMMSE: 0.229347, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:26:27] Epoch 25/50, Loss: 60.540649, Train_MMSE: 0.223495, NMMSE: 0.229492, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:29:39] Epoch 26/50, Loss: 60.648682, Train_MMSE: 0.223045, NMMSE: 0.227028, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:32:52] Epoch 27/50, Loss: 60.777973, Train_MMSE: 0.222474, NMMSE: 0.227131, LS_NMSE: 1.324841, Lr: 0[2025[2025-02-19 14:36:03] Epoch 28/50, Loss: 60.372211, Train_MMSE: 0.222058, NMMSE: 0.23093, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:39:16] Epoch 29/50, Loss: 60.036995, Train_MMSE: 0.221648, NMMSE: 0.228355, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:42:26] Epoch 30/50, Loss: 59.872192, Train_MMSE: 0.221355, NMMSE: 0.225985, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:45:38] Epoch 31/50, Loss: 60.099297, Train_MMSE: 0.220942, NMMSE: 0.226457, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:48:49] Epoch 32/50, Loss: 60.558357, Train_MMSE: 0.220604, NMMSE: 0.224852, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 14:52:01] Epoch 33/50, Loss: 60.263706, Train_MMSE: 0.220321, NMMSE: 0.22816, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 14:55:12] Epoch 34/50, Loss: 59.705784, Train_MMSE: 0.219997, NMMSE: 0.22672, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 14:58:24] Epoch 35/50, Loss: 60.282043, Train_MMSE: 0.219765, NMMSE: 0.224456, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:01:37] Epoch 36/50, Loss: 59.764534, Train_MMSE: 0.21952, NMMSE: 0.224479, LS_NMSE: 1.324841, Lr: 0.001[[2025-02-19 15:04:48] Epoch 37/50, Loss: 59.713856, Train_MMSE: 0.219207, NMMSE: 0.226588, LS_NMSE: 1.324841, Lr: 0.001[[2025-02-19 15:08:01] Epoch 38/50, Loss: 60.038311, Train_MMSE: 0.219067, NMMSE: 0.227592, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:11:11] Epoch 39/50, Loss: 59.625610, Train_MMSE: 0.218946, NMMSE: 0.226034, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:14:22] Epoch 40/50, Loss: 59.675632, Train_MMSE: 0.218631, NMMSE: 0.223887, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:17:33] Epoch 41/50, Loss: 59.590115, Train_MMSE: 0.218452, NMMSE: 0.226012, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:20:33] Epoch 42/50, Loss: 60.078960, Train_MMSE: 0.218289, NMMSE: 0.224696, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:23:39] Epoch 43/50, Loss: 60.090591, Train_MMSE: 0.218117, NMMSE: 0.224094, LS_NMSE: 1.324841, Lr: 0.00[2[2025-02-19 15:26:41] Epoch 44/50, Loss: 58.828751, Train_MMSE: 0.218015, NMMSE: 0.222316, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 15:29:03] Epoch 45/50, Loss: 58.747246, Train_MMSE: 0.217798, NMMSE: 0.223758, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 15:31:25] Epoch 46/50, Loss: 59.586269, Train_MMSE: 0.217654, NMMSE: 0.223199, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 15:33:47] Epoch 47/50, Loss: 59.943256, Train_MMSE: 0.217461, NMMSE: 0.222185, LS_NMSE: 1.324841, Lr: 0.[202[2025-02-19 15:36:10] Epoch 48/50, Loss: 60.143990, Train_MMSE: 0.217368, NMMSE: 0.22384, LS_NMSE: 1.324841, Lr: 0.0[20[2025-02-19 15:38:31] Epoch 49/50, Loss: 59.401173, Train_MMSE: 0.2172, NMMSE: 0.221541, LS_NMSE: 1.324841, Lr: 0.001[[2025-02-19 15:40:18] Epoch 50/50, Loss: 59.887074, Train_MMSE: 0.217102, NMMSE: 0.222207, LS_NMSE: 1.324841, Lr: 0.001
01
